{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access functions from other locations\n",
    "import sys\n",
    "sys.path.append('/data/ad181/RemoteDir/rl_robust_owc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "import gym\n",
    "from stable_baselines3.ppo import PPO, MlpPolicy\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "from utils.custom_eval_callback import CustomEvalCallback\n",
    "from utils.env_wrappers import StateCoarse, BufferWrapper\n",
    "from typing import Callable\n",
    "from utils.plot_functions import plot_learning\n",
    "\n",
    "from model.ressim import Grid\n",
    "from ressim_env import ResSimEnv_v0, ResSimEnv_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1\n",
    "case='case_1_full_state'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./data', exist_ok=True)\n",
    "os.makedirs('./data/'+case, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../envs_params/env_data/env_train.pkl', 'rb') as input:\n",
    "    env_train = pickle.load(input)\n",
    "    \n",
    "with open('../envs_params/env_data/env_eval.pkl', 'rb') as input:\n",
    "    env_eval = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env, rank: int, seed: int) -> Callable:\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "    \n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environment you wish to have in subprocesses\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    :return: (Callable)\n",
    "    \"\"\"\n",
    "    def _init() -> gym.Env:\n",
    "        env_ = env\n",
    "        env_.seed(seed + rank)\n",
    "        return env_\n",
    "    return _init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test run\n",
    "# env = env_train\n",
    "# base_action = np.ones(env.action_space.shape[0])\n",
    "\n",
    "# state, done = env.reset(), False\n",
    "# print(state.shape)\n",
    "# while not done:\n",
    "#     state, reward, done, info = env.step(base_action)\n",
    "#     print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1\n",
      "Box(-100000.0, 100000.0, (3721,), float64)\n",
      "seed 1: model definition ..\n",
      "Using cuda device\n",
      "seed 1: learning ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f8961fc9da0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f8961fc9cf8>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f8961fc9da0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f8961fc9d30>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 101  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 31   |\n",
      "|    total_timesteps | 3200 |\n",
      "-----------------------------\n",
      "Eval num_timesteps=6400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.596     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 37        |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 171       |\n",
      "|    total_timesteps      | 6400      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0199498 |\n",
      "|    clip_fraction        | 0.43      |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 91.8      |\n",
      "|    explained_variance   | -0.498    |\n",
      "|    learning_rate        | 1e-06     |\n",
      "|    loss                 | 0.0333    |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -0.0315   |\n",
      "|    std                  | 0.055     |\n",
      "|    value_loss           | 0.0403    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 34         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 274        |\n",
      "|    total_timesteps      | 9600       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07480799 |\n",
      "|    clip_fraction        | 0.472      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.235      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0521     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0283    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00935    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=12800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=12800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.598     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 31        |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 411       |\n",
      "|    total_timesteps      | 12800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0530085 |\n",
      "|    clip_fraction        | 0.461     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 91.8      |\n",
      "|    explained_variance   | 0.801     |\n",
      "|    learning_rate        | 1e-06     |\n",
      "|    loss                 | 0.0522    |\n",
      "|    n_updates            | 60        |\n",
      "|    policy_gradient_loss | -0.0318   |\n",
      "|    std                  | 0.055     |\n",
      "|    value_loss           | 0.00368   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 16000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031356815 |\n",
      "|    clip_fraction        | 0.47        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0473      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00239     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=19200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=19200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.611       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 646         |\n",
      "|    total_timesteps      | 19200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006445117 |\n",
      "|    clip_fraction        | 0.464       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0435      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00211     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 22400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018735128 |\n",
      "|    clip_fraction        | 0.483       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0352      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00198     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=25600, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=25600, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.626        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 29           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 881          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002644396 |\n",
      "|    clip_fraction        | 0.467        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0428       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00192      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 980         |\n",
      "|    total_timesteps      | 28800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009859174 |\n",
      "|    clip_fraction        | 0.469       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0374      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00188     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=32000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.638       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1117        |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003908813 |\n",
      "|    clip_fraction        | 0.481       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0351      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0021      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 28            |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 1216          |\n",
      "|    total_timesteps      | 35200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0022107887 |\n",
      "|    clip_fraction        | 0.482         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.951         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.048         |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.0387       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00171       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=38400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=38400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.654        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 1353         |\n",
      "|    total_timesteps      | 38400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059264875 |\n",
      "|    clip_fraction        | 0.486        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0239       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.04        |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00175      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1451         |\n",
      "|    total_timesteps      | 41600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046298597 |\n",
      "|    clip_fraction        | 0.478        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0773       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00168      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=44800, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=44800, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.661       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1589        |\n",
      "|    total_timesteps      | 44800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004116572 |\n",
      "|    clip_fraction        | 0.491       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0307      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00154     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1687        |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004469867 |\n",
      "|    clip_fraction        | 0.484       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0383      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00176     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=51200, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=51200, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.668        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1824         |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.013849459 |\n",
      "|    clip_fraction        | 0.487        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0319       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0017       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 1922         |\n",
      "|    total_timesteps      | 54400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074157026 |\n",
      "|    clip_fraction        | 0.492        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0497       |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00161      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=57600, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=57600, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.674      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 2060       |\n",
      "|    total_timesteps      | 57600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00790364 |\n",
      "|    clip_fraction        | 0.489      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.961      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0678     |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.0399    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00158    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2157        |\n",
      "|    total_timesteps      | 60800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007578788 |\n",
      "|    clip_fraction        | 0.499       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0662      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00165     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=64000, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=64000, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.681       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2294        |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029084207 |\n",
      "|    clip_fraction        | 0.508       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0294      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00163     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2392        |\n",
      "|    total_timesteps      | 67200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011705293 |\n",
      "|    clip_fraction        | 0.507       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.025       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00158     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70400, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=70400, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.684       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2530        |\n",
      "|    total_timesteps      | 70400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012770002 |\n",
      "|    clip_fraction        | 0.5         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0287      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00161     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2629         |\n",
      "|    total_timesteps      | 73600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.012152123 |\n",
      "|    clip_fraction        | 0.507        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0313       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0384      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0019       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=76800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=76800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.686        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 2766         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.008148424 |\n",
      "|    clip_fraction        | 0.502        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0402       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00156      |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 27        |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 2864      |\n",
      "|    total_timesteps      | 80000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0225456 |\n",
      "|    clip_fraction        | 0.521     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 91.8      |\n",
      "|    explained_variance   | 0.964     |\n",
      "|    learning_rate        | 1e-06     |\n",
      "|    loss                 | 0.0592    |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | -0.0418   |\n",
      "|    std                  | 0.055     |\n",
      "|    value_loss           | 0.00148   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=83200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=83200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.688        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 3002         |\n",
      "|    total_timesteps      | 83200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073904586 |\n",
      "|    clip_fraction        | 0.513        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.00985      |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0403      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00155      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 3100        |\n",
      "|    total_timesteps      | 86400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014802978 |\n",
      "|    clip_fraction        | 0.52        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0259      |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00158     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=89600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=89600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.688        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 3237         |\n",
      "|    total_timesteps      | 89600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.002597909 |\n",
      "|    clip_fraction        | 0.521        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0177       |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00179      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 3335         |\n",
      "|    total_timesteps      | 92800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089589665 |\n",
      "|    clip_fraction        | 0.514        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.043        |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0405      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00164      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=96000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.69        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 3472        |\n",
      "|    total_timesteps      | 96000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033420846 |\n",
      "|    clip_fraction        | 0.523       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.051       |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00147     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 3570       |\n",
      "|    total_timesteps      | 99200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02652882 |\n",
      "|    clip_fraction        | 0.524      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0365     |\n",
      "|    n_updates            | 600        |\n",
      "|    policy_gradient_loss | -0.0412    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00157    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=102400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=102400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 5              |\n",
      "|    mean_reward          | 0.691          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 27             |\n",
      "|    iterations           | 32             |\n",
      "|    time_elapsed         | 3708           |\n",
      "|    total_timesteps      | 102400         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00067716837 |\n",
      "|    clip_fraction        | 0.524          |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | 91.8           |\n",
      "|    explained_variance   | 0.964          |\n",
      "|    learning_rate        | 1e-06          |\n",
      "|    loss                 | 0.0357         |\n",
      "|    n_updates            | 620            |\n",
      "|    policy_gradient_loss | -0.0405        |\n",
      "|    std                  | 0.055          |\n",
      "|    value_loss           | 0.00164        |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 3806        |\n",
      "|    total_timesteps      | 105600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012715783 |\n",
      "|    clip_fraction        | 0.538       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0497      |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00161     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=108800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=108800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.691       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 3943        |\n",
      "|    total_timesteps      | 108800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008846254 |\n",
      "|    clip_fraction        | 0.533       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0336      |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00157     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 4042          |\n",
      "|    total_timesteps      | 112000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035649538 |\n",
      "|    clip_fraction        | 0.532         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.966         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0369        |\n",
      "|    n_updates            | 680           |\n",
      "|    policy_gradient_loss | -0.04         |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00154       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=115200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=115200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.691        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 4179         |\n",
      "|    total_timesteps      | 115200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066770194 |\n",
      "|    clip_fraction        | 0.541        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0293       |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0405      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0015       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 4277        |\n",
      "|    total_timesteps      | 118400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014755399 |\n",
      "|    clip_fraction        | 0.54        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0429      |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00144     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=121600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=121600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.693       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 4415        |\n",
      "|    total_timesteps      | 121600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009287339 |\n",
      "|    clip_fraction        | 0.524       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0248      |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00154     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 4514        |\n",
      "|    total_timesteps      | 124800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022176959 |\n",
      "|    clip_fraction        | 0.538       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0381      |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00147     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=128000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.693       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 4651        |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008886111 |\n",
      "|    clip_fraction        | 0.535       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.034       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00141     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 4750        |\n",
      "|    total_timesteps      | 131200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012701993 |\n",
      "|    clip_fraction        | 0.533       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0388      |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00144     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=134400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=134400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.693       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 4888        |\n",
      "|    total_timesteps      | 134400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030540101 |\n",
      "|    clip_fraction        | 0.545       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0343      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00147     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 4986        |\n",
      "|    total_timesteps      | 137600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017800998 |\n",
      "|    clip_fraction        | 0.537       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0351      |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00154     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=140800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=140800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.693       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 5124        |\n",
      "|    total_timesteps      | 140800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032425176 |\n",
      "|    clip_fraction        | 0.552       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0451      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0014      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 5222         |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023305274 |\n",
      "|    clip_fraction        | 0.524        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0297       |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00143      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=147200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=147200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.694       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 5359        |\n",
      "|    total_timesteps      | 147200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021221805 |\n",
      "|    clip_fraction        | 0.546       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0569      |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00139     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 5456         |\n",
      "|    total_timesteps      | 150400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006766176 |\n",
      "|    clip_fraction        | 0.551        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0344       |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00137      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=153600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=153600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.695        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 5594         |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.006368356 |\n",
      "|    clip_fraction        | 0.545        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0554       |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00133      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 5691        |\n",
      "|    total_timesteps      | 156800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023367185 |\n",
      "|    clip_fraction        | 0.562       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0609      |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00133     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=160000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 5827        |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039194655 |\n",
      "|    clip_fraction        | 0.558       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0274      |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00155     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 5927        |\n",
      "|    total_timesteps      | 163200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031124027 |\n",
      "|    clip_fraction        | 0.552       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0391      |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00137     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=166400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=166400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.695        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 6062         |\n",
      "|    total_timesteps      | 166400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.002028172 |\n",
      "|    clip_fraction        | 0.545        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0504       |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.039       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00142      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 6161          |\n",
      "|    total_timesteps      | 169600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0126185175 |\n",
      "|    clip_fraction        | 0.535         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.967         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.029         |\n",
      "|    n_updates            | 1040          |\n",
      "|    policy_gradient_loss | -0.0357       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00133       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=172800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=172800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.695        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 6297         |\n",
      "|    total_timesteps      | 172800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038225031 |\n",
      "|    clip_fraction        | 0.543        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0361       |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.0386      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00137      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 6395        |\n",
      "|    total_timesteps      | 176000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020392776 |\n",
      "|    clip_fraction        | 0.564       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0501      |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00146     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=179200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=179200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 6532        |\n",
      "|    total_timesteps      | 179200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019707456 |\n",
      "|    clip_fraction        | 0.554       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0383      |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0014      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 6629        |\n",
      "|    total_timesteps      | 182400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013553944 |\n",
      "|    clip_fraction        | 0.556       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0013      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=185600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=185600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.695      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 6766       |\n",
      "|    total_timesteps      | 185600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04569008 |\n",
      "|    clip_fraction        | 0.56       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0368     |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00124    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 6864        |\n",
      "|    total_timesteps      | 188800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029765194 |\n",
      "|    clip_fraction        | 0.568       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0228      |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00127     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=192000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 7002        |\n",
      "|    total_timesteps      | 192000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011088393 |\n",
      "|    clip_fraction        | 0.552       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0395      |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00144     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 61         |\n",
      "|    time_elapsed         | 7099       |\n",
      "|    total_timesteps      | 195200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03500352 |\n",
      "|    clip_fraction        | 0.56       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0349     |\n",
      "|    n_updates            | 1200       |\n",
      "|    policy_gradient_loss | -0.039     |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00126    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=198400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=198400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.695      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 62         |\n",
      "|    time_elapsed         | 7235       |\n",
      "|    total_timesteps      | 198400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02973386 |\n",
      "|    clip_fraction        | 0.565      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0316     |\n",
      "|    n_updates            | 1220       |\n",
      "|    policy_gradient_loss | -0.0401    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00137    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 7333         |\n",
      "|    total_timesteps      | 201600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030175329 |\n",
      "|    clip_fraction        | 0.555        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0388       |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.0389      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00123      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=204800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=204800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 7469        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017363954 |\n",
      "|    clip_fraction        | 0.565       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0328      |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00137     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 7566        |\n",
      "|    total_timesteps      | 208000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021703146 |\n",
      "|    clip_fraction        | 0.571       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0282      |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00129     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=211200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=211200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.695        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 7702         |\n",
      "|    total_timesteps      | 211200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.005236006 |\n",
      "|    clip_fraction        | 0.552        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0742       |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.0363      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00112      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 7801        |\n",
      "|    total_timesteps      | 214400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025753189 |\n",
      "|    clip_fraction        | 0.565       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0565      |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00115     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=217600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=217600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 7937        |\n",
      "|    total_timesteps      | 217600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026548766 |\n",
      "|    clip_fraction        | 0.567       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0322      |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00113     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 8035        |\n",
      "|    total_timesteps      | 220800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028870588 |\n",
      "|    clip_fraction        | 0.572       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0249      |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0396     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00137     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 8171        |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007605302 |\n",
      "|    clip_fraction        | 0.564       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.03        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00121     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 8268        |\n",
      "|    total_timesteps      | 227200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014071872 |\n",
      "|    clip_fraction        | 0.58        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0243      |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00127     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=230400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=230400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.696       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 8404        |\n",
      "|    total_timesteps      | 230400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022403361 |\n",
      "|    clip_fraction        | 0.571       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0512      |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00111     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 8503        |\n",
      "|    total_timesteps      | 233600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031066375 |\n",
      "|    clip_fraction        | 0.564       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0291      |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00125     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=236800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=236800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 8639        |\n",
      "|    total_timesteps      | 236800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013598433 |\n",
      "|    clip_fraction        | 0.555       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0485      |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00111     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 8738        |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002104838 |\n",
      "|    clip_fraction        | 0.56        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0429      |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=243200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=243200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.696     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 27        |\n",
      "|    iterations           | 76        |\n",
      "|    time_elapsed         | 8874      |\n",
      "|    total_timesteps      | 243200    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0308727 |\n",
      "|    clip_fraction        | 0.572     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 91.8      |\n",
      "|    explained_variance   | 0.975     |\n",
      "|    learning_rate        | 1e-06     |\n",
      "|    loss                 | 0.0332    |\n",
      "|    n_updates            | 1500      |\n",
      "|    policy_gradient_loss | -0.0395   |\n",
      "|    std                  | 0.055     |\n",
      "|    value_loss           | 0.00114   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 8974        |\n",
      "|    total_timesteps      | 246400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022675639 |\n",
      "|    clip_fraction        | 0.553       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0513      |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00107     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=249600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=249600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.696         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 78            |\n",
      "|    time_elapsed         | 9111          |\n",
      "|    total_timesteps      | 249600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0061810925 |\n",
      "|    clip_fraction        | 0.564         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.969         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0606        |\n",
      "|    n_updates            | 1540          |\n",
      "|    policy_gradient_loss | -0.0357       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00114       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 9210        |\n",
      "|    total_timesteps      | 252800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024402587 |\n",
      "|    clip_fraction        | 0.567       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0736      |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00107     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=256000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.696      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 9346       |\n",
      "|    total_timesteps      | 256000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03134858 |\n",
      "|    clip_fraction        | 0.58       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0247     |\n",
      "|    n_updates            | 1580       |\n",
      "|    policy_gradient_loss | -0.0391    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00113    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 9444        |\n",
      "|    total_timesteps      | 259200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020526802 |\n",
      "|    clip_fraction        | 0.576       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0415      |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00116     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=262400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=262400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 9581        |\n",
      "|    total_timesteps      | 262400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014426613 |\n",
      "|    clip_fraction        | 0.571       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0357      |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00108     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 9679        |\n",
      "|    total_timesteps      | 265600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026841845 |\n",
      "|    clip_fraction        | 0.576       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0287      |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00106     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=268800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=268800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 9814        |\n",
      "|    total_timesteps      | 268800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020961199 |\n",
      "|    clip_fraction        | 0.582       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.000965    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 9912        |\n",
      "|    total_timesteps      | 272000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030114878 |\n",
      "|    clip_fraction        | 0.575       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0351      |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.000978    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=275200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=275200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.696       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 10048       |\n",
      "|    total_timesteps      | 275200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012917028 |\n",
      "|    clip_fraction        | 0.572       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00104     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 10147       |\n",
      "|    total_timesteps      | 278400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019872831 |\n",
      "|    clip_fraction        | 0.576       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0131      |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=281600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=281600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.696       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 10281       |\n",
      "|    total_timesteps      | 281600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021775482 |\n",
      "|    clip_fraction        | 0.567       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0333      |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00095     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 10379       |\n",
      "|    total_timesteps      | 284800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012112382 |\n",
      "|    clip_fraction        | 0.572       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0585      |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0011      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=288000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 10515       |\n",
      "|    total_timesteps      | 288000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021597495 |\n",
      "|    clip_fraction        | 0.571       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.001       |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 91            |\n",
      "|    time_elapsed         | 10613         |\n",
      "|    total_timesteps      | 291200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00069561956 |\n",
      "|    clip_fraction        | 0.581         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.975         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0308        |\n",
      "|    n_updates            | 1800          |\n",
      "|    policy_gradient_loss | -0.0367       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00126       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=294400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=294400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.695       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 10747       |\n",
      "|    total_timesteps      | 294400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057061024 |\n",
      "|    clip_fraction        | 0.58        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0452      |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.0371     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.000911    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 10845      |\n",
      "|    total_timesteps      | 297600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03710049 |\n",
      "|    clip_fraction        | 0.578      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.975      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.039      |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | -0.0394    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.000982   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=300800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=300800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.696       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 10981       |\n",
      "|    total_timesteps      | 300800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009414551 |\n",
      "|    clip_fraction        | 0.573       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0728      |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 2\n",
      "Box(-100000.0, 100000.0, (3721,), float64)\n",
      "seed 2: model definition ..\n",
      "Using cuda device\n",
      "seed 2: learning ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f894bff2a90> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f894bfe24e0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f894bff2a90> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f894bfe29e8>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 101         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 3200        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022189742 |\n",
      "|    clip_fraction        | 0.582       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.058       |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00112     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6400, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.601       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 6400        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029557448 |\n",
      "|    clip_fraction        | 0.445       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.314      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0268      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0339     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0366      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 35          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 9600        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070911855 |\n",
      "|    clip_fraction        | 0.464       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.177       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0462      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00997     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=12800, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=12800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.608       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053263985 |\n",
      "|    clip_fraction        | 0.474       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0643      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00384     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 31         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 501        |\n",
      "|    total_timesteps      | 16000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01906039 |\n",
      "|    clip_fraction        | 0.455      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0444     |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00249    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=19200, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=19200, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.623       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 637         |\n",
      "|    total_timesteps      | 19200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008605089 |\n",
      "|    clip_fraction        | 0.457       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0247      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00208     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 735        |\n",
      "|    total_timesteps      | 22400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01720534 |\n",
      "|    clip_fraction        | 0.458      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0597     |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0368    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00193    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=25600, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=25600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.638        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 29           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 872          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059323884 |\n",
      "|    clip_fraction        | 0.466        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0503       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0378      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00174      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 29           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 970          |\n",
      "|    total_timesteps      | 28800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039701774 |\n",
      "|    clip_fraction        | 0.462        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0299       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0382      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00178      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=32000, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=32000, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.645       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1104        |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009880925 |\n",
      "|    clip_fraction        | 0.471       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0334      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00173     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1202        |\n",
      "|    total_timesteps      | 35200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010504677 |\n",
      "|    clip_fraction        | 0.475       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0201      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0385     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00166     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=38400, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=38400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.653      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 28         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 1339       |\n",
      "|    total_timesteps      | 38400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01285094 |\n",
      "|    clip_fraction        | 0.493      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0311     |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0409    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00158    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1436        |\n",
      "|    total_timesteps      | 41600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016046105 |\n",
      "|    clip_fraction        | 0.48        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.034       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00154     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=44800, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=44800, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.655       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1572        |\n",
      "|    total_timesteps      | 44800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009074191 |\n",
      "|    clip_fraction        | 0.493       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0405     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00156     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 28            |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 1670          |\n",
      "|    total_timesteps      | 48000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0013863326 |\n",
      "|    clip_fraction        | 0.485         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.96          |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0544        |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.0399       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00154       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=51200, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=51200, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.66        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1807        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009647987 |\n",
      "|    clip_fraction        | 0.493       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0392      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00149     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1905        |\n",
      "|    total_timesteps      | 54400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006406486 |\n",
      "|    clip_fraction        | 0.499       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0384      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00146     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=57600, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=57600, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.667         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 28            |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 2041          |\n",
      "|    total_timesteps      | 57600         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0009681916 |\n",
      "|    clip_fraction        | 0.503         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.963         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0445        |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.0403       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.0014        |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 2139         |\n",
      "|    total_timesteps      | 60800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.016659407 |\n",
      "|    clip_fraction        | 0.477        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0405       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0365      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00144      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=64000, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.673       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2273        |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010429485 |\n",
      "|    clip_fraction        | 0.5         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00143     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2370        |\n",
      "|    total_timesteps      | 67200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004492438 |\n",
      "|    clip_fraction        | 0.504       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0016      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70400, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=70400, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.675        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 2508         |\n",
      "|    total_timesteps      | 70400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033001162 |\n",
      "|    clip_fraction        | 0.505        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0341       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0403      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00154      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 2605         |\n",
      "|    total_timesteps      | 73600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.008609612 |\n",
      "|    clip_fraction        | 0.51         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0405       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0017       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=76800, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=76800, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.675        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 2743         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139358565 |\n",
      "|    clip_fraction        | 0.507        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0159       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0403      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00141      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 28         |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 2841       |\n",
      "|    total_timesteps      | 80000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00788213 |\n",
      "|    clip_fraction        | 0.509      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0234     |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0413    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00163    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=83200, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=83200, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.676         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 2977          |\n",
      "|    total_timesteps      | 83200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0014651895 |\n",
      "|    clip_fraction        | 0.512         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.968         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0683        |\n",
      "|    n_updates            | 500           |\n",
      "|    policy_gradient_loss | -0.0405       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00147       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 3076         |\n",
      "|    total_timesteps      | 86400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055789305 |\n",
      "|    clip_fraction        | 0.51         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0185       |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00153      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=89600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=89600, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.679       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 3212        |\n",
      "|    total_timesteps      | 89600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015998228 |\n",
      "|    clip_fraction        | 0.518       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0314      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00147     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 3310         |\n",
      "|    total_timesteps      | 92800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.012969823 |\n",
      "|    clip_fraction        | 0.512        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0353       |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0388      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00148      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=96000, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.682         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 3446          |\n",
      "|    total_timesteps      | 96000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0021069504 |\n",
      "|    clip_fraction        | 0.523         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.964         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0299        |\n",
      "|    n_updates            | 580           |\n",
      "|    policy_gradient_loss | -0.0398       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.0016        |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 3544          |\n",
      "|    total_timesteps      | 99200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0047934414 |\n",
      "|    clip_fraction        | 0.52          |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.964         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0205        |\n",
      "|    n_updates            | 600           |\n",
      "|    policy_gradient_loss | -0.0396       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00154       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=102400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=102400, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.684       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 3681        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020685153 |\n",
      "|    clip_fraction        | 0.537       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0384      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0421     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00154     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 3779         |\n",
      "|    total_timesteps      | 105600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.002530942 |\n",
      "|    clip_fraction        | 0.537        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0183       |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.041       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00165      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=108800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=108800, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.684        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 3916         |\n",
      "|    total_timesteps      | 108800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036877322 |\n",
      "|    clip_fraction        | 0.529        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0538       |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00164      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 4014        |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026159262 |\n",
      "|    clip_fraction        | 0.534       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0357      |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00152     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=115200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=115200, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.684         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 4151          |\n",
      "|    total_timesteps      | 115200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0004153085 |\n",
      "|    clip_fraction        | 0.528         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.971         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0381        |\n",
      "|    n_updates            | 700           |\n",
      "|    policy_gradient_loss | -0.0403       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00143       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 4250        |\n",
      "|    total_timesteps      | 118400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012961661 |\n",
      "|    clip_fraction        | 0.532       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0715      |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00156     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=121600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=121600, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.685        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 4385         |\n",
      "|    total_timesteps      | 121600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.028932586 |\n",
      "|    clip_fraction        | 0.498        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0207       |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0305      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00187      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 4483        |\n",
      "|    total_timesteps      | 124800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026780067 |\n",
      "|    clip_fraction        | 0.549       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.046       |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0427     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00149     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=128000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.685       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 4620        |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007152014 |\n",
      "|    clip_fraction        | 0.532       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0432      |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00157     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 4718        |\n",
      "|    total_timesteps      | 131200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004312682 |\n",
      "|    clip_fraction        | 0.525       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0809      |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00155     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=134400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=134400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.686         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 4854          |\n",
      "|    total_timesteps      | 134400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0031307077 |\n",
      "|    clip_fraction        | 0.529         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.967         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0352        |\n",
      "|    n_updates            | 820           |\n",
      "|    policy_gradient_loss | -0.0391       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00151       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 4952         |\n",
      "|    total_timesteps      | 137600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059988284 |\n",
      "|    clip_fraction        | 0.535        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.101        |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0395      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00139      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=140800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=140800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.687       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 5089        |\n",
      "|    total_timesteps      | 140800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033214763 |\n",
      "|    clip_fraction        | 0.551       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0305      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00163     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 5187        |\n",
      "|    total_timesteps      | 144000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005901079 |\n",
      "|    clip_fraction        | 0.531       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0351      |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00141     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=147200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=147200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.688         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 5323          |\n",
      "|    total_timesteps      | 147200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0013208651 |\n",
      "|    clip_fraction        | 0.539         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.967         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0403        |\n",
      "|    n_updates            | 900           |\n",
      "|    policy_gradient_loss | -0.0394       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00154       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 5421        |\n",
      "|    total_timesteps      | 150400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021520196 |\n",
      "|    clip_fraction        | 0.546       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0464      |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00147     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=153600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=153600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.687        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 5557         |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063164784 |\n",
      "|    clip_fraction        | 0.537        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0421       |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00143      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 5656        |\n",
      "|    total_timesteps      | 156800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011773481 |\n",
      "|    clip_fraction        | 0.553       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0302      |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0409     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00158     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=160000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.688       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 5789        |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009144559 |\n",
      "|    clip_fraction        | 0.545       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0329      |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00148     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 5886         |\n",
      "|    total_timesteps      | 163200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053787353 |\n",
      "|    clip_fraction        | 0.548        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0486       |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.0393      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0014       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=166400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=166400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.688      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 6022       |\n",
      "|    total_timesteps      | 166400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04107223 |\n",
      "|    clip_fraction        | 0.547      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.025      |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | -0.0387    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00133    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 6119         |\n",
      "|    total_timesteps      | 169600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070951986 |\n",
      "|    clip_fraction        | 0.554        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0636       |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00144      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=172800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=172800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.688       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 6255        |\n",
      "|    total_timesteps      | 172800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026203293 |\n",
      "|    clip_fraction        | 0.551       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0321      |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00131     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 55            |\n",
      "|    time_elapsed         | 6353          |\n",
      "|    total_timesteps      | 176000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0063125286 |\n",
      "|    clip_fraction        | 0.538         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.97          |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.028         |\n",
      "|    n_updates            | 1080          |\n",
      "|    policy_gradient_loss | -0.0386       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00134       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=179200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=179200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.687       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 6491        |\n",
      "|    total_timesteps      | 179200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010983724 |\n",
      "|    clip_fraction        | 0.547       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0439      |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00126     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 6589        |\n",
      "|    total_timesteps      | 182400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011512293 |\n",
      "|    clip_fraction        | 0.542       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00127     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=185600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=185600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.687       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 6725        |\n",
      "|    total_timesteps      | 185600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024937093 |\n",
      "|    clip_fraction        | 0.548       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0613      |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00126     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 6824       |\n",
      "|    total_timesteps      | 188800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01332556 |\n",
      "|    clip_fraction        | 0.551      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0341     |\n",
      "|    n_updates            | 1160       |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00125    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=192000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.687        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 6958         |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013209224 |\n",
      "|    clip_fraction        | 0.553        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0325       |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.0397      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00132      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 61            |\n",
      "|    time_elapsed         | 7056          |\n",
      "|    total_timesteps      | 195200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0083385585 |\n",
      "|    clip_fraction        | 0.547         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.97          |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0238        |\n",
      "|    n_updates            | 1200          |\n",
      "|    policy_gradient_loss | -0.0358       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00127       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=198400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=198400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.688       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 7191        |\n",
      "|    total_timesteps      | 198400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032445498 |\n",
      "|    clip_fraction        | 0.565       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0654      |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00135     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 7289        |\n",
      "|    total_timesteps      | 201600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023431934 |\n",
      "|    clip_fraction        | 0.567       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0357      |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.0404     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00122     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=204800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=204800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.688      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 64         |\n",
      "|    time_elapsed         | 7426       |\n",
      "|    total_timesteps      | 204800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01013731 |\n",
      "|    clip_fraction        | 0.561      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.975      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0667     |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00126    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 7524        |\n",
      "|    total_timesteps      | 208000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028267402 |\n",
      "|    clip_fraction        | 0.564       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0418      |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00115     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=211200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=211200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.687       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 7659        |\n",
      "|    total_timesteps      | 211200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051984254 |\n",
      "|    clip_fraction        | 0.563       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0538      |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00119     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 67            |\n",
      "|    time_elapsed         | 7757          |\n",
      "|    total_timesteps      | 214400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0066975188 |\n",
      "|    clip_fraction        | 0.551         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.972         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0326        |\n",
      "|    n_updates            | 1320          |\n",
      "|    policy_gradient_loss | -0.0359       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00136       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=217600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=217600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.688       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 7894        |\n",
      "|    total_timesteps      | 217600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011706817 |\n",
      "|    clip_fraction        | 0.555       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0455      |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00113     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 7992        |\n",
      "|    total_timesteps      | 220800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023233734 |\n",
      "|    clip_fraction        | 0.559       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0275      |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00124     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.69        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 8128        |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021373598 |\n",
      "|    clip_fraction        | 0.561       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0526      |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00126     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 8226        |\n",
      "|    total_timesteps      | 227200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025665917 |\n",
      "|    clip_fraction        | 0.57        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0348      |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00144     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=230400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=230400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.69        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 8362        |\n",
      "|    total_timesteps      | 230400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012799607 |\n",
      "|    clip_fraction        | 0.552       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0611      |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00104     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 8460         |\n",
      "|    total_timesteps      | 233600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064156987 |\n",
      "|    clip_fraction        | 0.565        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0271       |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.0394      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00113      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=236800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=236800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.69      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 27        |\n",
      "|    iterations           | 74        |\n",
      "|    time_elapsed         | 8597      |\n",
      "|    total_timesteps      | 236800    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0348436 |\n",
      "|    clip_fraction        | 0.577     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 91.8      |\n",
      "|    explained_variance   | 0.977     |\n",
      "|    learning_rate        | 1e-06     |\n",
      "|    loss                 | 0.0541    |\n",
      "|    n_updates            | 1460      |\n",
      "|    policy_gradient_loss | -0.0392   |\n",
      "|    std                  | 0.055     |\n",
      "|    value_loss           | 0.00115   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 8696        |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023669286 |\n",
      "|    clip_fraction        | 0.566       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0423      |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=243200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=243200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.691       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 8834        |\n",
      "|    total_timesteps      | 243200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025533158 |\n",
      "|    clip_fraction        | 0.562       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0457      |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00107     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 8932        |\n",
      "|    total_timesteps      | 246400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042954773 |\n",
      "|    clip_fraction        | 0.562       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0337      |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00112     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=249600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=249600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.691       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 9067        |\n",
      "|    total_timesteps      | 249600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007476158 |\n",
      "|    clip_fraction        | 0.572       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0484      |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00114     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 9164       |\n",
      "|    total_timesteps      | 252800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03164399 |\n",
      "|    clip_fraction        | 0.585      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.017      |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | -0.0405    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00109    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=256000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.691       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 9302        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015902972 |\n",
      "|    clip_fraction        | 0.579       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00114     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 9402        |\n",
      "|    total_timesteps      | 259200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018125767 |\n",
      "|    clip_fraction        | 0.567       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.026       |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0384     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=262400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=262400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 5              |\n",
      "|    mean_reward          | 0.692          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 27             |\n",
      "|    iterations           | 82             |\n",
      "|    time_elapsed         | 9538           |\n",
      "|    total_timesteps      | 262400         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00012390852 |\n",
      "|    clip_fraction        | 0.565          |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | 91.8           |\n",
      "|    explained_variance   | 0.977          |\n",
      "|    learning_rate        | 1e-06          |\n",
      "|    loss                 | 0.0334         |\n",
      "|    n_updates            | 1620           |\n",
      "|    policy_gradient_loss | -0.0364        |\n",
      "|    std                  | 0.055          |\n",
      "|    value_loss           | 0.00116        |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 83            |\n",
      "|    time_elapsed         | 9637          |\n",
      "|    total_timesteps      | 265600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0014736152 |\n",
      "|    clip_fraction        | 0.559         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.974         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0512        |\n",
      "|    n_updates            | 1640          |\n",
      "|    policy_gradient_loss | -0.0362       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00108       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=268800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=268800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.693       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 9771        |\n",
      "|    total_timesteps      | 268800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040271435 |\n",
      "|    clip_fraction        | 0.573       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0432      |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0386     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00106     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 9869         |\n",
      "|    total_timesteps      | 272000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052000475 |\n",
      "|    clip_fraction        | 0.571        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0323       |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00102      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=275200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=275200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 10004       |\n",
      "|    total_timesteps      | 275200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021835038 |\n",
      "|    clip_fraction        | 0.563       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0522      |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.0378     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.000998    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 10101       |\n",
      "|    total_timesteps      | 278400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013778422 |\n",
      "|    clip_fraction        | 0.564       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0429      |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=281600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=281600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.693       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 10239       |\n",
      "|    total_timesteps      | 281600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017499786 |\n",
      "|    clip_fraction        | 0.568       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0232      |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00109     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 10337        |\n",
      "|    total_timesteps      | 284800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.016100278 |\n",
      "|    clip_fraction        | 0.558        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0338       |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.0335      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00107      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=288000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.693         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 90            |\n",
      "|    time_elapsed         | 10474         |\n",
      "|    total_timesteps      | 288000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0054145004 |\n",
      "|    clip_fraction        | 0.563         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.974         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0411        |\n",
      "|    n_updates            | 1780          |\n",
      "|    policy_gradient_loss | -0.0351       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00104       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 10572       |\n",
      "|    total_timesteps      | 291200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048255224 |\n",
      "|    clip_fraction        | 0.6         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0538      |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.0397     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00102     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=294400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=294400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.693       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 10707       |\n",
      "|    total_timesteps      | 294400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007615671 |\n",
      "|    clip_fraction        | 0.581       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0529      |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.000969    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 10804       |\n",
      "|    total_timesteps      | 297600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019049875 |\n",
      "|    clip_fraction        | 0.579       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0317      |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0011      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=300800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.694         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 94            |\n",
      "|    time_elapsed         | 10940         |\n",
      "|    total_timesteps      | 300800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021205425 |\n",
      "|    clip_fraction        | 0.58          |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.977         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0405        |\n",
      "|    n_updates            | 1860          |\n",
      "|    policy_gradient_loss | -0.0369       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.000997      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAjIAAAHUCAYAAAAgOcJbAAAgAElEQVR4Xu2dCZjOVfvHvzNm7MYu29iSfV+iJGFESpHKWoRCKvQmVLbiVYmEQnnfir8KFUUiZE/27A2yDcZuBmMWM+N/3cf7TINhnsf8tvP8vue65hpmzu+c+3zuc5/nO2f5nYCrV69eBRMJkAAJkAAJkAAJaEgggEJGQ6/RZBIgARIgARIgAUWAQoYdgQRIgARIgARIQFsCFDLauo6GkwAJkAAJkAAJUMiwD5AACZAACZAACWhLgEJGW9fRcBIgARIgARIgAQoZ9gESIAESIAESIAFtCVDIaOs6Gk4CJEACJEACJEAhwz5AAiRAAiRAAiSgLQEKGW1dR8NJgARIgARIgAQoZNgHSIAESIAESIAEtCVAIaOt62g4CZAACZAACZAAhQz7AAmQAAmQAAmQgLYEKGS0dR0NJwESIAESIAESoJBhHyABEiABEiABEtCWAIWMtq6j4SRAAiRAAiRAAhQy7AMkQAIkQAIkQALaEqCQ0dZ1NJwESIAESIAESIBChn2ABEiABEiABEhAWwIUMtq6joaTAAmQAAmQAAlQyLAPkAAJkAAJkAAJaEuAQkZb19FwEiABEiABEiABChn2ARIgARIgARIgAW0JUMho6zoaTgIkQAIkQAIkQCHDPkACJEACJEACJKAtAQoZbV1Hw0mABEiABEiABChk2AdIgARIgARIgAS0JUAho63raDgJkAAJkAAJkACFDPsACZAACZAACZCAtgQoZLR1HQ0nARIgARIgARKgkGEfIAESIAESIAES0JYAhYy2rqPhJEACJEACJEACFDLsAyRAAiRAAiRAAtoSoJDR1nU0nARIgARIgARIgEKGfYAESIAESIAESEBbAhQy2rqOhpMACZAACZAACVDIsA+QAAmQAAmQAAloS4BCRlvX0XASIAESIAESIAEKGfYBEiABEiABEiABbQlQyGjrOhpOAiRAAiRAAiRAIcM+QAIkQAIkQAIkoC0BChltXUfDSYAESIAESIAEKGTYB0iABEiABEiABLQlQCGjretoOAmQAAmQAAmQAIUM+wAJkAAJkAAJkIC2BChktHUdDScBEiABEiABEqCQYR8gARIgARIgARLQlgCFjLauo+EkQAIkQAIkQAIUMuwDJEACJEACJEAC2hKgkNHWdTScBEiABEiABEiAQoZ9gARIgARIgARIQFsCFDLauo6GkwAJkAAJkAAJUMiwD5AACZAACZAACWhLgEJGW9fRcBIgARIgARIgAQoZ9gESIAESIAESIAFtCVDIaOs6Gk4CJEACJEACJEAhwz5AAiRAAiRAAiSgLQEKGW1dR8NJgARIgARIgAQoZNgHSIAESIAESIAEtCVAIaOt62g4CZAACZAACZAAhQz7AAmQAAmQAAmQgLYEKGS0dR0NJwESIAESIAESoJBhHyABEiABEiABEtCWAIWMtq6j4SRAAiRAAiRAAhQy7AMkQAIkQAIkQALaEqCQ0dZ1NJwESIAESIAESIBChn2ABEiABEiABEhAWwIUMtq6joaTAAmQAAmQAAlQyLAPkAAJkAAJkAAJaEuAQkZb19FwEiABEiABEiABChn2ARIgARIgARIgAW0JUMho6zoaTgIkQAIkQAIkQCHDPkACJEACJEACJKAtAQoZbV1Hw0mABEiABEiABChk2AdIgARIgARIgAS0JUAho63raDgJkAAJkAAJkACFDPsACZAACZAACZCAtgQoZLR1HQ0nARIgARIgARKgkGEfIAESIAESIAES0JYAhYy2rqPhJEACJEACJEACFDLsAyRAAiRAAiRAAtoSoJDR1nU0nARIgARIgARIgEKGfYAESIAESIAESEBbAhQy2rqOhpMACZAACZAACVDIsA+QAAmQAAmQAAloS4BCRlvX0XASIAESIAESIAEKGfYBEiABEiABEiABbQlQyGjrOhpOAiRAAiRAAiRAIcM+QAIkQAIkQAIkoC0BChltXUfDSYAESIAESIAEKGTYB0iABEiABEiABLQlQCGjretoOAmQAAmQAAmQAIWM5n0gOTkZcXFxCAoKQkBAgOatofkkQAIkYC2Bq1evIjExEVmzZkVgYKC1lbM2QwhQyBiC0b5CLl++jBw5cthnAGsmARIgAT8gEBMTg+zZs/tBS9zXBAoZzX2ekJCALFmyQIIwODhY89bQfBIgARKwlsCVK1fUH4Px8fHInDmztZWzNkMIUMgYgtG+QiQIJfhE0FDI2OcH1kwCJKAnAY6hevottdUUMpr7kEGouQNpPgmQgK0EOIbait+QyilkDMFoXyEMQvvYs2YSIAH9CXAM1d+HFDKa+5BBqLkDaT4JkICtBDiG2orfkMopZAzBaF8hDEL72LNmEiAB/QlwDNXfhxQymvuQQai5A2k+CZCArQQ4htqK35DKKWQMwWhfIQxC+9izZhIgAf0JcAzV34cUMpr7kEGouQNpPgmQgK0EOIbait+QyilkDMFoXyEMQvvYs2YSIAH9CXAM1d+HFDKa+5BBqLkDaT4JkECGCWw9ch75c2RBify+XzHAMTTD+G0vgELGdhdkzAAGYcb48WkSIAE9CSQmJePX3ScxbfUBbDkShQ73hmL0k9V8bgzHUJ+ROe4BChnHucQ3gxiEvvFibhIgAb0JXIy7glkbI/DF2kM4FhWrGlMwVxa82LAMXniwjM+N4xjqMzLHPUAh4ziX+GYQg9A3XsxNAiRgHIGj5y/j79MxKJI7K4rnzYbsmYNuW/jlhEREnIvFsajLuBSfhLgrSYi/It+T1b/jEpOQlAxkC86EHFkyqfI837MGB2JF+GklYi7FJ6p6KhUJQfcHSuOx6kWQJSjTHTWMY+gdYXPUQxQyjnKH78YwCH1nxidIgATujEBCYjI2HT6nBMXyv05h36lL1xVUIGdmhObLjtC82RGaLxuuXgUizsfiyLnLOHruMs7GJNxZxTc81bRCIXRvWBr3lcmPgICADJXJMTRD+BzxMIWMI9xw50YwCO+cHZ8kARK4PYGk5KvYf+oSthw5j5Xhp7Fm/5mU2RB5skDOLKhWPDdOXYxTMy3RsVduW2DubMFK4BTPkx0h2YKQNTgTsgQFqu+ef2cKDEDslSTEJiQhJj4JMosTk5CEy/GJSiQ9e19J3F0wp2Gu4xhqGErbCqKQsQ29MRUzCI3hyFJIwJ8IyMyJiAH5fiUpOeV7fGIykq9eVcswslQj3z1CInNQII5HxWL70WhsOxqFPyOisPNYNC4nJKWgkcmPGqF50Lh8IfVVuWgIAgP/mRERIRNx7vK1r/OXEYAAJVzULE2+7AjJGuw4zBxDHecSnw2ikPEZmbMeYBA6yx+0hgTsJLD9aBT+u+Ygft4RiStJVzNsigiXcoVyqVmXBmUL4MFyBZEvR+YMl+ukAjiGOskbd2YLhcydcXPMUwxCx7iChpCALQTkGPLiXSfxxdqD2HT4vLIhOFOAeq9KcFAAMmcKRHAmmX259l1mUGRmRjbZer7HJV7bbJs3e2Y141I9NDeqFc+DKsVyI2eW22/gtaXRBlbKMdRAmDYVRSFjE3ijqmUQGkWS5ZCAXgTOxyRg1qYITP/9EI5HxynjZc/Ks/VLomO9EupIMlP6BDiGps/I6TkoZJzuoXTsYxBq7kCaTwJeEjgRHYcNh85h06Fz2HDwHMJPXlSngiRVKRaCbg1K49Fqd34M2Usz/C4bx1D9XUoho7kPGYSaO5DmkwCAUxficOpiPC7EXsGFuCu4EJt47Xtcojq2vPHwOXUqKHWSJZ9G5Qqia4NSqFMyb4aPIbvVERxD9fc8hYzmPmQQau5Amu9qAvJit9EL92Dm+iPpcpClontL5UOdUnlRt1Q+VCwSAjmqzJQxAhxDM8bPCU9TyDjBCxmwgUGYAXh8lARsJLB2/xm88d129Zp9OQpdtVhudTw5JFswQrIG/e97MPLnzIxaJfKiZP7snHUxwV8cQ02AanGRFDIWAze6Ogah0URZHgmYS0BmYf69cA++/t8szL2l82HMU9VQMn8Ocytm6WkS4Biqf8egkNHchwxCzR3oJ+bLS9eCAgM4Y5COP9fsO4OB31+bhZH7hAa2KI/n7it13Uvl/KRLaNMMjqHauOqWhlLIaO5DBqHmDtTc/F3HozFh2T71HpNyd+XEU7WLo3XNYiiUK6vXLTt7KR5/nbh47SvygjqNc/B0DIKDAtUSSy613BKEXFmufZeyZRZD9olky3xnFwV6bZxBGfdEXsC01Qfx/ZajqkTOwhgE1oBiOIYaANHmIihkbHZARqtnEGaUIJ+/EwKpBYw8L2+A9RwFlg2ojcsXVKKmSYW7IK++lxSfmKTu7fkrUkTLBSVc9kRexJlL8XdignrRW62SefBA2QK4v2wBVCuWG0GZrtWVkZScfFVdcrg78gKOnY9V9p25lKC+n42Jx5mLCepOITnyHFbxLjSteBfuLpjjptkoecHcz9sjMXP9YWw5EqVM4ixMRjxjzrMcQ83hamWpFDJW0jahLgahCVBZ5C0J3ChgcmUJwvMPlMbz95dSH/xzNkXgl50n1BtjJeXNHow6pfLh0JkYHDgTA7mE8MYkL3GrWCQXyt+VCxWKhKBC4VwoWyinuhPoYlzi/44kXzuOLP+XsmSjrFxkmPo1/GJLmYI51CyNCAb5LhcRqn8HZ1IzO7mzXdtEK5cXer7Lstju4xew6/gF9V3aIftYfEml8mdXgkaETcFcmfHthgh8t+Uooi5fu0RRboVuVzcUneqVRNE82XwpmnlNJsAx1GTAFhRPIWMBZDOrYBCaSZdlCwG5hXjZXycxd8sxLPvrlILiETDdG5RG7uzXXwQogkNmIr7bfBSb//fKfHlGXpFfTsRK4X8ES/nCudTbaO8kya3IGw+dV6JGvkSIGJVKF8iBSkVDUDp/DiVCCuTKol75LyJF7BWBtO7AWSzbcxLL9pxC5P/erHtj/feVyY9O9Uvg4UqFU2amjLKR5RhDgGOoMRztLIVCxk76BtTNIDQAIou4iYDMUqzedxo//XkcS3afRMz/bkC+nYBJC+Pfpy+p5SSZYSmVP4ep7z2RV/bLS+VkSUdufpavuIRr3+UGZ5nNkSUh+br20rlrXzJJJIKqStEQVC6WW72fxZf7ha5evapmcZbuPqUE38kLcWhZtYiafZF2MzmbAMdQZ/vHG+soZLyh5OA8DEIHO0cz0+QDWZZrvtt8DL/sjExZFpF3rt1/dwE8Xr0oWlQtrN51wkQC/kKAY6j+nqSQ0dyHDELNHegA82V2QpaN5L0mcmLIk2qWyIMnqhdFy2pFfDqF5IAm0QQS8JoAx1CvUTk2I4WMY13jnWEMQu84Mdf1BGT2ZdvRaHy9/jB+2nYccVeubc4tnjcb2tUJVUeoQ/NlJzYS8HsCHEP1dzGFjOY+ZBBq7kCLzJdTOOHqXS0X1PHnjYfOqePPkuS4dJMKhdCpXgk0vKegqftYLGouqyEBrwlwDPUalWMzUsg41jXeGcYg9I6T23LtP3VRvaRuW0SUEizyXpQbU5HcWdG+bgl1LLhwbu9fYOc2lmyvfxPgGKq/fylkNPchg1BzB3ppfnpXAMhSkRw/XrTzhNqo+/fpmOtKltNGFYrI0eeQlO/VixvzAjkvm8BsJOBIAhxDHekWn4yikPEJl/MyMwid55OMWCSCRN5J4nkxm+e7zKjIS90K5sqCQrnkfSb/+8qZRR0nXrz7BCLOxaZUXTgkK1pUKYwGZQuol80Vy5ON9yBlxDF81m8JcAzV37UUMpr7kEGouQP/Z/6pi3EYMX+3erGb522wqVuWNThQvS3Xcw1AWq0ukS87HqlSGM2rFEaN4nl4EaF/dA22wmQCHENNBmxB8RQyFkA2swoGoZl0rSn7jwNn8co3W3H64rU7h2T2RN4qW6lISMp3OU0kr/c/G5Og8smXiB/PM40rFFL5A+TSIyYSIAGvCXAM9RqVYzNSyDjWNd4ZxiD0jpMTc8nlhFNW/Y0PF4ert8vKyaH32lblO1uc6Cza5LcEOIbq71oKGc19yCDU04FRlxPwr9nb1N1F8ubc15uXR68H7+ZykJ7upNUaE+AYqrHz/mc6hYzmPmQQ6udAORL90swtOBYVqzbtTuxQE/XL5NevIbSYBPyAAMdQ/Z1IIaO5DxmEejlw9sYIvD1vJxKSklG/TD5M6FCTS0l6uZDW+hkBjqH6O5RCRnMfMgj1ceD//XFYiRhJfRrfjf5h5RCUKVCfBtBSEvBDAhxD9XcqhYyPPkxKSsKgQYPw5ZdfIi4uDi1atMCUKVOQP3/aSwOnTp3CgAEDsGDBAkjAlClTBgsXLkTRokVVzfLvIUOGYP/+/ciRIwdat26NcePGIWtW7960yiD00YE2ZfeIGDlU9EHbani6TqhNlrBaEiCB1AQ4hurfHyhkfPThqFGj8NVXX2Hx4sXImzcvunTpguTkZMyfP/+mkkTo1K1bF/Xr18fo0aORL18+7NmzB6GhoQgJCYGInBIlSijh0qtXLxw/fhyPPPIIHn/8cUg93iQGoTeU7M1DEWMvf9ZOArcjwDFU//5BIeOjD0uWLImhQ4eie/fu6snw8HBUqFABERERKF68+HWlTZ06FSNHjsSBAwcQHBx8U01btmxB7dq11cxOlixZ1O8HDx6MHTt2qBkcbxKD0BtK9uWhiLGPPWsmAW8IcAz1hpKz81DI+OCf6Oho5MmTB1u3bkWNGjVSnpQloTlz5qBly5bXlda+fXucP39ezbrMnTsXBQoUQO/evdG3b1+VT2ZyHnvsMbU89dJLL+HYsWOqDPn9iy++mKZlsrQlz3mSBKHUn5CQkKZY8qF5zGowAYoYg4GyOBIwgQCFjAlQLS6SQsYH4DLrIqJEZlhKly6d8mSxYsUwduxYiHBJncLCwrBs2TKMHz9eCZjt27cr0TJx4kR06NBBZZ09ezZeeeUVnD17FiJSOnXqhOnTpyMwMO1NoMOHD8eIESNusppCxgdHWpCVIsYCyKyCBAwgQCFjAESbi6CQ8cEBUVFRal+MtzMybdq0wcaNG3H06NGUWvr166f2woiAWb58uZqB+f7779G8eXOcOXMGL7zwgtpLI5uJ00qckfHBYTZlXbD9OF7+eiu4sdcmB7BaEvCBAIWMD7AcmpVCxkfHyB6ZYcOGoVu3burJvXv3onz58mnukZGZk2nTpqnfeZIImcjISMyaNQsffvihWpJav359yu9l0/Bzzz2nlqS8SQxCbyhZl+fo+ct45OPVuBiXiPeerIr295awrnLWRAIk4DMBjqE+I3PcAxQyPrpEThPNmDEDixYtUrMzXbt2Vceq09qce/jwYVSsWBFjxoxRp5J27twJWW6aNGkS2rVrh7Vr16JZs2aYN2+e+i7LSyKQYmJi1JKUN4lB6A0la/LIpY4dPvsDGw6dw5M1i2Fcu3/2UVljAWshARLwlQDHUF+JOS8/hYyPPpGlnYEDB6qln/j4eLUkJKeT5D0yM2fORM+ePXHp0qWUUlesWIH+/furmRt5d4zMyPTp0yfl93KUW2ZmRPTIu2MaNWqkjmPLEW1vEoPQG0rW5Plk+X6MWRyO0HzZsPDVhsiV9eaTatZYwlpIgAS8JcAx1FtSzs1HIeNc33hlGYPQK0ymZ/ozIgpPTf4dV2UDd8/7ULtkXtPrZAUkQAIZJ8AxNOMM7S6BQsZuD2SwfgZhBgEa8HhMfCIenbAah85eRr+we9AvrJwBpbIIEiABKwhwDLWCsrl1UMiYy9f00hmEpiNOt4KB323HrE0RqFUij5qN4f1J6SJjBhJwDAGOoY5xxR0bQiFzx+ic8SCD0F4//LIjEr1nbkHOLEFqX0yJ/NntNYi1kwAJ+ESAY6hPuByZmULGkW7x3igGofesjM4ZGR2LFuNXIzr2CsY9Ux1P1rr+igqj62N5JEACxhPgGGo8U6tLpJCxmrjB9TEIDQbqZXEnouPw6jdb1VHrVtWLYkL7GgiQN+AxkQAJaEWAY6hW7krTWAoZzX3IILTWgdGXr+DTlfvx5dpDiE9MRrE82bCwb0Pkzsaj1tZ6grWRgDEEOIYaw9HOUihk7KRvQN0MQgMgelFEbEISvvj9IKas+BsX4hIRGAA8Vbs4XmtWHoVzZ/WiBGYhARJwIgGOoU70im82Ucj4xstxuRmEGXfJqQtxkEsek68CebIHIyRbMPLIV/bM6v8bD53Dx0v34dTFeFVZ88p3YUDz8ihbKFfGK2cJJEACthLgGGorfkMqp5AxBKN9hTAIM8b+0JkYdP7Pehw9H5tuQfXL5MPAFhVQswRfdpcuLGYgAU0IcAzVxFG3MZNCRnMfMgjv3IF7Ii/g2f9swJlL8RCRElbxLnUCKeryFUTFXlH/jr6cgBxZgtCz0d148J4C3NB757j5JAk4kgDHUEe6xSejKGR8wuW8zAzCO/PJ5sPn8PwXG9V+l4cr3YUJHWoia3CmOyuMT5EACWhLgGOotq5LMZxCRnMfMgh9d+DKvafRa8ZmxF5JQttaxfF+26p8G6/vGPkECfgFAY6h+ruRQkZzHzIIfXPgz9sj0W/WVlxJuornG5TCkEcrIVCOIDGRAAm4kgDHUP3dTiGjuQ8ZhN478NsNR/Dm3B3qdNJrzcrhlSZluefFe3zMSQJ+SYBjqP5upZDR3IcMQu8cuPfkRTQfvwpXrwIjHq+MLveX8u5B5iIBEvBrAhxD9XcvhYzmPmQQeufA/rP+xNytx9DzwTIY3LKidw8xFwmQgN8T4Biqv4spZDT3IYMwfQdGnLuMhz5cgaDAAKwZ2AQFc2VJ/yHmIAEScAUBjqH6u5lCRnMfMgjTd+CQeTsx44/DeLZ+Sbzbukr6DzAHCZCAawhwDNXf1RQymvuQQXh7B56+GI8H3v8NiclXseL1hxCaL7vmHqf5JEACRhLgGGokTXvKopCxh7thtTIIb4/y/UV/YfKKv9GmZjF81K6GYdxZEAmQgH8Q4Biqvx8pZDT3IYPw1g68EHcFDUb/hovxifi1/4ModxcvedS8u9N8EjCcAMdQw5FaXiCFjOXIja2QQXhrnp+u2I8PFoWrO5SmdaljLHiWRgIk4BcEOIbq70YKGc19yCBM24FxV5LU3pgzlxLww0v3oxZvrNa8p9N8EjCHAMdQc7haWSqFjJW0TaiLQZg21BnrDmHIj7tQr3Q+zOp5nwnkWSQJkIA/EOAYqr8XKWQ09yGD8GYHJiYlq/fGHD0fi6+63YtG5Qpq7mWaTwIkYBYBjqFmkbWuXAoZ61ibUhOD8Gasc7ceRf9Z21C5aAgWvPIA71MypeexUBLwDwIcQ/X3I4WM5j5kEF7vwOTkq2jx8SrsPXkJn3SshUerFdHcwzSfBEjATAIcQ82ka03ZFDLWcDatFgbh9WiX7D6JF6ZvQpkCObDktUbIFBhgGnsWTAIkoD8BjqH6+5BCRnMfMgivd2D7z9bhjwPn8H7bqmhXt4Tm3qX5JEACZhPgGGo2YfPLp5Axn7GpNTAI/8F76kIc6o1ehhyZg7Dp7TBkDc5kKnsWTgIkoD8BjqH6+5BCRnMfMgj/ceD0dYcw9MddaF2jKMa3r6m5Z2k+CZCAFQQ4hlpB2dw6KGTM5Wt66QzCfxC3m7oO6w+ew9Rna6N55cKms2cFJEAC+hPgGKq/DylkNPchg/CaA+WW63v/vRTZgzNh85BmXFbSvF/TfBKwigDHUKtIm1cPhYx5bC0pmUF4DfOMPw5jyLydeLx6UUzowGUlSzofKyEBPyDAMVR/J1LIaO5DBuE1B3b47A+sO3AWUzrXQosqfHeM5t2a5pOAZQQ4hlqG2rSKKGRMQ2tNwQxC4MyleNw7aqlaTtrCZSVrOh5rIQE/IcAxVH9HUsho7kMGITBz/WG8NXcnHqtWBJM61tLcozSfBEjASgIcQ62kbU5dFDLmcLWsVAYh0GnaH1i7/ywmd6qFR6pyWcmyzseKSMAPCHAM1d+JFDKa+9DtQXj2UjzqjlqKLEHXlpWyZeZL8DTv0jSfBCwl4PYx1FLYJlVGIWMSWKuKdXsQfrPhCAb/sAOPVi2CTzpxWcmqfsd6SMBfCLh9DPUHP1LIaO5Ftwfhs/9Zj9X7zvCma837Mc0nAbsIuH0MtYu7kfVSyBhJ04ay3ByE52IS1LJScKYAtayUPXOQDR5glSRAAjoTcPMYqrPfUttOIaO5J90chN9uOIJBP+zAI1UKY3Ln2pp7kuaTAAnYQcDNY6gdvM2ok0LGDKoWlunmIHzuvxuwau9pTOxQE62qF7WQOqsiARLwFwJuHkP9xYcUMpp70q1BGHU5AXVGLkWmwGvLSjmycFlJ865M80nAFgJuHUNtgW1SpRQyPoJNSkrCoEGD8OWXXyIuLg4tWrTAlClTkD9//jRLOnXqFAYMGIAFCxZAAqZMmTJYuHAhiha9NoOQmJiId999V5V35swZFC5cGJMmTcIjjzzilWVuDcLZGyPwxvfb0bzyXZj6bB2vWDETCZAACdxIwK1jqD/1BAoZH705atQofPXVV1i8eDHy5s2LLl26IDk5GfPnz7+pJBE6devWRf369TF69Gjky5cPe/bsQWhoKEJCQlT+Hj16YNeuXfjiiy9Qvnx5REZGIiEhAaVKlfLKMrcGYdcvNmBF+Gl83L4GnqhRzCtWzEQCJEACFDL+1wcoZHz0acmSJTF06FB0795dPRkeHo4KFSogIiICxYsXv660qVOnYuTIkThw4ACCg4NvqsnzrIgbKeNOkhuFTPTlK6gzagkCAq4tK+XkstKddB0+QwIkAKiZ8syZM6s/INMapwnJ+QQoZHzwUXR0NPLkyYOtW7eiRo0aKU/myJEDc+bMQcuWLa8rrX379jh//jxKlCiBuXPnokCBAujduzf69u2r8smS1MCBAzFixAiMHTtWfTC3atUK77//PnLmzJmmZbK0JTNAniRBKPW7KQg9p5WaVboLnz/HZSUfujCzkgAJ3ECAQkb/LkEh47nsK1AAACAASURBVIMPZdZFRInMsJQuXTrlyWLFiikhIsIldQoLC8OyZcswfvx4JWC2b9+u9tRMnDgRHTp0ULM1Q4YMUc/J7E1MTAyefPJJVKtWTf0/rTR8+HAlfG5MbhEySclX0eyjlThwOgZTOtdGiyqFffAgs5IACZDA9QQoZPTvERQyPvgwKipK7YvxdkamTZs22LhxI44ePZpSS79+/XD8+HHMnj0bH3/8MeT/+/btQ9myZVWeefPm4cUXX4RsEk4ruX1G5pcdkeg9cwvuLpgDS/o3QmBggA8eZFYSIAESoJDxtz5AIeOjR2WPzLBhw9CtWzf15N69e9Um3bT2yMjMybRp09TvPEmEi2zonTVrFlauXImHHnoI+/fvx913350iZHr27ImTJ096ZZmb/pq4evUqWk1ag53HLmDs09XRtvb1e5K8AsZMJEACJJCKgJvGUH91PIWMj56VU0szZszAokWL1OxM165d1WYxOV59Yzp8+DAqVqyIMWPGoFevXti5cydkuUmOV7dr107tdZG9Np6lJFlaklkc+f/kyZO9ssxNQbhy72l0+e8GFMuTDSsGPITgTIFeMWImEiABErgVATeNof7aCyhkfPSsLO3IBl1570t8fDyaN2+u9rPIe2RmzpwJmU25dOlSSqkrVqxA//791cyNvDtGZmT69OmT8nsRO7J/ZtWqVcidOzfatm2rjmrLBl5vkpuC8Jmp67Dh4Dm8+0RlPHufd8fTvWHIPCRAAu4l4KYx1F+9TCGjuWfdEoQbD53D01PWoUDOLFgzsDGyBmfS3HM0nwRIwAkE3DKGOoG1WTZQyJhF1qJy3RKEz3+xAcvDT2PQIxXQq9G1/URMJEACJJBRAm4ZQzPKycnPU8g42Tte2OaGINx1PBqPTliDkKxB+H1wU74Az4t+wSwkQALeEXDDGOodCX1zUcjo6ztluRuCsM/XW/Dz9ki82vQevNasnOYeo/kkQAJOIuCGMdRJvM2whULGDKoWlunvQXjg9CU0HbcS2YIzYe3AJsibI7OFdFkVCZCAvxPw9zHU3/0n7aOQ0dzL/h6Eb3y3DbM3HUWPB0rj7ccqae4tmk8CJOA0Av4+hjqNtxn2UMiYQdXCMv05CI9FxaLRB8sRGBCAVW80RuHcWS0ky6pIgATcQMCfx1A3+I8zMn7gZX8OwuE/7cKXvx9Ch3tLYPSTVf3AW2wCCZCA0wj48xjqNNZm2eOqGZm1a9eiePHikGsG5C6jN954A0FBQXjvvffUzdQ6Jn8Nwm0RUWj32TokJCZj+esPoWR+714QqKMPaTMJkIB9BPx1DLWPqPU1u0rIyKv/f/jhB3VB4/PPP68uc8yaNSuyZ8+u7j7SMfljEO44Go1O0/7AhbhEPN+gFIa1qqyja2gzCZCABgT8cQzVALuhJrpKyMjdSOfPn4dcPlioUCHs2rVLiZgyZcrc8rZpQ2mbUJi/BeHOYyJi1iM69gqeql0cH7StxhuuTeg3LJIESOAaAX8bQ93oV1cJGVk+kpuo9+zZgy5dumDHjh3q4ka54+jixYta+t+fgnD38QvoOO0PRF2+gidrFsOYp6sjU2CAln6h0SRAAnoQ8KcxVA/ixlvpKiHzzDPPIDY2FmfPnkXTpk3x7rvvIjw8HI899hj27dtnPF0LSvSXINwTeQEdP/8D5y9fQesaRTH2mRoUMRb0H1ZBAm4n4C9jqJv96CohExUVhTFjxiBz5sxqo2+2bNmwYMEC/P333+jbt6+W/cAfgjD8xEV0+PwPnItJwOPVi+KjdhQxWnZGGk0CGhLwhzFUQ+yGmuwqIWMoOYcUpnsQ7jt5Ee0/+wNnYxLwWLUiGN+uBoIyBTqELs0gARLwdwK6j6H+7h9v2uf3Quadd97xhgOGDh3qVT6nZdI9CJ+YtAbbjkajZdXCmNC+JkWM0zoY7SEBPyeg+xjq5+7xqnl+L2SaNWuWAkJOK61atQqFCxdW75I5fPgwTpw4gUaNGmHJkiVeAXNaJp2D8PDZGDQaswL5c2TGusFNkTmIMzFO61+0hwT8nYDOY6i/+8bb9vm9kEkN4rXXXlMvvhs8eDACAq6dhhk9ejTOnDmDsWPHesvMUfl0DsJPV+zHB4vC0bFeCfy7Dd/c66iORWNIwCUEdB5DXeKidJvpKiFTsGBBREZGqrf5elJiYqKaoRExo2PSOQgfm7gaO49dwMwe9dCgrJ5vVtaxz9BmEiCBfwjoPIbSj9cIuErIhIaGYv78+ahRo0aK/7du3YpWrVqpt/zqmHQNwtTLSuvfbMq9MTp2PtpMAn5AQNcx1A/QG9YEVwkZWUb6+OOP0bNnT5QqVQqHDh3CZ599hldeeQVvvvmmYVCtLEjXIOSykpW9hHWRAAncioCuYyg9+g8BVwkZafb06dMxY8YMHDt2DMWKFcOzzz6L5557Tts+oWsQPjphNXYdv4Cve9TD/VxW0rb/0XAS0J2ArmOo7tyNtN81QiYpKQnfffcdWrdujSxZshjJ0NaydAzCQ2di8NCH104rcVnJ1u7DyknA9QR0HENd77QbALhGyEi7c+XKpe2dSv40LfrJ8v0YszgcneqVwCieVuKYRAIkYCMBChkb4RtUtauETJMmTTB+/HhUq1bNIHz2F6NjEHJZyf5+QwtIgASuEdBxDKXvrifgKiEzcuRIfP7552qzr7wQz/MuGUHSsWNHLfuGbkHIZSUtuxmNJgG/JaDbGOq3jshAw1wlZEqXLp0mKhE0Bw4cyABG+x7VLQi5rGRfX2HNJEACNxPQbQylD28m4Coh448dQLcg5LKSP/ZCtokE9CWg2xiqL2nzLKeQMY+tJSXrFISeZaUCOTPjj8F8CZ4lHYSVkAAJ3JaATmMoXZk2AVcJmdjYWMg+mWXLluH06dOQSyQ9iUtL5ocIl5XMZ8waSIAEfCNAIeMbLyfmdpWQ6dWrF9asWYPevXtj4MCBeP/99zFp0iR06tQJb7/9thP9k65NOgVhy49XY3fkBXz9Qj3cfzfvVkrXucxAAiRgOgGdxlDTYWhagauEjLzJd/Xq1ShTpgzy5MmDqKgo7N69W11RILM0OiZdgvDgmRg0/nAFZFlp/ZthyBR47fZxJhIgARKwk4AuY6idjJxet6uETO7cuREdHa18UqhQIXVRZObMmRESEoILFy443Vdp2qdLEHqWlTrXL4GRratqyZpGkwAJ+B8BXcZQ/yNvXItcJWTk1utvvvkGFStWxIMPPqjeHSMzMwMGDEBERIRxVC0sSZcg5LKShZ2CVZEACXhNQJcx1OsGuTCjq4TMrFmzlHBp3rw5lixZgjZt2iA+Ph6TJ09Gjx49tHS/DkHIZSUtuxaNJgFXENBhDHWFIzLQSFcJmRs5SQdOSEhAjhw5MoDQ3kd1CEKeVrK3j7B2EiCBWxPQYQyl/25PwFVCRk4pPfzww6hZs6bf9AsdgrDVxDXYcSwaX/eoh/vL8rSS33Q+NoQE/ICADmOoH2A2tQmuEjKPP/44Vq5cqTb4ygWSYWFhaNasGUqVKmUqZDMLd3oQRpy7jIYfLEfe7MHY+FYYgjIFmomDZZMACZCATwScPob61BiXZnaVkBEfJyUlYf369Vi6dKn62rBhA0JDQ7Fv3z4tu4DTg3Da6gMY+fMePFOnOD54qrqWjGk0CZCA/xJw+hjqv+SNa5nrhIyg27FjB3799Ve14XfdunWoUqUK1q5daxxVC0tyehC2nfw7Nh8+jy+61kXjCoUsJMOqSIAESCB9Ak4fQ9NvAXO4Ssg8++yzahYmb968allJvho3boxcuXJp2xOcHIQnL8Sh3r+XIVeWIGwaEoYsQZm05UzDSYAE/JOAk8dQ/yRufKtcJWSyZ8+O4sWLQwSNiJh69eohMFDvPRtODsLp6w5h6I+70LpGUYxv7z8brI0PQ5ZIAiRgFwEnj6F2MdGtXlcJGTlqLXctefbH/P3332jYsKHa8NunTx/dfKfsdXIQdvjsD6w7cBZTOtdGiyqFteRLo0mABPybgJPHUP8mb1zrXCVkUmMLDw/H7NmzMXbsWFy8eFFtAtYxOTUIz16KR91RS9Vy0pYhzZAtM5eVdOxftJkE/J2AU8dQf+duZPtcJWTkzb6ywVe+Tp48qZaWmjZtqmZk7rvvPiO5WlaWU4Nw1sYjGPj9DrSsWhifdqptGQ9WRAIkQAK+EHDqGOpLG9ye11VCplq1aimbfBs1aqT1G309HdepQdj1iw1YEX4aEzrUxOPVi7o9zth+EiABhxJw6hjqUFyONMtVQsYID8gS1KBBg/Dll18iLi4OLVq0wJQpU5A/f/40iz916pS6lHLBggVqP0uZMmWwcOFCFC16/Ye73MRduXJlFCxYEPv37/faVCcGYXTsFdQZuQQBAQFqWSlnliCv28OMJEACJGAlASeOoVa23x/qcp2Qkc2+06dPR2RkJObPn4/NmzcjJiZG3YbtTRo1ahS++uorLF68WB3j7tKlC5KTk1VZNyYROnXr1kX9+vUxevRo5MuXD3v27FEv4AsJCbkuuwgiCajDhw9rL2Tmbj2K/rO2IaxiIUzrUtcbrMxDAiRAArYQoJCxBbuhlbpKyHz99dd4+eWX0blzZyVGoqOjsWXLFrz22mtYsWKFV2BLliyJoUOHonv37iq/bBquUKECIiIi1NHu1Gnq1KkYOXIkDhw4gODg4FuW//nnn2Pu3Ll45plnVH7dZ2RenL4Jv+4+iQ+fro6nal/PxCvIzEQCJEACFhGgkLEItInVuErIyNKNCJg6deqo2ZTz58+r26+LFSuG06dPp4tZhE+ePHmwdetW1KhRIyW/3J49Z84ctGzZ8roy2rdvr+ooUaKEEioFChRA79690bdv35R8R44cQYMGDdQbhuVYeHpCRpa2ZAbIkyQIpX5px+3EUrqNMyhDTHwiar27BEnJV7H57WbInf3WAs6gKlkMCZAACdwxAQqZO0bnmAddJWQ84kXoyzLPuXPnlCgQgSH/Ti/JrIuIEplhKV26dEp2EUJyjFuES+okL91btmwZxo8frwTM9u3b1Z6aiRMnokOHDiqrnJh66qmn0LNnT7XvJj0hM3z4cIwYMeImU50iZH7eHok+X29Bw3sKYEb3eukh5e9JgARIwFYCFDK24jekclcJGZmJmTBhAu6///4UISN7ZmQzrsyIpJeioqLUTI63MzJt2rTBxo0bIRt5Palfv344fvy4eoeNLD3JkXARO7Ix1hsh4/QZmZe/3oIF2yPx7zZV0bFeifSQ8vckQAIkYCsBChlb8RtSuauEzLx58/DCCy+opZ33338fMrshsyWfffYZHnnkEa+Ayh6ZYcOGoVu3bir/3r17Ub58+TT3yMjMybRp09TvUgsZ2WgsAqZ169ZYvnw5smXLpn4dGxurNh7LDJGcbKpVq1a6NjkpCOOuJKH2u0tw+UoSNrwZhoK5sqRrPzOQAAmQgJ0EnDSG2slB57pdI2RkJuO7775T+0lkJuTgwYMoVaqUEjWyvONtklNLM2bMwKJFi9TsTNeuXdVpIzlefWOSE0gVK1bEmDFj0KtXL+zcuVO9x2bSpElo164dZIZHTjZ5kogbEVYyOyTHub3Z8+KkIFy6+yR6TN+Ee0vnw+yeer5g0Nt+wHwkQAL+QcBJY6h/ELW+Fa4RMoJWbrmW6wgykkQQDRw4UC0DxcfHo3nz5koYifCYOXOm2uty6dKllCrkNFT//v3VzI28O0aWlm51r5M3S0s32u6kIPzX7G34fstRDGtVCc83+GcPUUZ481kSIAESMJOAk8ZQM9vpz2W7Ssg0adJEzXjIG379JTklCK8kJaPOyKWQl+GtG9wERXJfWy5jIgESIAEnE3DKGOpkRk63zVVCRk4EyTtbZNZE9rrIBltP6tixo9N9laZ9TgnCncei8djENahUJAQL+zbUkiWNJgEScB8Bp4yh7iNvXItdJWRSH5lOjVAEjRyp1jE5JQjnbT2GfrP+RNtaxTH2meo6oqTNJEACLiTglDHUhegNa7KrhIxh1BxUkFOC8INFf+HTFX9j8CMV0LPR3Q4iRFNIgARI4NYEnDKG0kd3ToBC5s7ZOeJJpwThC9M3Ycnuk/hv1zpoUuEuR7ChESRAAiSQHgGnjKHp2cnf35oAhYzmvcMpQdj4wxU4eCYGq99ojNB82TWnSvNJgATcQsApY6hbeJvRTgoZM6haWKYTglBehFdp6CJkCcqEXSOaIzDwn03UFqJgVSRAAiTgMwEnjKE+G80HriNAIaN5h3BCEO4+fgEtJ6xG1WK5Mf+VBzQnSvNJgATcRMAJY6ibeJvRVgoZM6haWKYTgvDHP4+h77d/4smaxTCu3T+3gluIgVWRAAmQwB0RcMIYekeG86EUAhQymncGJwThh4vDMWn5fgxsUQG9H+KJJc27FM0nAVcRcMIY6irgJjSWQsYEqFYW6YQg7DljExbvOolpz9VBWCWeWLLS/6yLBEggYwScMIZmrAV8mkJG8z7ghCBsMnYFDpyOwcoBD6Fk/hyaE6X5JEACbiLghDHUTbzNaCuFjBlULSzT7iCMT5QTS4sRnCkAu0a0QCaeWLLQ+6yKBEggowTsHkMzaj+fByhkNO8FdgfhXycuoMX41ahcNAQ/v8o7ljTvTjSfBFxHwO4x1HXATWgwhYwJUK0s0u4gnL/tOF75Zita1yiK8e1rWtl01kUCJEACGSZg9xia4QawAM7I6N4H7A7Ccb+GY8Jv+zGgeXn0aVxWd5y0nwRIwGUE7B5DXYbblOZyRsYUrNYVancQ9v6/zfhl5wl89mxtPFy5sHUNZ00kQAIkYAABu8dQA5rg+iIoZDTvAnYHYdi4ldh/6hKWv/4QShfgiSXNuxPNJwHXEbB7DHUdcBMaTCFjAlQri7QzCBMSk9UdS3K30p53eGLJSr+zLhIgAWMI2DmGGtMClkIho3kfsDMI9568iIc/WoWKRULwS1+eWNK8K9F8EnAlATvHUFcCN6HRFDImQLWySDuD8Oftkejz9RY8Xr0oJnTgiSUr/c66SIAEjCFg5xhqTAtYCoWM5n3AziD8aMlefLxsH15/uBxebnKP5iRpPgmQgBsJ2DmGupG3GW2mkDGDqoVl2hmEfWZuwc87IjGlc220qMITSxa6nVWRAAkYRMDOMdSgJri+GAoZzbuAnUHYbNxK7Dt1Ccv+1Qh3F8ypOUmaTwIk4EYCdo6hbuRtRpspZMygamGZdgXhlaRkVByyCIEBAdj9TnMEZQq0sNWsigRIgASMIWDXGGqM9SxFCFDIaN4P7ArC/acuImzcKlQonAuL+j2oOUWaTwIk4FYCdo2hbuVtRrspZMygamGZdgXhwh2ReGnmFjxWrQgmdaxlYYtZFQmQAAkYR8CuMdS4FrAkChnN+4BdQfjx0n34aOlevNasHF5tyhNLmncjmk8CriVg1xjqWuAmNJxCxgSoVhZpVxC+/PUWLNgeicmdauGRqkWsbDLrIgESIAHDCNg1hhrWABbEPTK69wG7grD5R6sQfvIilr72IMoWyqU7RtpPAiTgUgJ2jaEuxW1KszkjYwpW6wq1IwgT5cTS0EWqkbvfaYFgnliyzuGsiQRIwFACdoyhhjaAhXFGRvc+YEcQ/n36EpqOXYlyd+XEr/0b6Y6Q9pMACbiYgB1jqItxm9J0zsiYgtW6Qu0IwkU7I9Hr/7bg0apF8EknnliyztusiQRIwGgCdoyhRrfB7eVRyGjeA+wIwonL9mHskr3oF3YP+oWV05wgzScBEnAzATvGUDfzNqPtFDJmULWwTDuC8NVvtuKnbcfxScdaeLQaTyxZ6G5WRQIkYDABO8ZQg5vg+uIoZDTvAnYEYYvxq/DXiYv4tf+DKHcXTyxp3oVoPgm4moAdY6irgZvQeAoZE6BaWaTVQSgnlioNW4zk5KvqxFLmIN6xZKW/WRcJkICxBKweQ421nqUJAQoZzfuB1UF48EwMGn+4AmUL5cTS13hiSfPuQ/NJwPUErB5DXQ/cBAAUMiZAtbJIq4Nw8a4T6DljMx6pUhiTO9e2sqmsiwRIgAQMJ2D1GGp4A1ggZ2R07wNWB+Eny/djzOJwdb+S3LPERAIkQAI6E7B6DNWZlVNt54yMUz3jpV1WB2G/b7di3p/HMbFDTbSqXtRLK5mNBEiABJxJwOox1JkU9LaKQkZv/8HqIHx0wmrsOn4Bi/o1RIXCIZrTo/kkQAJuJ2D1GOp23ma0n0LGDKoWlmllEMpJpcrDFiM+MUmdWMoanMnClrIqEiABEjCegJVjqPHWs0QhQCGjeT+wMgiPRcWiwXu/oWT+7Fg5oLHm5Gg+CZAACcDyWW0yN54AhYzxTC0t0Uohs2rvaTz33w1oUqEQ/tu1rqXtZGUkQAIkYAYBK8dQM+xnmZyR0b4PWBmEX6w9iBHzd+OFhqXx1qOVtGfHBpAACZCAlWMoaZtDgDMyPnJNSkrCoEGD8OWXXyIuLg4tWrTAlClTkD9//jRLOnXqFAYMGIAFCxaoKcwyZcpg4cKFKFq0KPbu3Ys333wT69atw4ULF1CiRAn0798fPXr08NoqK4Pw7Xk78H9/HMF7T1ZF+3tLeG0jM5IACZCAUwlYOYY6lYHudlHI+OjBUaNG4auvvsLixYuRN29edOnSBcnJyZg/f/5NJYnQqVu3LurXr4/Ro0cjX7582LNnD0JDQxESEoL169dj06ZNaNOmDYoUKYLVq1ejVatWmD59Op544gmvLLMyCDt89gfWHTiLOb3uQ91S+byyj5lIgARIwMkErBxDncxBZ9soZHz0XsmSJTF06FB0795dPRkeHo4KFSogIiICxYsXv660qVOnYuTIkThw4ACCg4O9qklETenSpTFu3Div8lsZhPeOWopTF+OxZUgz5MuR2Sv7mIkESIAEnEzAyjHUyRx0to1CxgfvRUdHI0+ePNi6dStq1KiR8mSOHDkwZ84ctGzZ8rrS2rdvj/Pnz6slo7lz56JAgQLo3bs3+vbtm2atMTExKFu2LN577z0105NWkqUtmQHyJAlCqT8hIcFrseRDk1OyXoi7gmrDf0We7MH4c+jDd1IEnyEBEiABxxGgkHGcS3w2iELGB2Qy6yKiRGZYZNbEk4oVK4axY8dChEvqFBYWhmXLlmH8+PFKwGzfvl3tqZk4cSI6dOhwXd7ExEQ89dRTiIqKwtKlSxEUFJSmZcOHD8eIESNu+p3ZQubPiCi0/mQtapfMi+973+8DNWYlARIgAecSoJBxrm+8tYxCxltSgBIZsi/G2xkZWSbauHEjjh49mlJLv379cPz4ccyePTvlZyJCRASdPn1abQTOlSvXLa2ya0bm+81H8a852/BMneL44KnqPlBjVhIgARJwLgEKGef6xlvLKGS8JfW/fLJHZtiwYejWrZv6iZw8Kl++fJp7ZGTmZNq0aep3niRCJjIyErNmzVI/io2NxZNPPqmWhn766Se1TORLsioIP1j0Fz5d8TcGP1IBPRvd7YuJzEsCJEACjiVg1RjqWAB+YBiFjI9OlFNLM2bMwKJFi9TsTNeuXdWxajlefWM6fPgwKlasiDFjxqBXr17YuXMnZLlp0qRJaNeuHS5duoTHHnsM2bJlU3tosmbN6qM11r2VsueMTVi86ySmPVcHYZXu8tlOPkACJEACTiRAIeNEr/hmE4WMb7wgSzsDBw5U75GJj49H8+bNIaeT5D0yM2fORM+ePZVA8aQVK1aod8PIzI28O0ZmZPr06aN+Lce4RQiJkAkMDEx5pnPnzurdNN4kq4IwbNxK7D91CctffwilC/g2a+RNO5iHBEiABOwgYNUYakfb3FInhYzmnrYiCBOTklFx6CJFas87LRCU6R/RpTk+mk8CJOByAlaMoS5HbHrzKWRMR2xuBVYE4cEzMWj84QrcUygnlrzWyNwGsXQSIAESsJCAFWOohc1xZVUUMpq73YogXLr7JHpM34QWlQtjyrO1NSdG80mABEjgHwJWjKHkbS4BChlz+ZpeuhVBOHXl3xj9y1/o0/huDGhewfQ2sQISIAESsIqAFWOoVW1xaz0UMpp73oogfOO7bZi96SjGPVMdT9a6/hoGzfHRfBIgAZcTsGIMdTli05tPIWM6YnMrsCII207+HZsPn8ePfRqgemgecxvE0kmABEjAQgJWjKEWNseVVVHIaO52s4Pw6tWrqPHOEkTHXsGO4Q8jV1bvLr/UHCvNJwEScAkBs8dQl2C0tZkUMrbiz3jlZgfh2UvxqD1yKe4KyYL1b4Zl3GCWQAIkQAIOImD2GOqgpvqtKRQymrvW7CDccPAcnpm6DvffnR9fv1Bfc1o0nwRIgASuJ2D2GEre5hOgkDGfsak1mB2E32w4gsE/7EDn+iUwsnVVU9vCwkmABEjAagJmj6FWt8eN9VHIaO51s4Nw5ILdmLbmIIa1qoTnG5TWnBbNJwESIAHOyPhbH6CQ0dyjZguZ57/YgOXhpzG92714sFxBzWnRfBIgARKgkPG3PkAho7lHzRYyD36wHEfOXcbaQU1QLE82zWnRfBIgARKgkPG3PkAho7lHzRQycVeS1GWRWYMyYdeI5ggMDNCcFs0nARIgAQoZf+sDFDKae9RMIfPXiQtoMX41KhcNwc+vNtScFM0nARIggZsJmDmGkrc1BChkrOFsWi1mBuHP2yPR5+steLx6UUzoUNO0NrBgEiABErCLgJljqF1tclu9FDKae9zMIJywbB/GLdmL/mHl0DfsHs1J0XwSIAES4IyMP/YBChnNvWqmkOn77Vb8+OdxTOpYE49VK6o5KZpPAiRAAhQy/tgHKGQ096qZQqbVxDXYcSwav/RtiIpFQjQnRfNJgARIgELGH/sAhYzmXjVLyMhlkZWHLUbslSTseacFsgZn0pwUzScBEiABChl/7AMUMpp71SwhExkdi/tG/4bQfNmw+o0mmlOi+SRAAiSQNgGzxlDyto4AhYx1rE2pyawgXLPvDDr/3j33oQAAHnRJREFUZz0eKl8QXz5/rym2s1ASIAESsJuAWWOo3e1yU/0UMpp726wg/Or3Qxj20y50f6A0hjxWSXNKNJ8ESIAEOCPjr32AQkZzz5olZIb+uBPT1x3Gv9tURcd6JTSnRPNJgARIgELGX/sAhYzmnjVLyHSa9gfW7j+Lb1+sj/pl8mtOieaTAAmQAIWMv/YBChnNPWuWkKn/72U4cSEOG98KQ8FcWTSnRPNJgARIgELGX/sAhYzmnjVDyFyKT0SVYYsRkjUI24Y9jIAAXhapeTeh+SRAArcgYMYYStjWEqCQsZa34bWZEYTbj0bh8UlrUbNEHsx9qYHhNrNAEiABEnAKATPGUKe0zS12UMho7mkzgnDu1qPoP2sbnqpdHB8+XV1zQjSfBEiABG5NwIwxlLytJUAhYy1vw2szIwgHfb8d326MwNuPVkSPhmUMt5kFkgAJkIBTCJgxhjqlbW6xg0JGc08bHYQJicmoO2opomOvYPUbjRGaL7vmhGg+CZAACXBGxp/7AIWM5t41Wsgs3X0SPaZvQq0SefAD98do3jtoPgmQQHoEjB5D06uPvzeeAIWM8UwtLdHoIHz1m634adtxDG9VCV0blLa0LayMBEiABKwmYPQYarX9rA+gkNG8FxgZhJcTElH73aWIT0zC+jf5/hjNuwbNJwES8IKAkWOoF9UxiwkEKGRMgGplkUYGoczEyIzMA2UL4P961LOyGayLBEiABGwhYOQYaksDWClnZHTvA0YGYY+vNmHpnpP4oG01PFM3VHc0tJ8ESIAE0iVg5BiabmXMYAoBzsiYgtW6Qo0KwujLV1Bn1BIEIAAb3w5D7mzB1jWCNZEACZCATQSMGkNtMp/VgntktO8ERgXhrI1HMPD7HWhW6S58/lwd7bmwASRAAiTgDQGjxlBv6mIecwhwRsYcrpaValQQem67ntihJlpVL2qZ/ayIBEiABOwkYNQYamcb3F43hYzmPcCIIDx1MQ5y23XW4EzY/HYzZMucSXMqNJ8ESIAEvCNgxBjqXU3MZRYBChmzyFpUrhFB+MXagxgxfzeeqFEUH7evaZHlrIYESIAE7CdgxBhqfyvcbQGFjOb+NyII23y6FluPROE/XeqgacW7NCdC80mABEjAewJGjKHe18acZhCgkDGDqoVlZjQII85dRsMPlqtTShvfCkPmoEALrWdVJEACJGAvgYyOofZaz9qFAIWM5v0go0H4yfL9GLM4HB3uDcXoJ6tpToPmkwAJkIBvBDI6hvpWG3ObQYBCxgyqFpaZ0SBsMX4V/jpxEV+/UA/3313AQstZFQmQAAnYTyCjY6j9LaAFFDKa94GMBOHekxfx8EerUChXFqwb3BSZAgM0p0HzSYAESMA3AhkZQ32ribnNIkAh4yPZpKQkDBo0CF9++SXi4uLQokULTJkyBfnz50+zpFOnTmHAgAFYsGABJGDKlCmDhQsXomjRa+9q2b9/P3r16oV169Yhb968eP3119GvXz+vrcpIEH64OByTlu9HtwalMbRVJa/rZEYSIAES8BcCGRlD/YWB7u2gkPHRg6NGjcJXX32FxYsXK+HRpUsXJCcnY/78+TeVJEKnbt26qF+/PkaPHo18+fJhz549CA0NRUhICEQUValSBc2aNcN7772H3bt3K2E0depUtG3b1ivL7jQIr169ikZjVuDIucuY16cBaoTm8ao+ZiIBEiABfyJwp2OoPzHQvS0UMj56sGTJkhg6dCi6d++ungwPD0eFChUQERGB4sWLX1eaCJKRI0fiwIEDCA6++e6i5cuX49FHH4XM2uTMmVM9O3jwYGzatAlLlizxyrI7DcI/I6LQ+pO1KJk/O1a8/hACAris5BVwZiIBEvArAnc6hvoVBM0bQyHjgwOjo6ORJ08ebN26FTVq1Eh5MkeOHJgzZw5atmx5XWnt27fH+fPnUaJECcydOxcFChRA79690bdvX5Vv/Pjxaonqzz//THlOyunTp48SN2klmcWRGSBPkiCU+hMSEtIUS7dq3sW4K/hlxwm1L6Zt7esFmA9ImJUESIAEtCZAIaO1+5TxFDI++FBmXUSUyAxL6dKlU54sVqwYxo4dCxEuqVNYWBiWLVumBIsImO3bt6ulo4kTJ6JDhw549913sXTpUqxcuTLlMZmJadWqldp/k1YaPnw4RowYcdOvfBUyPjSbWUmABEjAbwlQyOjvWgoZH3wYFRWl9sV4OyPTpk0bbNy4EUePHk2pRTbyHj9+HLNnz7Z1RsaHZjMrCZAACfgtAQoZ/V1LIeOjD2WPzLBhw9CtWzf15N69e1G+fPk098jIzMm0adPU7zxJhExkZCRmzZoFzx6Z06dPq+UhSW+++aYSP2bvkfGx2cxOAiRAAn5JgEJGf7dSyPjoQzm1NGPGDCxatEjNznTt2lUdq5bj1Temw4cPo2LFihgzZow6Yr1z507IctOkSZPQrl27lFNLzZs3V6ea5EST/Hvy5Ml46qmnvLKMQegVJmYiARIggTQJcAzVv2NQyPjoQ9lsO3DgQLVJNz4+XgkPOZ0k75GZOXMmevbsiUuXLqWUumLFCvTv31/N3Mi7Y2RGRjbzepK8R0aeSf0eGcnvbWIQekuK+UiABEjgZgIcQ/XvFRQymvuQQai5A2k+CZCArQQ4htqK35DKKWQMwWhfIQxC+9izZhIgAf0JcAzV34cUMpr7kEGouQNpPgmQgK0EOIbait+QyilkDMFoXyEMQvvYs2YSIAH9CXAM1d+HFDKa+5BBqLkDaT4JkICtBDiG2orfkMopZAzBaF8h8kbfLFmyICYmxqcrCuyzmDWTAAmQgHMIeK55kVOomTNndo5htMRrAhQyXqNyZsbLly+nvEzPmRbSKhIgARJwPgH5YzB79uzON5QW3kSAQkbzTiEXSMq9TEFBQWneYO35a8NfZmzYHmd3WH/zj9D2tzaxPdfH0NWrV5GYmIisWbMiMDDQ2QFG69IkQCHj5x3D39Z/2R5nd1h/849HyMiSg79czOpvPvK39jg7wp1pHYWMM/1imFX+FuRsj2Fdw5SC/M0/FDKmdBNDC/XHPmcoIBcURiHj5072tyBne5zdYf3NPxQyzu5v/ugf5xN3noUUMs7ziaEWyd1Q7777LoYMGYJMmTIZWrYdhbE9dlD3vk5/84+03N/axPZ435+ZUw8CFDJ6+IlWkgAJkAAJkAAJpEGAQobdggRIgARIgARIQFsCFDLauo6GkwAJkAAJkAAJUMiwD5AACZAACZAACWhLgEJGW9elb7hs6hs0aBC+/PJL9dK8Fi1aYMqUKcifP3/6Dxuco2vXrpg5c6a6TsGTPvjgA7z00ksp/58+fTpGjBiByMhIVKtWTdlao0aNlN9v2rRJ5d+5cyeKFCmCkSNHokOHDim/P3XqFHr16oUlS5YgW7Zs6N69O0aNGpXykquM8Pj222/xySefYNu2bZC3KcsLtFKnRYsW4V//+hcOHDiAu+++Gx9//DGaNm2akmX//v3KtnXr1iFv3rx4/fXX0a9fv5TfS5kvv/wy5s6dC3lB19NPP42JEyeql3R50pgxYzB+/HhERUWhQYMG+Oyzz1CqVKmU36dnQ2p7b9eeFStWoHHjxte9MVr88fvvvzu2PQMHDsSCBQtw5MgRhISEoGXLlnj//feRL18+R/Wv9Pq4x9j02iMx3a1bt+veRNuqVSt88803lsaLt+0Ro9566y18/fXXOHfunBoHHnzwQYwbNw4lSpRQNqdXlhXxn54NBg+LLM4gAhQyBoF0YjHyIf7VV19h8eLF6sOzS5cukDcBz58/33JzRcjI24enTZuWZt1r1qxB8+bN8eOPP6Jhw4YYO3as+iDft28fcubMiejoaJQtWxYDBgxA3759sXz5crRt21Z9v/fee1WZzZo1Ux9iX3zxBUTUSHkifERgSMoID2EoA3BsbCxefPHF64SMiJcqVarg888/VwJERILUu2fPHoSGhqpTL/J7se+9997D7t27laicOnWqaoOkF154Qf3cI2Qef/xx1S5hIElEYP/+/ZUvy5UrpzisXbsWW7duVUItPRtuhH679oiQCQsLu0msecpwYnvefPNNxV44nz9/Hp07d1ZCTHhKckL/Ss+G1D5Krz0iZETIi0BOK1kRL760R2z866+/1B8guXPnVn8MvP322/jjjz+UQE6vLCe2x/JBlBXekgCFjB93jpIlS2Lo0KFqZkJSeHg4KlSogIiICBQvXtzSlqcnZDwia8aMGcouEVwiAmTWplOnTkqcDBs2DIcPH065ikFmY0TkiIA4ePAgypQpowZ2mRGRJELhww8/VGJIkhE80vqQF7t+++03rF69OoXpfffdh8cee0z9FSpi69FHH1XiSuyVNHjwYMhfmDJ7JOJIZg5kRsEziyNCQ0SOiCd5q2yjRo3UX7BylF7ShQsXUKhQISxbtkzNzqRnw62cnVZ70hMyTm6Pp50iiJ9//nnFT5IT+ld6NtwuIG9sT3pCxop4yUh75MoU6bNi59mzZ7X3j6WDKSu7iQCFjJ92CvkLJk+ePOov9tTLM/JX6pw5c9TUu5VJhIwMxgEBAShQoACeeOIJNZB5PtjFRsmTerlFPvwrV66sxIz8/NChQ5g3b16K2bLUIm3ZsGGD+rk8L8sunrRx40Y1q3Hp0iU1u2AEj7Q+5Fu3bq2WeGTZx5P69OmD06dPY/bs2ern8sHz559/pvxe7JY8Im7k5zVr1lQzCWKjJHlWhMquXbtQqVIl9XMpQ+ryJGEjZcjsT3o2+CpkZGlJxK684K527dr497//jerVq6tinNweTztfffVV7NixQ4lISU7oX+nZcLt4vLE90hd69uypZlqDg4OVmB09ejRKly6tirEiXu6kPbK01Lt3byXEZYb2o48+Ukuq6ZXl1PZYOYayrlsToJDx094hsy6y9ixLDp7BTZparFgxtWzTvn17S1u+efNm9cFYsGBBteQify3LzIlnTV/+LVPN8nNPkpmYXLlyqb0yMqskYkSWyjxJZmKkLTJlLTM58rzM2HiSzMTIMozsuZEPZCN4pCVkZBblgQceUPt7PElmYqTNsm9FZlGWLl2KlStXpvxeZmJkT4PsXZKZHJltkVkoEXqSPG/IlT019evXVy8zlDJEYHiSfHhJGbIPKj0bfBEyJ06cwMmTJ5WIFBEoe01kP44Ig6JFizq6PdLOWbNmqaU64eoRX07oX+nZcCsfpdUeiWuJB1luFTEsfUCWZ2QPl/yxYkW83Gl7pJ3Sx/7zn/8oAfbQQw+pscDu+E/PBksHTFbmEwEKGZ9w6ZNZZibkrzWnzMjcSE72d8gAJh+UsvHP7L/IRBgYwcMNMzJp9fJ77rlHfVjKB6STZ2REGMsslczQiTj0JCf0r/RsSIv7rdpzY17p37L3RPa/iajN6AyGN/FyJ+1JbbcIMFkOlg3aTZo0MXVG1or26PPp4H+WUsj4n09TWiR7QmT5Rk43SNq7dy/Kly9vyx6ZGzHLTIN80Fy8eFGdzJH1djmtI6cGJMm/ZY+MzAZ49sgMHz78uhmXjh07qr8+U++R+fvvv9XgKElmEWT5KfUemYzyuNUeGVnCWLVqVUoz77//frUvJvUeGVkuEnslyWZOWfpKvUfm559/VgO6pF9//RVPPvnkdXtkZJ/MO++8o36f1h6Z29lwq26e3n4Yz3PSb2SDcY8ePVL2/DitPfIX/htvvAHhKLNYqZMT+ld6Ntzoo9u158a8MjsjQkaWb2Wjtuw9MTtefG3PjTYfP35czRDLTJ/Eqd3xn9H2+PFHieObRiHjeBfduYFySkeWXGR5Q2YjZA+J/GUim0qtTnKSR07qyF4PERYyaMgJhu+//16ZItPi8vuffvpJTTfL2rkcYfacWpIZJpkVkGOpsl9AlmnatGmjNtmmPrUk5csHgHzISnmyj0COOkvKCA85qSPsRKzI/iKZSZIks0kyzV+1alX897//VRt0ZSlAjlrLKSRZzvKc8pFTVLKPQZbW5N+TJ0/GU089pcqRpRD5uZyykSUm2fMie1MmTZqkfi+nll577TUlcISDfGDL0onn1JIIuNvZcKO/b9ceEURitwhCOV0iG6ZlFkY+cFKfwnJSeyZMmKBEnmySFm43Jif0r/RsSG1zeu0RsSbLZiIEZG+VbB6XOJc9VbLvzIp48aU90qc//fRTtGvXTi0vHz16FK+88oraHyYxLqeX7I5/X9pj9fjJ+m5PgELGj3uIfFjJB79sDIyPj1cfnnKSx473yMgy0vbt25UdsolVRIj8xSjHpT1JZmPkZ6nfIyObYD1JZjBk2UA+UEUEiTC51XtkRGDI7IFsUpXjyZIywkMYpt6/47FJTkvJRt8b3+EiH/zyl7EnyWkqEVWp3yMjx6k9yfMemR9++EH9KK33yMim5xvfI5N6/1N6NqTu6rdrj4gpqefMmTNqBqlWrVpqX0zdunUd2x7ZWySbR1O/p0iM9QhO+bcT+ld6NngAp9cemR0TcSub+iWGRPxLX5c9YVbGi7ftESEjp/jkpJ6cWJI/OGRMEPHpOWWYXllWxH96Nvjxx4XWTaOQ0dp9NJ4ESIAESIAE3E2AQsbd/mfrSYAESIAESEBrAhQyWruPxpMACZAACZCAuwlQyLjb/2w9CZAACZAACWhNgEJGa/fReBIgARIgARJwNwEKGXf7n60nARIgARIgAa0JUMho7T4aTwIkQAIkQALuJkAh427/s/UkQAIkQAIkoDUBChmt3UfjSYAESIAESMDdBChk3O1/tt6PCMgVFPJ222nTptnaqoSEBDz77LPqOgW5tVveEOxNkmsdxH7PtQzePMM8JEACJEAhwz5AAn5CwClCRm5slksxd+7cmXJJ5o2I5VqHkSNHonPnzo6g7+3lmY4wlkaQAAlcR4BChh2CBPyEgNFCRi7JDA4O9pmOCBQRBkuXLr3lsxQyPmPlAyRAArcgQCHDrkECJhCQD+oXX3wRy5Ytw/r161GyZElMmTIFDRs2VLWlJTrKli2Lt99+W/1OLnUUQfDyyy+r26flckC5dFJuOZabskUkyMWZctP3Aw88kFKmiA+5JPPHH39UtwwPGTJEledJcmO2lCE3c8uN6C+99JK6VVsuKfTMSkjdQ4cOxcmTJ9UFfzcmueBSypALLmNjY1X9cluz3Jgty0NyC7hcEpg1a1Z1u7eUlzq1atUKcntz5syZ1VLS/fffr5ahbmQiNsky0xdffKFuBpfbnuVm8e+++w7jxo1Ttkl9clmiJ8ks0L/+9S9s3rwZ2bNnR6dOndTFhCLIZMlLeM6bNw9xcXEoXLiwelbql4sL5WdySaakTz75RN3QfuTIEcVn7dq16udi+9ixY5ErVy71f7FRbmqXNsoN5HXq1MHnn38O8aUkufV9xIgR6rZnseeRRx65iYcJ3Y9FkoCrCFDIuMrdbKxVBETIeARFpUqV1C3k33//PeS2bG+FjAgWeU5Exa5du1CvXj1UrVoVEydOVP9+6623VJn79u1LKVNuRJYP/vbt2+O3337D448/rr7Lh7WUUb9+ffzf//2fuolYnpMPVvmgfe6555SQady4sbpRfPLkyerDXz58b0wiqP78808lZOQW4759+0JuJt6yZYvaEyM3mK9Zs8bnGZm0hMy9996rhEu+fPnw6KOPKkEgbROBJmJMOIjd0r5Tp06hYsWKSpzITeWnT5/GE088oRgIw88++0y1S0Sg3AAfERGBixcvQvyT1tKSCJsqVaqgY8eOSrjJ/0UYiQASseYRMlLnTz/9hGLFiinRs3LlSnVDu9z0njt3bixevBhNmjRRwksYecSsVX2R9ZCAvxOgkPF3D7N9thAQISOzHW+88YaqPzw8HBUqVFAbX+VD1JsZmVdffRXnz59X4kCSfKjXrVtXzRZIkg/yypUrIyoqSn1gSpkyKyCzLp4kH7wyyyAf4jIbIbMpng9hySOzC7/88ov6cPcIGZmFCA0NTZObzLRIefLB3axZM5Xn0qVLSmjIB/h9991nqJCZPXs2nn76aVXPp59+ikGDBt3ERNooYkpmrhYuXKiEmyeJ0BMxuH//fjUTMmrUKNV+sVNmgzwpLSEjAkqeFaaeJDM9IpqEo/hFZmRkc3X37t1VFhErMtMl5dWoUQMFChRQdon4EkZMJEACxhOgkDGeKUskAdy4B0RmEkQcyIyM/M4bISNLS/IB7EkPPfQQwsLC1PKTpEOHDqF06dJqZqF48eKqzKSkJMyYMSPlGckrswDyAS8zGvIhnyVLlpTfizARu2S2Rj58mzZtqsq4VZLlJpmRELtkOcaTpH5Z7nnmmWcMFTIiyjxLZ57ltlsx6dOnjxIV2bJlS7Hr6tWrqj0ithITE5VwmzNnjpqNkrZ+8MEHahkoLSEzZswYtWnZs9zkKVRmZkTcyAyMCBkRgVJWWiykXOEi7ShTpoxa9pIZHiYSIAHjCFDIGMeSJZFACoH0hIzMjpw9exZywkeSfNjKMo0sG6XeI+OrkLndjIx80EvyzOjc6C5vTu6I8JHlpgULFihRJelOZmTkQ132rqQ+tZTW0pIvQkaEh7RB9t+kl2QWS3wgs0+rVq1SX7L8I2LHk0TwyDKZiLxbpdvNyMjMjSeJf2UWq23btkpEpRaB6dnK35MACdyeAIUMewgJmEAgPSEjswuy7CQbgYsWLao+1GV2QDaKZkTIyB6Z6dOnq+UY+VCXvTAyYyCzGrIRtlGjRmqJpUWLFmo2Ye/evWovifzcGyEjqGQTs+wBkWUbEV/9+/fHunXrsHXrVq/3yMiHvCxNyf4cT8qokDlx4oTaEDx69Gg16yGbiWXWStoo7ZXZKLFX9hmJIJOlOxEV8nPJU758eRw4cEDNckmS5SNZHhK7XnnlFeTMmRPHjx/Hhg0b0KZNG5VHGMrynmyuFj++/vrrqjxhLcuIsldI2hkSEoLly5ermRupQ/oHEwmQgDEEKGSM4chSSOA6AukJGTld1Lt3byUGZIZD9mLIyZ8bTy35OiOT+tSS7MWRTbHdunVLsU0Eh9Sxbds29WEuyyoiqOR0kbdCRvaByF4V2ewrG1pFlIjtng9nbzb7ylKXiAOZlZL9KrJPJ6NCRhop+4bENhEbcqJKbJLNybJfSWa/3n33XTULIyJH9hzJDNg999yj+MiMlezJEYbyc3mpnyzbyUZfESGyMVjESrt27VIEmOfUkmywFoFSq1YtJUbLlSuHyMhItTlYBJ7M9MgSnpQl5TKRAAkYR4BCxjiWLIkESMBlBETIpF7+clnz2VwScAQBChlHuIFGkAAJ6EiAQkZHr9FmfyNAIeNvHmV7SIAELCNAIWMZalZEArckQCHDzkECJEACJEACJKAtAQoZbV1Hw0mABEiABEiABChk2AdIgARIgARIgAS0JUAho63raDgJkAAJkAAJkACFDPsACZAACZAACZCAtgQoZLR1HQ0nARIgARIgARKgkGEfIAESIAESIAES0JYAhYy2rqPhJEACJEACJEACFDLsAyRAAiRAAiRAAtoSoJDR1nU0nARIgARIgARIgEKGfYAESIAESIAESEBbAhQy2rqOhpMACZAACZAACVDIsA+QAAmQAAmQAAloS4BCRlvX0XASIAESIAESIAEKGfYBEiABEiABEiABbQlQyGjrOhpOAiRAAiRAAiRAIcM+QAIkQAIkQAIkoC0BChltXUfDSYAESIAESIAEKGTYB0iABEiABEiABLQlQCGjretoOAmQAAmQAAmQAIUM+wAJkAAJkAAJkIC2BChktHUdDScBEiABEiABEqCQYR8gARIgARIgARLQlgCFjLauo+EkQAIkQAIkQAIUMuwDJEACJEACJEAC2hKgkNHWdTScBEiABEiABEiAQoZ9gARIgARIgARIQFsCFDLauo6GkwAJkAAJkAAJUMiwD5AACZAACZAACWhLgEJGW9fRcBIgARIgARIgAQoZ9gESIAESIAESIAFtCVDIaOs6Gk4CJEACJEACJEAhwz5AAiRAAiRAAiSgLQEKGW1dR8NJgARIgARIgAQoZNgHSIAESIAESIAEtCVAIaOt62g4CZAACZAACZAAhQz7AAmQAAmQAAmQgLYEKGS0dR0NJwESIAESIAESoJBhHyABEiABEiABEtCWAIWMtq6j4SRAAiRAAiRAAhQy7AMkQAIkQAIkQALaEqCQ0dZ1NJwESIAESIAESIBChn2ABEiABEiABEhAWwIUMtq6joaTAAmQAAmQAAlQyLAPkAAJkAAJkAAJaEuAQkZb19FwEiABEiABEiABChn2ARIgARIgARIgAW0JUMho6zoaTgIkQAIkQAIkQCHDPkACJEACJEACJKAtAQoZbV1Hw0mABEiABEiABChk2AdIgARIgARIgAS0JUAho63raDgJkAAJkAAJkACFDPsACZAACZAACZCAtgT+Hz1RtK87Ej1yAAAAAElFTkSuQmCC\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 3\n",
      "Box(-100000.0, 100000.0, (3721,), float64)\n",
      "seed 3: model definition ..\n",
      "Using cuda device\n",
      "seed 3: learning ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f8948f10d68> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f8948f105f8>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f8948f10d68> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f8948f10b00>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 3200        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026069384 |\n",
      "|    clip_fraction        | 0.575       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0432      |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.0379     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6400, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.584       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 6400        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.066043854 |\n",
      "|    clip_fraction        | 0.451       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -1.19       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0596      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0513      |\n",
      "-----------------------------------------\n",
      "Early stopping at step 14 due to reaching max kl: 0.08\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 37         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 257        |\n",
      "|    total_timesteps      | 9600       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07613302 |\n",
      "|    clip_fraction        | 0.444      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.287      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.056      |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0232    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.0107     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=12800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=12800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.595      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 32         |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 392        |\n",
      "|    total_timesteps      | 12800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05750185 |\n",
      "|    clip_fraction        | 0.482      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.784      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.064      |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0324    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00414    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 491         |\n",
      "|    total_timesteps      | 16000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028247166 |\n",
      "|    clip_fraction        | 0.467       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0293      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0363     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00245     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=19200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=19200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.608        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 30           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 630          |\n",
      "|    total_timesteps      | 19200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147245815 |\n",
      "|    clip_fraction        | 0.452        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0511       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0366      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0021       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 728        |\n",
      "|    total_timesteps      | 22400      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00888762 |\n",
      "|    clip_fraction        | 0.455      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.02       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0375    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00203    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=25600, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=25600, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.621        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 29           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 865          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007466364 |\n",
      "|    clip_fraction        | 0.453        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0592       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0376      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00187      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 29         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 963        |\n",
      "|    total_timesteps      | 28800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01909418 |\n",
      "|    clip_fraction        | 0.484      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0467     |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0395    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00173    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=32000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=32000, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.633         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 29            |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 1102          |\n",
      "|    total_timesteps      | 32000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0011494685 |\n",
      "|    clip_fraction        | 0.462         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.951         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0436        |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.0379       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00177       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1199        |\n",
      "|    total_timesteps      | 35200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002413838 |\n",
      "|    clip_fraction        | 0.484       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0329      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00185     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=38400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=38400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1336        |\n",
      "|    total_timesteps      | 38400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015137352 |\n",
      "|    clip_fraction        | 0.484       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0369      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0387     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0016      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 1436         |\n",
      "|    total_timesteps      | 41600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076517654 |\n",
      "|    clip_fraction        | 0.479        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0302       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0389      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00167      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=44800, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=44800, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.65          |\n",
      "| time/                   |               |\n",
      "|    fps                  | 28            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 1574          |\n",
      "|    total_timesteps      | 44800         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0012023187 |\n",
      "|    clip_fraction        | 0.481         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.958         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0445        |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -0.0387       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.0016        |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1672         |\n",
      "|    total_timesteps      | 48000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059527564 |\n",
      "|    clip_fraction        | 0.477        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.058        |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0385      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00171      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=51200, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=51200, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.656       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1808        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008528855 |\n",
      "|    clip_fraction        | 0.49        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0275      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00161     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 1906         |\n",
      "|    total_timesteps      | 54400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034671403 |\n",
      "|    clip_fraction        | 0.495        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0578       |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0396      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00169      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=57600, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=57600, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.667        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 2041         |\n",
      "|    total_timesteps      | 57600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013678193 |\n",
      "|    clip_fraction        | 0.501        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.939        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.037        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0404      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0018       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 28           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 2139         |\n",
      "|    total_timesteps      | 60800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036435581 |\n",
      "|    clip_fraction        | 0.493        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0317       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0401      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0017       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=64000, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.668       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2272        |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004011812 |\n",
      "|    clip_fraction        | 0.5         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.053       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00174     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 2370        |\n",
      "|    total_timesteps      | 67200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011451495 |\n",
      "|    clip_fraction        | 0.503       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.044       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00169     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70400, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=70400, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.673       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 2505        |\n",
      "|    total_timesteps      | 70400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017018892 |\n",
      "|    clip_fraction        | 0.505       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0271      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00172     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 28            |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 2603          |\n",
      "|    total_timesteps      | 73600         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0037216544 |\n",
      "|    clip_fraction        | 0.498         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.958         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.037         |\n",
      "|    n_updates            | 440           |\n",
      "|    policy_gradient_loss | -0.0389       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00174       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=76800, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=76800, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.677       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 2738        |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033604775 |\n",
      "|    clip_fraction        | 0.529       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0497      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0419     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00181     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2836        |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024722219 |\n",
      "|    clip_fraction        | 0.511       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0402      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0418     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00161     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=83200, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=83200, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.678       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 2972        |\n",
      "|    total_timesteps      | 83200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017714618 |\n",
      "|    clip_fraction        | 0.517       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0923      |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0406     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00163     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 3070        |\n",
      "|    total_timesteps      | 86400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012002184 |\n",
      "|    clip_fraction        | 0.522       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0349      |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0412     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00158     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=89600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=89600, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.682      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 3205       |\n",
      "|    total_timesteps      | 89600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01715684 |\n",
      "|    clip_fraction        | 0.512      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0478     |\n",
      "|    n_updates            | 540        |\n",
      "|    policy_gradient_loss | -0.0406    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00169    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 3304        |\n",
      "|    total_timesteps      | 92800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009225411 |\n",
      "|    clip_fraction        | 0.524       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0701      |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00175     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=96000, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.682       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 3440        |\n",
      "|    total_timesteps      | 96000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005010717 |\n",
      "|    clip_fraction        | 0.514       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0422      |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00173     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 3539        |\n",
      "|    total_timesteps      | 99200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009956748 |\n",
      "|    clip_fraction        | 0.522       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0344      |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0407     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00159     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=102400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=102400, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.684       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 3673        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026106492 |\n",
      "|    clip_fraction        | 0.519       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00162     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 3771        |\n",
      "|    total_timesteps      | 105600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011728826 |\n",
      "|    clip_fraction        | 0.512       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0247      |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00163     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=108800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=108800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.685      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 3907       |\n",
      "|    total_timesteps      | 108800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03643119 |\n",
      "|    clip_fraction        | 0.542      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0353     |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00151    |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 35            |\n",
      "|    time_elapsed         | 4002          |\n",
      "|    total_timesteps      | 112000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0092251925 |\n",
      "|    clip_fraction        | 0.535         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.968         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0331        |\n",
      "|    n_updates            | 680           |\n",
      "|    policy_gradient_loss | -0.0395       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00144       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=115200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=115200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.686       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 4139        |\n",
      "|    total_timesteps      | 115200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | -0.01375429 |\n",
      "|    clip_fraction        | 0.534       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0122      |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.038      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00156     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 27             |\n",
      "|    iterations           | 37             |\n",
      "|    time_elapsed         | 4237           |\n",
      "|    total_timesteps      | 118400         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00095219136 |\n",
      "|    clip_fraction        | 0.531          |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | 91.8           |\n",
      "|    explained_variance   | 0.968          |\n",
      "|    learning_rate        | 1e-06          |\n",
      "|    loss                 | 0.0268         |\n",
      "|    n_updates            | 720            |\n",
      "|    policy_gradient_loss | -0.0397        |\n",
      "|    std                  | 0.055          |\n",
      "|    value_loss           | 0.0016         |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=121600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=121600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.687       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 4374        |\n",
      "|    total_timesteps      | 121600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013980458 |\n",
      "|    clip_fraction        | 0.538       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0182      |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0415     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00143     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 4472        |\n",
      "|    total_timesteps      | 124800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009260645 |\n",
      "|    clip_fraction        | 0.537       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0719      |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0016      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=128000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.688       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 4608        |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003018911 |\n",
      "|    clip_fraction        | 0.533       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0386      |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0401     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00154     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 27        |\n",
      "|    iterations           | 41        |\n",
      "|    time_elapsed         | 4706      |\n",
      "|    total_timesteps      | 131200    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0109989 |\n",
      "|    clip_fraction        | 0.538     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 91.8      |\n",
      "|    explained_variance   | 0.964     |\n",
      "|    learning_rate        | 1e-06     |\n",
      "|    loss                 | 0.0623    |\n",
      "|    n_updates            | 800       |\n",
      "|    policy_gradient_loss | -0.0401   |\n",
      "|    std                  | 0.055     |\n",
      "|    value_loss           | 0.00166   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=134400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=134400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.687       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 4843        |\n",
      "|    total_timesteps      | 134400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022728465 |\n",
      "|    clip_fraction        | 0.539       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0632      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00159     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 4942          |\n",
      "|    total_timesteps      | 137600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0137497615 |\n",
      "|    clip_fraction        | 0.527         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.967         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0246        |\n",
      "|    n_updates            | 840           |\n",
      "|    policy_gradient_loss | -0.0377       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00158       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=140800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=140800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.688       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 5077        |\n",
      "|    total_timesteps      | 140800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012074594 |\n",
      "|    clip_fraction        | 0.528       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0319      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0016      |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 5178          |\n",
      "|    total_timesteps      | 144000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0031606746 |\n",
      "|    clip_fraction        | 0.542         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.97          |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0235        |\n",
      "|    n_updates            | 880           |\n",
      "|    policy_gradient_loss | -0.0395       |\n",
      "|    std                  | 0.0551        |\n",
      "|    value_loss           | 0.00143       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=147200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=147200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.688       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 5315        |\n",
      "|    total_timesteps      | 147200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014785605 |\n",
      "|    clip_fraction        | 0.549       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0352      |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0408     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00144     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 5413         |\n",
      "|    total_timesteps      | 150400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048800493 |\n",
      "|    clip_fraction        | 0.54         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0486       |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0399      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00154      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=153600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=153600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.689       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 5549        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007815132 |\n",
      "|    clip_fraction        | 0.533       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0495      |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0392     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 5647        |\n",
      "|    total_timesteps      | 156800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031799875 |\n",
      "|    clip_fraction        | 0.554       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0248      |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.041      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00142     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=160000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.689       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 5784        |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009299498 |\n",
      "|    clip_fraction        | 0.532       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.041       |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00152     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 5882       |\n",
      "|    total_timesteps      | 163200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03047243 |\n",
      "|    clip_fraction        | 0.564      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0487     |\n",
      "|    n_updates            | 1000       |\n",
      "|    policy_gradient_loss | -0.0412    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00142    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=166400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=166400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.688      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 6017       |\n",
      "|    total_timesteps      | 166400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04064043 |\n",
      "|    clip_fraction        | 0.552      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0363     |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00154    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 6115        |\n",
      "|    total_timesteps      | 169600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015193114 |\n",
      "|    clip_fraction        | 0.554       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0311      |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0411     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00155     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=172800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=172800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.689        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 6253         |\n",
      "|    total_timesteps      | 172800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004547882 |\n",
      "|    clip_fraction        | 0.549        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0364       |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.039       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00143      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 6350        |\n",
      "|    total_timesteps      | 176000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046116903 |\n",
      "|    clip_fraction        | 0.567       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0404      |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0394     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.0014      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=179200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=179200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.689        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 6488         |\n",
      "|    total_timesteps      | 179200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062844944 |\n",
      "|    clip_fraction        | 0.558        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0728       |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.0391      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00149      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 6586        |\n",
      "|    total_timesteps      | 182400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045416575 |\n",
      "|    clip_fraction        | 0.574       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0339      |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0402     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00136     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=185600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=185600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.688      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 6720       |\n",
      "|    total_timesteps      | 185600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01666515 |\n",
      "|    clip_fraction        | 0.564      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0318     |\n",
      "|    n_updates            | 1140       |\n",
      "|    policy_gradient_loss | -0.0412    |\n",
      "|    std                  | 0.0551     |\n",
      "|    value_loss           | 0.00133    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 59         |\n",
      "|    time_elapsed         | 6817       |\n",
      "|    total_timesteps      | 188800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04331141 |\n",
      "|    clip_fraction        | 0.574      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0536     |\n",
      "|    n_updates            | 1160       |\n",
      "|    policy_gradient_loss | -0.0403    |\n",
      "|    std                  | 0.0551     |\n",
      "|    value_loss           | 0.00132    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=192000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.689       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 6954        |\n",
      "|    total_timesteps      | 192000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002771423 |\n",
      "|    clip_fraction        | 0.558       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0345      |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00145     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 27        |\n",
      "|    iterations           | 61        |\n",
      "|    time_elapsed         | 7052      |\n",
      "|    total_timesteps      | 195200    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0193336 |\n",
      "|    clip_fraction        | 0.555     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 91.8      |\n",
      "|    explained_variance   | 0.975     |\n",
      "|    learning_rate        | 1e-06     |\n",
      "|    loss                 | 0.0398    |\n",
      "|    n_updates            | 1200      |\n",
      "|    policy_gradient_loss | -0.0393   |\n",
      "|    std                  | 0.0551    |\n",
      "|    value_loss           | 0.00128   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=198400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=198400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.688      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 62         |\n",
      "|    time_elapsed         | 7187       |\n",
      "|    total_timesteps      | 198400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03219989 |\n",
      "|    clip_fraction        | 0.561      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0334     |\n",
      "|    n_updates            | 1220       |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    std                  | 0.0551     |\n",
      "|    value_loss           | 0.00145    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 7285        |\n",
      "|    total_timesteps      | 201600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023721552 |\n",
      "|    clip_fraction        | 0.568       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0255      |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.04       |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00134     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=204800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=204800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.689       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 7418        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009705594 |\n",
      "|    clip_fraction        | 0.549       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0483      |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00132     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 65            |\n",
      "|    time_elapsed         | 7516          |\n",
      "|    total_timesteps      | 208000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0012450195 |\n",
      "|    clip_fraction        | 0.562         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.971         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0218        |\n",
      "|    n_updates            | 1280          |\n",
      "|    policy_gradient_loss | -0.0379       |\n",
      "|    std                  | 0.0551        |\n",
      "|    value_loss           | 0.00128       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=211200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=211200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.69        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 7653        |\n",
      "|    total_timesteps      | 211200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012943025 |\n",
      "|    clip_fraction        | 0.558       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0378      |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00143     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 7751        |\n",
      "|    total_timesteps      | 214400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033124696 |\n",
      "|    clip_fraction        | 0.564       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0292      |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00142     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=217600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=217600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.69       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 7888       |\n",
      "|    total_timesteps      | 217600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03962906 |\n",
      "|    clip_fraction        | 0.568      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0464     |\n",
      "|    n_updates            | 1340       |\n",
      "|    policy_gradient_loss | -0.0385    |\n",
      "|    std                  | 0.0551     |\n",
      "|    value_loss           | 0.00123    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 7986        |\n",
      "|    total_timesteps      | 220800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011123871 |\n",
      "|    clip_fraction        | 0.564       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.026       |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00125     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=224000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.691        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 8122         |\n",
      "|    total_timesteps      | 224000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.002331059 |\n",
      "|    clip_fraction        | 0.565        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0324       |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.0377      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00124      |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 27             |\n",
      "|    iterations           | 71             |\n",
      "|    time_elapsed         | 8220           |\n",
      "|    total_timesteps      | 227200         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00055776356 |\n",
      "|    clip_fraction        | 0.558          |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | 91.8           |\n",
      "|    explained_variance   | 0.975          |\n",
      "|    learning_rate        | 1e-06          |\n",
      "|    loss                 | 0.0345         |\n",
      "|    n_updates            | 1400           |\n",
      "|    policy_gradient_loss | -0.0377        |\n",
      "|    std                  | 0.0551         |\n",
      "|    value_loss           | 0.0012         |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=230400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=230400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 8355        |\n",
      "|    total_timesteps      | 230400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027627392 |\n",
      "|    clip_fraction        | 0.569       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0588      |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.0398     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00119     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 8453        |\n",
      "|    total_timesteps      | 233600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021960678 |\n",
      "|    clip_fraction        | 0.571       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0287      |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.0403     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00123     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=236800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=236800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.692      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 74         |\n",
      "|    time_elapsed         | 8587       |\n",
      "|    total_timesteps      | 236800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03442359 |\n",
      "|    clip_fraction        | 0.572      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0484     |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | -0.04      |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00115    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 8685        |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026798556 |\n",
      "|    clip_fraction        | 0.573       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0374      |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0399     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00114     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=243200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=243200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 8820        |\n",
      "|    total_timesteps      | 243200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029054945 |\n",
      "|    clip_fraction        | 0.566       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0254      |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.0393     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0012      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 8919       |\n",
      "|    total_timesteps      | 246400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02971387 |\n",
      "|    clip_fraction        | 0.566      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0211     |\n",
      "|    n_updates            | 1520       |\n",
      "|    policy_gradient_loss | -0.038     |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00116    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=249600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=249600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 9056        |\n",
      "|    total_timesteps      | 249600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038452037 |\n",
      "|    clip_fraction        | 0.57        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0311      |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00131     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 79         |\n",
      "|    time_elapsed         | 9154       |\n",
      "|    total_timesteps      | 252800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02039176 |\n",
      "|    clip_fraction        | 0.574      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0383     |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | -0.0395    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.0011     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=256000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.692      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 9291       |\n",
      "|    total_timesteps      | 256000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01035394 |\n",
      "|    clip_fraction        | 0.563      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0538     |\n",
      "|    n_updates            | 1580       |\n",
      "|    policy_gradient_loss | -0.0386    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00108    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 9388        |\n",
      "|    total_timesteps      | 259200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022000253 |\n",
      "|    clip_fraction        | 0.561       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0355      |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0389     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00112     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=262400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=262400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 9522        |\n",
      "|    total_timesteps      | 262400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015523336 |\n",
      "|    clip_fraction        | 0.567       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.053       |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.0383     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00106     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 9622        |\n",
      "|    total_timesteps      | 265600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030810738 |\n",
      "|    clip_fraction        | 0.574       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0403      |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00112     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=268800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=268800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 9757        |\n",
      "|    total_timesteps      | 268800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022207692 |\n",
      "|    clip_fraction        | 0.568       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0395     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 9855        |\n",
      "|    total_timesteps      | 272000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014829822 |\n",
      "|    clip_fraction        | 0.566       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.001       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=275200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=275200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 9992        |\n",
      "|    total_timesteps      | 275200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003586552 |\n",
      "|    clip_fraction        | 0.569       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0307      |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.037      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0011      |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 27            |\n",
      "|    iterations           | 87            |\n",
      "|    time_elapsed         | 10090         |\n",
      "|    total_timesteps      | 278400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023157358 |\n",
      "|    clip_fraction        | 0.569         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.978         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0429        |\n",
      "|    n_updates            | 1720          |\n",
      "|    policy_gradient_loss | -0.037        |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00106       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=281600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=281600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.692       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 10225       |\n",
      "|    total_timesteps      | 281600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016063666 |\n",
      "|    clip_fraction        | 0.566       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0238      |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.039      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00107     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 10323       |\n",
      "|    total_timesteps      | 284800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045276623 |\n",
      "|    clip_fraction        | 0.572       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0455      |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.0377     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0011      |\n",
      "-----------------------------------------\n",
      "Early stopping at step 8 due to reaching max kl: 0.08\n",
      "Eval num_timesteps=288000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=288000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.693     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 27        |\n",
      "|    iterations           | 90        |\n",
      "|    time_elapsed         | 10423     |\n",
      "|    total_timesteps      | 288000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0822558 |\n",
      "|    clip_fraction        | 0.511     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 91.8      |\n",
      "|    explained_variance   | 0.786     |\n",
      "|    learning_rate        | 1e-06     |\n",
      "|    loss                 | 0.0529    |\n",
      "|    n_updates            | 1780      |\n",
      "|    policy_gradient_loss | -0.0206   |\n",
      "|    std                  | 0.055     |\n",
      "|    value_loss           | 0.00145   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 10521        |\n",
      "|    total_timesteps      | 291200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.011444636 |\n",
      "|    clip_fraction        | 0.555        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0493       |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.0351      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00107      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=294400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=294400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.693        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 10657        |\n",
      "|    total_timesteps      | 294400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.007032163 |\n",
      "|    clip_fraction        | 0.587        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0612       |\n",
      "|    n_updates            | 1820         |\n",
      "|    policy_gradient_loss | -0.0389      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.000961     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 27           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 10755        |\n",
      "|    total_timesteps      | 297600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072047045 |\n",
      "|    clip_fraction        | 0.574        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0566       |\n",
      "|    n_updates            | 1840         |\n",
      "|    policy_gradient_loss | -0.0372      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.000987     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=300800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=300800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.694      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 27         |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 10891      |\n",
      "|    total_timesteps      | 300800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03855805 |\n",
      "|    clip_fraction        | 0.586      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0368     |\n",
      "|    n_updates            | 1860       |\n",
      "|    policy_gradient_loss | -0.0393    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.000963   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seed in range(1,4):\n",
    "    if True:\n",
    "        print(f'seed {seed}')\n",
    "        log_dir = './data/'+case+'/seed_'+str(seed)\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        num_cpu = 64\n",
    "        env_train.seed(seed)\n",
    "        env_eval.seed(seed)\n",
    "        train_callback = CustomEvalCallback( env_train, \n",
    "                                            best_model_save_path=None, \n",
    "                                            n_eval_episodes=1,\n",
    "                                            log_path=str(log_dir)+'/results_train', \n",
    "                                            eval_freq=100)\n",
    "        callback_list = [train_callback]\n",
    "        eval_callback = CustomEvalCallback( env_eval, \n",
    "                                           best_model_save_path=None, \n",
    "                                           n_eval_episodes=1,\n",
    "                                           log_path=str(log_dir)+'/results_eval', \n",
    "                                           eval_freq=100)\n",
    "        callback_list.append(eval_callback)\n",
    "        callback = CallbackList(callback_list)\n",
    "        env = SubprocVecEnv([make_env(env_train, i, seed) for i in range(num_cpu)])\n",
    "        print(env.observation_space)\n",
    "#     env = VecMonitor(env, filename=log_dir)\n",
    "        print(f'seed {seed}: model definition ..')\n",
    "        model = PPO(policy=MlpPolicy,\n",
    "            env=env,\n",
    "            learning_rate = 1e-6,\n",
    "            n_steps = 50,\n",
    "            batch_size = 16,\n",
    "            n_epochs = 20,\n",
    "            gamma = 0.99,\n",
    "            gae_lambda = 0.95,\n",
    "            clip_range = 0.1,\n",
    "            clip_range_vf = None,\n",
    "            ent_coef = 0.001,\n",
    "            vf_coef = 0.5,\n",
    "            max_grad_norm = 0.5,\n",
    "            use_sde= False,\n",
    "            create_eval_env= False,\n",
    "            policy_kwargs = dict(net_arch=[4000,2000,800,300], log_std_init=-2.9),\n",
    "            verbose = 1,\n",
    "            target_kl = 0.05,\n",
    "            seed = seed,\n",
    "            device = \"auto\")\n",
    "        print(f'seed {seed}: learning ..')\n",
    "        model.learn(total_timesteps=300000, callback=callback)\n",
    "#         model.save(log_dir+'/PPO')\n",
    "        del model\n",
    "        fig = plot_learning(log_dir, case='train')\n",
    "        fig.savefig(log_dir+'/learn_train.png')\n",
    "        fig = plot_learning(log_dir, case='eval')\n",
    "        fig.savefig(log_dir+'/learn_eval.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
