{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access functions from other locations\n",
    "import sys\n",
    "sys.path.append('/data/ad181/RemoteDir/rl_robust_owc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "import gym\n",
    "from stable_baselines3.ppo import PPO, MlpPolicy\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "from utils.custom_eval_callback import CustomEvalCallback\n",
    "from utils.env_wrappers import StateCoarse, BufferWrapper\n",
    "from typing import Callable\n",
    "from utils.plot_functions import plot_learning\n",
    "\n",
    "from model.ressim import Grid\n",
    "from ressim_env import ResSimEnv_v0, ResSimEnv_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1\n",
    "case='case_1_ppo_frozen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./data', exist_ok=True)\n",
    "os.makedirs('./data/'+case, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../envs_params/env_data/env_train.pkl', 'rb') as input:\n",
    "    env_train = pickle.load(input)\n",
    "k_list_train = env_train.k_list[13]\n",
    "env_train.set_k( np.array([k_list_train]) )\n",
    "    \n",
    "with open('../envs_params/env_data/env_eval.pkl', 'rb') as input:\n",
    "    env_eval = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env wrapper parameters\n",
    "x_coords, y_coords = env_train.p_x, env_train.p_y\n",
    "\n",
    "def env_wrappers(env, x_coords, y_coords):\n",
    "    env_ = deepcopy(env)\n",
    "    env_ = StateCoarse(env_, x_coords, y_coords, include_well_pr=True)\n",
    "    return env_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env, rank: int, seed: int) -> Callable:\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "    \n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environment you wish to have in subprocesses\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    :return: (Callable)\n",
    "    \"\"\"\n",
    "    def _init() -> gym.Env:\n",
    "        env_ = env\n",
    "        env_.seed(seed + rank)\n",
    "        return env_\n",
    "    return _init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test run\n",
    "# env = StateCoarse(env_train, x_coords, y_coords, include_well_pr=True)\n",
    "# print(env.observation_space)\n",
    "# base_action = np.ones(env.action_space.shape[0])\n",
    "\n",
    "# state, done = env.reset(), False\n",
    "# print(state)\n",
    "# while not done:\n",
    "#     state, reward, done, info = env.step(base_action)\n",
    "#     print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1\n",
      "Box(-100000.0, 100000.0, (93,), float64)\n",
      "seed 1: model definition ..\n",
      "Using cuda device\n",
      "seed 1: learning ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f67e001acf8> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f67e1736fd0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f67e001acf8> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f67e001ac88>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 105  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 30   |\n",
      "|    total_timesteps | 3200 |\n",
      "-----------------------------\n",
      "Eval num_timesteps=6400, episode_reward=0.56 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 6400        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009529302 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -1.39       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.125       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0915      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 9600        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016261056 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -1.39       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0905      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0626      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=12800, episode_reward=0.56 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=12800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.593       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014689944 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.771      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0476      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 16000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013815782 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.584      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0388      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=19200, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=19200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.595     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 49        |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 387       |\n",
      "|    total_timesteps      | 19200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0202064 |\n",
      "|    clip_fraction        | 0.209     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 91.8      |\n",
      "|    explained_variance   | -0.43     |\n",
      "|    learning_rate        | 1e-06     |\n",
      "|    loss                 | 0.0928    |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -0.0154   |\n",
      "|    std                  | 0.055     |\n",
      "|    value_loss           | 0.0298    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 448         |\n",
      "|    total_timesteps      | 22400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017465398 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.176      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0732      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0247      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=25600, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=25600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.598      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 527        |\n",
      "|    total_timesteps      | 25600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01456275 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.0703     |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0749     |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.0197     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 48         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 588        |\n",
      "|    total_timesteps      | 28800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00918128 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.207      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0623     |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.0167     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=32000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.599        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 662          |\n",
      "|    total_timesteps      | 32000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086705275 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0954       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0149      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0137       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 716         |\n",
      "|    total_timesteps      | 35200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009434476 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0559      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0114      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=38400, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=38400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.599       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 792         |\n",
      "|    total_timesteps      | 38400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009297485 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0709      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00991     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 846         |\n",
      "|    total_timesteps      | 41600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009926636 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0738      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00873     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=44800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=44800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.602       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 921         |\n",
      "|    total_timesteps      | 44800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011211816 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0415      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00783     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 974          |\n",
      "|    total_timesteps      | 48000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077865766 |\n",
      "|    clip_fraction        | 0.191        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0569       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.018       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00711      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=51200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=51200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.604       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1048        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008742874 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0763      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00663     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1102        |\n",
      "|    total_timesteps      | 54400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008926444 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0934      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00636     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=57600, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=57600, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.609       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 1175        |\n",
      "|    total_timesteps      | 57600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006262324 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.044       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00578     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 1233         |\n",
      "|    total_timesteps      | 60800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038176037 |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.798        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0713       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00603      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=64000, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=64000, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.616        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 1306         |\n",
      "|    total_timesteps      | 64000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068102907 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0634       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0196      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00558      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 1361         |\n",
      "|    total_timesteps      | 67200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037593842 |\n",
      "|    clip_fraction        | 0.182        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0671       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00539      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70400, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=70400, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.622        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 1437         |\n",
      "|    total_timesteps      | 70400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039506243 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0375       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0194      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00537      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1491        |\n",
      "|    total_timesteps      | 73600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004530737 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0758      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00501     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=76800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=76800, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.627        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 1565         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052488423 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.844        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0794       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0051       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 1628         |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032150138 |\n",
      "|    clip_fraction        | 0.199        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.85         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.063        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.005        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=83200, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=83200, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.63         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 1701         |\n",
      "|    total_timesteps      | 83200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014862823 |\n",
      "|    clip_fraction        | 0.181        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.852        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0719       |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00488      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 1766         |\n",
      "|    total_timesteps      | 86400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021277429 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.862        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0581       |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00466      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=89600, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=89600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.635        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 1838         |\n",
      "|    total_timesteps      | 89600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031504678 |\n",
      "|    clip_fraction        | 0.187        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.857        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0897       |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00483      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1893        |\n",
      "|    total_timesteps      | 92800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005031643 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.063       |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00459     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=96000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.636        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 1967         |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032519149 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.865        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.079        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00466      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 2021        |\n",
      "|    total_timesteps      | 99200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003936143 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0846      |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.0047      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=102400, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=102400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.636        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 2095         |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023808621 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0549       |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00446      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 2149         |\n",
      "|    total_timesteps      | 105600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012211418 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.056        |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00449      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=108800, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=108800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.641        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 2228         |\n",
      "|    total_timesteps      | 108800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029056715 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0661       |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00455      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 2282         |\n",
      "|    total_timesteps      | 112000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043603373 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0906       |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00443      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=115200, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=115200, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.644         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 48            |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 2356          |\n",
      "|    total_timesteps      | 115200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0005904412 |\n",
      "|    clip_fraction        | 0.186         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.875         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0554        |\n",
      "|    n_updates            | 700           |\n",
      "|    policy_gradient_loss | -0.0174       |\n",
      "|    std                  | 0.0551        |\n",
      "|    value_loss           | 0.00443       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 2411         |\n",
      "|    total_timesteps      | 118400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027800035 |\n",
      "|    clip_fraction        | 0.182        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.873        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0642       |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00449      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=121600, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=121600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.643        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 2487         |\n",
      "|    total_timesteps      | 121600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005785203 |\n",
      "|    clip_fraction        | 0.187        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0921       |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00435      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 2542         |\n",
      "|    total_timesteps      | 124800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033263636 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.108        |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00435      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=128000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 2617        |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004142382 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0669      |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00437     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 2671         |\n",
      "|    total_timesteps      | 131200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014262081 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.883        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0591       |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.0043       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=134400, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=134400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.645        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 2746         |\n",
      "|    total_timesteps      | 134400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031965924 |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.885        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0726       |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0186      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00424      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 2801         |\n",
      "|    total_timesteps      | 137600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033215857 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0758       |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.018       |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00423      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=140800, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=140800, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.646         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 48            |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 2875          |\n",
      "|    total_timesteps      | 140800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -3.354788e-05 |\n",
      "|    clip_fraction        | 0.197         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.892         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0784        |\n",
      "|    n_updates            | 860           |\n",
      "|    policy_gradient_loss | -0.0191       |\n",
      "|    std                  | 0.0551        |\n",
      "|    value_loss           | 0.00401       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 2928        |\n",
      "|    total_timesteps      | 144000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002268374 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0805      |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00437     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=147200, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=147200, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.648        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 3001         |\n",
      "|    total_timesteps      | 147200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012079095 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0385       |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00414      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 3056         |\n",
      "|    total_timesteps      | 150400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015853525 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0577       |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0177      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00426      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=153600, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=153600, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.647        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 3129         |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012760091 |\n",
      "|    clip_fraction        | 0.175        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.891        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.068        |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00414      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 3183        |\n",
      "|    total_timesteps      | 156800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001617577 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0444      |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00415     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=160000, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.646        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 3256         |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024560047 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0867       |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00415      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 3311        |\n",
      "|    total_timesteps      | 163200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002066629 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0536      |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00423     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=166400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=166400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.646        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 3386         |\n",
      "|    total_timesteps      | 166400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008729172 |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0634       |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.0166      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00418      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 3441         |\n",
      "|    total_timesteps      | 169600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012090825 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0508       |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00424      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=172800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=172800, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.646       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 3515        |\n",
      "|    total_timesteps      | 172800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001730926 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.07        |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00417     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 49         |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 3569       |\n",
      "|    total_timesteps      | 176000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00192204 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.898      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0637     |\n",
      "|    n_updates            | 1080       |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00398    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=179200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=179200, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.648       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 3642        |\n",
      "|    total_timesteps      | 179200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003598013 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0457      |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00413     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 3696         |\n",
      "|    total_timesteps      | 182400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024383294 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.106        |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.0186      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00404      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=185600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=185600, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.646        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 3770         |\n",
      "|    total_timesteps      | 185600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023061156 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0675       |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.0174      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00408      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 3823         |\n",
      "|    total_timesteps      | 188800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015287661 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0469       |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00398      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=192000, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.647        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 3896         |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045248056 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.899        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0859       |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00396      |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 49             |\n",
      "|    iterations           | 61             |\n",
      "|    time_elapsed         | 3950           |\n",
      "|    total_timesteps      | 195200         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00020078183 |\n",
      "|    clip_fraction        | 0.173          |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | 91.8           |\n",
      "|    explained_variance   | 0.899          |\n",
      "|    learning_rate        | 1e-06          |\n",
      "|    loss                 | 0.0563         |\n",
      "|    n_updates            | 1200           |\n",
      "|    policy_gradient_loss | -0.0168        |\n",
      "|    std                  | 0.055          |\n",
      "|    value_loss           | 0.00403        |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=198400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=198400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.647       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 4024        |\n",
      "|    total_timesteps      | 198400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001093452 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0737      |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00398     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 4076         |\n",
      "|    total_timesteps      | 201600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.942531e-05 |\n",
      "|    clip_fraction        | 0.199        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0702       |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00401      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=204800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=204800, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.646        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 64           |\n",
      "|    time_elapsed         | 4148         |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020761895 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.902        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0711       |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.0188      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00387      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 4207         |\n",
      "|    total_timesteps      | 208000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031535411 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.085        |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00407      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=211200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=211200, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.646        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 4280         |\n",
      "|    total_timesteps      | 211200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016913366 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0445       |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.0192      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00387      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 4334         |\n",
      "|    total_timesteps      | 214400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007108903 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0443       |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00378      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=217600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=217600, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.646        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 4407         |\n",
      "|    total_timesteps      | 217600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018183946 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.113        |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00387      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 4469        |\n",
      "|    total_timesteps      | 220800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001292584 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0514      |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00364     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.646        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 4541         |\n",
      "|    total_timesteps      | 224000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022505093 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0868       |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00378      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 4597        |\n",
      "|    total_timesteps      | 227200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003972337 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.9         |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0778      |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00385     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=230400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=230400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.645        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 4670         |\n",
      "|    total_timesteps      | 230400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025585962 |\n",
      "|    clip_fraction        | 0.182        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0613       |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.0169      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00375      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 4723         |\n",
      "|    total_timesteps      | 233600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053375456 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.904        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0658       |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.018       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00373      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=236800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=236800, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.647        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 4796         |\n",
      "|    total_timesteps      | 236800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026648473 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0667       |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00375      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 4850         |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018955946 |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0886       |\n",
      "|    n_updates            | 1480         |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0037       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=243200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=243200, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.645        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 4925         |\n",
      "|    total_timesteps      | 243200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020772861 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.906        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0724       |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00364      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 49            |\n",
      "|    iterations           | 77            |\n",
      "|    time_elapsed         | 4978          |\n",
      "|    total_timesteps      | 246400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013587951 |\n",
      "|    clip_fraction        | 0.179         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.909         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0573        |\n",
      "|    n_updates            | 1520          |\n",
      "|    policy_gradient_loss | -0.0177       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.0035        |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=249600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=249600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.644        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 5050         |\n",
      "|    total_timesteps      | 249600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012842488 |\n",
      "|    clip_fraction        | 0.206        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0626       |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | -0.0184      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00377      |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 49        |\n",
      "|    iterations           | 79        |\n",
      "|    time_elapsed         | 5105      |\n",
      "|    total_timesteps      | 252800    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0043875 |\n",
      "|    clip_fraction        | 0.182     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 91.9      |\n",
      "|    explained_variance   | 0.905     |\n",
      "|    learning_rate        | 1e-06     |\n",
      "|    loss                 | 0.0883    |\n",
      "|    n_updates            | 1560      |\n",
      "|    policy_gradient_loss | -0.0178   |\n",
      "|    std                  | 0.055     |\n",
      "|    value_loss           | 0.0037    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=256000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.643       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 5176        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002952628 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0884      |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00359     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 5227        |\n",
      "|    total_timesteps      | 259200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003805454 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0561      |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00354     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=262400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=262400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.644        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 5299         |\n",
      "|    total_timesteps      | 262400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023984576 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.908        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0792       |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.018       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00354      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 5353        |\n",
      "|    total_timesteps      | 265600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005132747 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0469      |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00361     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=268800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=268800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.645        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 5427         |\n",
      "|    total_timesteps      | 268800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034699321 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0785       |\n",
      "|    n_updates            | 1660         |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0034       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 5480         |\n",
      "|    total_timesteps      | 272000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023125887 |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0762       |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00332      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=275200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=275200, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.644        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 5553         |\n",
      "|    total_timesteps      | 275200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045251036 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0919       |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00344      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 5606         |\n",
      "|    total_timesteps      | 278400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017053544 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0723       |\n",
      "|    n_updates            | 1720         |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00328      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=281600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=281600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.644        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 5681         |\n",
      "|    total_timesteps      | 281600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011723447 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0845       |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00331      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 5735         |\n",
      "|    total_timesteps      | 284800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030316543 |\n",
      "|    clip_fraction        | 0.205        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0999       |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.0189      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00329      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=288000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 5807        |\n",
      "|    total_timesteps      | 288000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003199556 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0569      |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00341     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 5870         |\n",
      "|    total_timesteps      | 291200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009407258 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0697       |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00341      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=294400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=294400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.646       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 5944        |\n",
      "|    total_timesteps      | 294400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004376266 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0992      |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00334     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 5998         |\n",
      "|    total_timesteps      | 297600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024272609 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.065        |\n",
      "|    n_updates            | 1840         |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00324      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=300800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=300800, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.646       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 6072        |\n",
      "|    total_timesteps      | 300800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001258676 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0985      |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00333     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 2\n",
      "Box(-100000.0, 100000.0, (93,), float64)\n",
      "seed 2: model definition ..\n",
      "Using cuda device\n",
      "seed 2: learning ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f67a003a978> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f67a003a588>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f67a003a978> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f67a003a7b8>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 107          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 3200         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013022018 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.918        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0411       |\n",
      "|    n_updates            | 1880         |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0031       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6400, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.597      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 102        |\n",
      "|    total_timesteps      | 6400       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01305756 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | -0.245     |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0827     |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.0769     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 9600        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021037363 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.878      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0572      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=12800, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=12800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 240         |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019304182 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.946      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0449      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 16000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020921998 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.77       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0893      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0368      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=19200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=19200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.598       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 19200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021567311 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.525      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0839      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 22400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017585574 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.329      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0246      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=25600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=25600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.596       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020220675 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.0492     |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0895      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0208      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 554         |\n",
      "|    total_timesteps      | 28800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016622439 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0665      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0167      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=32000, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=32000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015955128 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0802      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0141      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 683         |\n",
      "|    total_timesteps      | 35200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011493931 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0743      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0122      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=38400, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=38400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 756         |\n",
      "|    total_timesteps      | 38400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011915591 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0714      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0105      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 810         |\n",
      "|    total_timesteps      | 41600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011048271 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0686      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00932     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=44800, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=44800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.608       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 886         |\n",
      "|    total_timesteps      | 44800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009883509 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0855      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00802     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 940         |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007917085 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0658      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00759     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=51200, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=51200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.607       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1013        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009774092 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0714      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00697     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1068        |\n",
      "|    total_timesteps      | 54400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009419661 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0606      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00639     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=57600, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=57600, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.613       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 1141        |\n",
      "|    total_timesteps      | 57600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008223992 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0719      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00607     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 1196        |\n",
      "|    total_timesteps      | 60800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008107832 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0614      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.0057      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=64000, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.616       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 1270        |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006214919 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0732      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.0059      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 1323         |\n",
      "|    total_timesteps      | 67200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052846624 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0743       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0188      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00572      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=70400, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.622       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1397        |\n",
      "|    total_timesteps      | 70400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008042774 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0603      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00558     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 1451         |\n",
      "|    total_timesteps      | 73600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071310354 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.825        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0645       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00536      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=76800, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=76800, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.628        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 1525         |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046293424 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.842        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0586       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0191      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00513      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 1579        |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003674879 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.842       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0633      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00513     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=83200, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=83200, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.628        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 1653         |\n",
      "|    total_timesteps      | 83200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035753392 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.841        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0984       |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00519      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 1707        |\n",
      "|    total_timesteps      | 86400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006452062 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0543      |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00515     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=89600, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=89600, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.63         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 1782         |\n",
      "|    total_timesteps      | 89600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027315188 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.852        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0397       |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00491      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1836        |\n",
      "|    total_timesteps      | 92800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003165226 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0525      |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00464     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=96000, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.63         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 1909         |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038006948 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.059        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00487      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 1964         |\n",
      "|    total_timesteps      | 99200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054578446 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.097        |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00491      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=102400, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=102400, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.634        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 2040         |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027765394 |\n",
      "|    clip_fraction        | 0.186        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.862        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0995       |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00468      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 2094        |\n",
      "|    total_timesteps      | 105600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005757394 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0816      |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.0047      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=108800, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=108800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.636        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 2168         |\n",
      "|    total_timesteps      | 108800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024207938 |\n",
      "|    clip_fraction        | 0.207        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.864        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0645       |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00461      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 2222         |\n",
      "|    total_timesteps      | 112000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038311672 |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.867        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0425       |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00458      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=115200, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=115200, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.637       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 2296        |\n",
      "|    total_timesteps      | 115200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005960324 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0816      |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00445     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 2350        |\n",
      "|    total_timesteps      | 118400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004075601 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0609      |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00445     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=121600, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=121600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.639        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 2422         |\n",
      "|    total_timesteps      | 121600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051843836 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.876        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.107        |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.0044       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 2474         |\n",
      "|    total_timesteps      | 124800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010977674 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.873        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0634       |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.0177      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00453      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=128000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.639       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 2548        |\n",
      "|    total_timesteps      | 128000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002158115 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.069       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00425     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 2602        |\n",
      "|    total_timesteps      | 131200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002484107 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0539      |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00465     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=134400, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=134400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.641        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 2677         |\n",
      "|    total_timesteps      | 134400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | -0.000601089 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.874        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0677       |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00455      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 2730         |\n",
      "|    total_timesteps      | 137600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019351959 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0809       |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00434      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=140800, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=140800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.641        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 2803         |\n",
      "|    total_timesteps      | 140800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036013103 |\n",
      "|    clip_fraction        | 0.186        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.878        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0672       |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.0188      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00433      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 2857         |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025034451 |\n",
      "|    clip_fraction        | 0.182        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0568       |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00441      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=147200, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=147200, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.641        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 2929         |\n",
      "|    total_timesteps      | 147200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048162364 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0838       |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.0189      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00424      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 2983         |\n",
      "|    total_timesteps      | 150400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017125725 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.885        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0722       |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0165      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00418      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=153600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=153600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.641        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 3056         |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031805777 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0806       |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00435      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 3110         |\n",
      "|    total_timesteps      | 156800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011523939 |\n",
      "|    clip_fraction        | 0.186        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0956       |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00399      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=160000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.64       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 3184       |\n",
      "|    total_timesteps      | 160000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00250252 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.879      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0693     |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.0168    |\n",
      "|    std                  | 0.0551     |\n",
      "|    value_loss           | 0.00443    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 3237         |\n",
      "|    total_timesteps      | 163200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029583527 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0688       |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.0174      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00442      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=166400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=166400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.639        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 3312         |\n",
      "|    total_timesteps      | 166400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003319645 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0853       |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00431      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 3368        |\n",
      "|    total_timesteps      | 169600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003130865 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0557      |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00436     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=172800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=172800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.637        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 3444         |\n",
      "|    total_timesteps      | 172800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035287214 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0593       |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00423      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 3498         |\n",
      "|    total_timesteps      | 176000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028127956 |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.889        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0785       |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.0167      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00416      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=179200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=179200, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.639       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 3572        |\n",
      "|    total_timesteps      | 179200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002150364 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0702      |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00444     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 3626         |\n",
      "|    total_timesteps      | 182400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026425195 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0554       |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00415      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=185600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=185600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.637        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 3700         |\n",
      "|    total_timesteps      | 185600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014041662 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.889        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0557       |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.0183      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00421      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 3755         |\n",
      "|    total_timesteps      | 188800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008368993 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0659       |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -0.0177      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00421      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=192000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.639        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 3831         |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023950743 |\n",
      "|    clip_fraction        | 0.191        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.889        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0686       |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.0188      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00423      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 3884         |\n",
      "|    total_timesteps      | 195200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027655745 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.068        |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.0188      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00434      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=198400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=198400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.64         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 3957         |\n",
      "|    total_timesteps      | 198400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009875023 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0634       |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00429      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 4012         |\n",
      "|    total_timesteps      | 201600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011284924 |\n",
      "|    clip_fraction        | 0.199        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.889        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0526       |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.0194      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00429      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=204800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=204800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.641         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 4086          |\n",
      "|    total_timesteps      | 204800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044559955 |\n",
      "|    clip_fraction        | 0.184         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.892         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0796        |\n",
      "|    n_updates            | 1260          |\n",
      "|    policy_gradient_loss | -0.0172       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00427       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 4139         |\n",
      "|    total_timesteps      | 208000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031858159 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0543       |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.0183      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00416      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=211200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=211200, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.639        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 4213         |\n",
      "|    total_timesteps      | 211200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040007737 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0661       |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.0184      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00424      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 4268         |\n",
      "|    total_timesteps      | 214400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032105828 |\n",
      "|    clip_fraction        | 0.206        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0558       |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.0188      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00422      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=217600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=217600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.638        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 4343         |\n",
      "|    total_timesteps      | 217600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034696602 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0559       |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00421      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 4396         |\n",
      "|    total_timesteps      | 220800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038684988 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0784       |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00416      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.637        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 4469         |\n",
      "|    total_timesteps      | 224000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024662209 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.076        |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00405      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 71            |\n",
      "|    time_elapsed         | 4524          |\n",
      "|    total_timesteps      | 227200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026292683 |\n",
      "|    clip_fraction        | 0.201         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.892         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0625        |\n",
      "|    n_updates            | 1400          |\n",
      "|    policy_gradient_loss | -0.019        |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00421       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=230400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=230400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.637        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 4600         |\n",
      "|    total_timesteps      | 230400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011757064 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.082        |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.0165      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00407      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 50             |\n",
      "|    iterations           | 73             |\n",
      "|    time_elapsed         | 4658           |\n",
      "|    total_timesteps      | 233600         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00028212072 |\n",
      "|    clip_fraction        | 0.205          |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | 91.8           |\n",
      "|    explained_variance   | 0.897          |\n",
      "|    learning_rate        | 1e-06          |\n",
      "|    loss                 | 0.0546         |\n",
      "|    n_updates            | 1440           |\n",
      "|    policy_gradient_loss | -0.0182        |\n",
      "|    std                  | 0.055          |\n",
      "|    value_loss           | 0.00398        |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=236800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=236800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.638        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 4733         |\n",
      "|    total_timesteps      | 236800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020123674 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0802       |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00397      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 4787        |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000568428 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0679      |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00415     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=243200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=243200, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.639        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 4861         |\n",
      "|    total_timesteps      | 243200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023793005 |\n",
      "|    clip_fraction        | 0.199        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0799       |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | -0.0184      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00414      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 4915         |\n",
      "|    total_timesteps      | 246400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027050972 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0958       |\n",
      "|    n_updates            | 1520         |\n",
      "|    policy_gradient_loss | -0.0169      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00399      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=249600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=249600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.639       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 4990        |\n",
      "|    total_timesteps      | 249600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000811708 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.048       |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00402     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 5045         |\n",
      "|    total_timesteps      | 252800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030344462 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0701       |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.0169      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00398      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=256000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.638        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 5120         |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030943393 |\n",
      "|    clip_fraction        | 0.204        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0675       |\n",
      "|    n_updates            | 1580         |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.004        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 5174         |\n",
      "|    total_timesteps      | 259200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021910714 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0604       |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00398      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=262400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=262400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.637        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 5247         |\n",
      "|    total_timesteps      | 262400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031293845 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0721       |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00395      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 5301        |\n",
      "|    total_timesteps      | 265600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002005397 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0681      |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00398     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=268800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=268800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.639       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 5375        |\n",
      "|    total_timesteps      | 268800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004736364 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0944      |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00373     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 5428         |\n",
      "|    total_timesteps      | 272000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010306501 |\n",
      "|    clip_fraction        | 0.191        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.061        |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00396      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=275200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=275200, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.639        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 5501         |\n",
      "|    total_timesteps      | 275200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026358236 |\n",
      "|    clip_fraction        | 0.187        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0725       |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.0167      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00377      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 5556         |\n",
      "|    total_timesteps      | 278400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018530679 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.902        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0456       |\n",
      "|    n_updates            | 1720         |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00378      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=281600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=281600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.638        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 5628         |\n",
      "|    total_timesteps      | 281600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031073021 |\n",
      "|    clip_fraction        | 0.215        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0795       |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | -0.0192      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00403      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 5680         |\n",
      "|    total_timesteps      | 284800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034712695 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0687       |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00387      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=288000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.638       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 5752        |\n",
      "|    total_timesteps      | 288000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001846075 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0522      |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00383     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 5807        |\n",
      "|    total_timesteps      | 291200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004305329 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0611      |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0038      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=294400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=294400, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.635        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 5881         |\n",
      "|    total_timesteps      | 294400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033531643 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.053        |\n",
      "|    n_updates            | 1820         |\n",
      "|    policy_gradient_loss | -0.0169      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00391      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 5936         |\n",
      "|    total_timesteps      | 297600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032114577 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0797       |\n",
      "|    n_updates            | 1840         |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00381      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=300800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=300800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.635        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 6012         |\n",
      "|    total_timesteps      | 300800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015151143 |\n",
      "|    clip_fraction        | 0.215        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.115        |\n",
      "|    n_updates            | 1860         |\n",
      "|    policy_gradient_loss | -0.0186      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00388      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 3\n",
      "Box(-100000.0, 100000.0, (93,), float64)\n",
      "seed 3: model definition ..\n",
      "Using cuda device\n",
      "seed 3: learning ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f679434af28> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f6794344240>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f679434af28> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f67943444a8>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 105          |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 3200         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041105435 |\n",
      "|    clip_fraction        | 0.219        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0684       |\n",
      "|    n_updates            | 1880         |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00375      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6400, episode_reward=0.54 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.592       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 6400        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009017096 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.00559    |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.091       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 9600        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016785393 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.787      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0882      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.063       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=12800, episode_reward=0.55 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=12800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016379314 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.719      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0452      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 16000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016666375 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.699      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0904      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0348      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=19200, episode_reward=0.55 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=19200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5         |\n",
      "|    mean_reward          | 0.596     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 53        |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 359       |\n",
      "|    total_timesteps      | 19200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0188947 |\n",
      "|    clip_fraction        | 0.206     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 91.8      |\n",
      "|    explained_variance   | -0.352    |\n",
      "|    learning_rate        | 1e-06     |\n",
      "|    loss                 | 0.0816    |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -0.0143   |\n",
      "|    std                  | 0.055     |\n",
      "|    value_loss           | 0.0283    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 22400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015106588 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.171      |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0872      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0225      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=25600, episode_reward=0.56 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=25600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016552243 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | -0.0235     |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0733      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0187      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 539        |\n",
      "|    total_timesteps      | 28800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01307432 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.23       |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0781     |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.0152     |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=32000, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=32000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 614         |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013908782 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0131      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 669         |\n",
      "|    total_timesteps      | 35200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011834135 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.067       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0109      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=38400, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=38400, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.606       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 742         |\n",
      "|    total_timesteps      | 38400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011914239 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0677      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00906     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 795        |\n",
      "|    total_timesteps      | 41600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00896607 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.642      |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0936     |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00824    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=44800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=44800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.611       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 870         |\n",
      "|    total_timesteps      | 44800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008295264 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0995      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00743     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 924         |\n",
      "|    total_timesteps      | 48000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007999862 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0834      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00676     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=51200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=51200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.613       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 998         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007873294 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00614     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 1050         |\n",
      "|    total_timesteps      | 54400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047830488 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.794        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0747       |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.017       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0058       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=57600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=57600, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.62         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 1124         |\n",
      "|    total_timesteps      | 57600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038467192 |\n",
      "|    clip_fraction        | 0.191        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.812        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0699       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00539      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 1178         |\n",
      "|    total_timesteps      | 60800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050553824 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0361       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00537      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=64000, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.624        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 1252         |\n",
      "|    total_timesteps      | 64000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069027375 |\n",
      "|    clip_fraction        | 0.213        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.825        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0732       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0197      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00544      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 1302         |\n",
      "|    total_timesteps      | 67200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058498047 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.84         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0657       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0184      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00498      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70400, episode_reward=0.62 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=70400, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.629        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 1377         |\n",
      "|    total_timesteps      | 70400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059307837 |\n",
      "|    clip_fraction        | 0.175        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0635       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.0161      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00541      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1431        |\n",
      "|    total_timesteps      | 73600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004753711 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.06        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00498     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=76800, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=76800, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.629       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 1505        |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005642402 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0769      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    std                  | 0.0551      |\n",
      "|    value_loss           | 0.00531     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 1559         |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047728107 |\n",
      "|    clip_fraction        | 0.225        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0501       |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0207      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00499      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=83200, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=83200, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5          |\n",
      "|    mean_reward          | 0.631      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 50         |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 1632       |\n",
      "|    total_timesteps      | 83200      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00478446 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 91.8       |\n",
      "|    explained_variance   | 0.85       |\n",
      "|    learning_rate        | 1e-06      |\n",
      "|    loss                 | 0.0612     |\n",
      "|    n_updates            | 500        |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    std                  | 0.055      |\n",
      "|    value_loss           | 0.00496    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 1686         |\n",
      "|    total_timesteps      | 86400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031751276 |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0649       |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.018       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0046       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=89600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=89600, episode_reward=0.63 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.632        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 1760         |\n",
      "|    total_timesteps      | 89600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042630434 |\n",
      "|    clip_fraction        | 0.187        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.865        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0411       |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0177      |\n",
      "|    std                  | 0.0551       |\n",
      "|    value_loss           | 0.00462      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 1813         |\n",
      "|    total_timesteps      | 92800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038997054 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.854        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.05         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00489      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=96000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.636        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 1887         |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027075268 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0539       |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00492      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 1942         |\n",
      "|    total_timesteps      | 99200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037949204 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0512       |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0048       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=102400, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=102400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.64        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 2017        |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005698534 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0619      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00461     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 2071         |\n",
      "|    total_timesteps      | 105600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035931421 |\n",
      "|    clip_fraction        | 0.212        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.867        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0641       |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0199      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00475      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=108800, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=108800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.645        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 2143         |\n",
      "|    total_timesteps      | 108800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018417168 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.866        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.07         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0178      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00461      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 2198         |\n",
      "|    total_timesteps      | 112000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021522974 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.081        |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0047       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=115200, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=115200, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.644        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 2276         |\n",
      "|    total_timesteps      | 115200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038620161 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.862        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0591       |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00491      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 2331         |\n",
      "|    total_timesteps      | 118400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035543155 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0676       |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00505      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=121600, episode_reward=0.66 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=121600, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.648        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 2405         |\n",
      "|    total_timesteps      | 121600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015460826 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0706       |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.0184      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00459      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 2460         |\n",
      "|    total_timesteps      | 124800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023955011 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.867        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0861       |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.018       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00486      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=128000, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.647        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 2532         |\n",
      "|    total_timesteps      | 128000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016362619 |\n",
      "|    clip_fraction        | 0.206        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.865        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.092        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0203      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00486      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 2586         |\n",
      "|    total_timesteps      | 131200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048561334 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.872        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0577       |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00464      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=134400, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=134400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.65         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 2660         |\n",
      "|    total_timesteps      | 134400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039079594 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0754       |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00468      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 2709        |\n",
      "|    total_timesteps      | 137600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002797122 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0702      |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00484     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=140800, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=140800, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.653         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 2782          |\n",
      "|    total_timesteps      | 140800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020639897 |\n",
      "|    clip_fraction        | 0.195         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.868         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0425        |\n",
      "|    n_updates            | 860           |\n",
      "|    policy_gradient_loss | -0.0191       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00483       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 2837          |\n",
      "|    total_timesteps      | 144000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025862694 |\n",
      "|    clip_fraction        | 0.183         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.871         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0621        |\n",
      "|    n_updates            | 880           |\n",
      "|    policy_gradient_loss | -0.0175       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00474       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=147200, episode_reward=0.67 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=147200, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.654       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 2911        |\n",
      "|    total_timesteps      | 147200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002921629 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.8        |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0663      |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00485     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 47            |\n",
      "|    time_elapsed         | 2964          |\n",
      "|    total_timesteps      | 150400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015493394 |\n",
      "|    clip_fraction        | 0.176         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.884         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0521        |\n",
      "|    n_updates            | 920           |\n",
      "|    policy_gradient_loss | -0.0169       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00436       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=153600, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=153600, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.653        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 3036         |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027827597 |\n",
      "|    clip_fraction        | 0.203        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.872        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.052        |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0183      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00485      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 3091         |\n",
      "|    total_timesteps      | 156800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.706051e-06 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0643       |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00444      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=160000, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.652        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 3166         |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012513566 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0684       |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00482      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 3218         |\n",
      "|    total_timesteps      | 163200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023255586 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0591       |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00472      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=166400, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=166400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.652        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 3291         |\n",
      "|    total_timesteps      | 166400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020794605 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.886        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0606       |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00429      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 3345         |\n",
      "|    total_timesteps      | 169600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015958619 |\n",
      "|    clip_fraction        | 0.182        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.874        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0842       |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00462      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=172800, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=172800, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.651        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 3420         |\n",
      "|    total_timesteps      | 172800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024444414 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0486       |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00472      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 3473         |\n",
      "|    total_timesteps      | 176000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016578793 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.878        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0497       |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.0192      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00471      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=179200, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=179200, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.651        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 3545         |\n",
      "|    total_timesteps      | 179200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042760633 |\n",
      "|    clip_fraction        | 0.205        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0662       |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.0196      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00471      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 3609         |\n",
      "|    total_timesteps      | 182400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036493754 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.887        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0834       |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.018       |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00435      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=185600, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=185600, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.649         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 58            |\n",
      "|    time_elapsed         | 3682          |\n",
      "|    total_timesteps      | 185600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0005872202 |\n",
      "|    clip_fraction        | 0.195         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.883         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.075         |\n",
      "|    n_updates            | 1140          |\n",
      "|    policy_gradient_loss | -0.0183       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00449       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 3737         |\n",
      "|    total_timesteps      | 188800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022477626 |\n",
      "|    clip_fraction        | 0.187        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.883        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0559       |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00446      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=192000, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.648         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 60            |\n",
      "|    time_elapsed         | 3811          |\n",
      "|    total_timesteps      | 192000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021948814 |\n",
      "|    clip_fraction        | 0.181         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.883         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0752        |\n",
      "|    n_updates            | 1180          |\n",
      "|    policy_gradient_loss | -0.0168       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00452       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 3864         |\n",
      "|    total_timesteps      | 195200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021627354 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.88         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0894       |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.0192      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00462      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=198400, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=198400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.648        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 3936         |\n",
      "|    total_timesteps      | 198400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032184862 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.878        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0626       |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.0174      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00476      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 3991         |\n",
      "|    total_timesteps      | 201600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019792581 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.887        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.08         |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00439      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=204800, episode_reward=0.68 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=204800, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.649         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 4065          |\n",
      "|    total_timesteps      | 204800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073186395 |\n",
      "|    clip_fraction        | 0.191         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.8          |\n",
      "|    explained_variance   | 0.889         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.118         |\n",
      "|    n_updates            | 1260          |\n",
      "|    policy_gradient_loss | -0.0175       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00428       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 4117         |\n",
      "|    total_timesteps      | 208000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011764121 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.887        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0714       |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.0182      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00434      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=211200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=211200, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.649        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 4190         |\n",
      "|    total_timesteps      | 211200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018710517 |\n",
      "|    clip_fraction        | 0.186        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.8         |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0953       |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00463      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 4244        |\n",
      "|    total_timesteps      | 214400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004249089 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.0043      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=217600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=217600, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.647        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 4319         |\n",
      "|    total_timesteps      | 217600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008210945 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.885        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0631       |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00447      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 4374         |\n",
      "|    total_timesteps      | 220800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025890493 |\n",
      "|    clip_fraction        | 0.19         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0725       |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0046       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.647         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 70            |\n",
      "|    time_elapsed         | 4447          |\n",
      "|    total_timesteps      | 224000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027992725 |\n",
      "|    clip_fraction        | 0.193         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.9          |\n",
      "|    explained_variance   | 0.884         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.094         |\n",
      "|    n_updates            | 1380          |\n",
      "|    policy_gradient_loss | -0.0184       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00453       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 4502         |\n",
      "|    total_timesteps      | 227200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013690925 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.889        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0688       |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.0161      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00442      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=230400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=230400, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.646         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 72            |\n",
      "|    time_elapsed         | 4576          |\n",
      "|    total_timesteps      | 230400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074578763 |\n",
      "|    clip_fraction        | 0.185         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.9          |\n",
      "|    explained_variance   | 0.886         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0327        |\n",
      "|    n_updates            | 1420          |\n",
      "|    policy_gradient_loss | -0.0173       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00447       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 73            |\n",
      "|    time_elapsed         | 4631          |\n",
      "|    total_timesteps      | 233600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | -0.0021239351 |\n",
      "|    clip_fraction        | 0.192         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.9          |\n",
      "|    explained_variance   | 0.889         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0977        |\n",
      "|    n_updates            | 1440          |\n",
      "|    policy_gradient_loss | -0.0184       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00434       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=236800, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=236800, episode_reward=0.65 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.646       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 4704        |\n",
      "|    total_timesteps      | 236800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000581181 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.063       |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00442     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 4760         |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021348237 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.889        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.108        |\n",
      "|    n_updates            | 1480         |\n",
      "|    policy_gradient_loss | -0.0181      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00426      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=243200, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=243200, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.644       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 4833        |\n",
      "|    total_timesteps      | 243200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003445723 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0559      |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00435     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 4887         |\n",
      "|    total_timesteps      | 246400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014051128 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0903       |\n",
      "|    n_updates            | 1520         |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00432      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=249600, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=249600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.644        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 4960         |\n",
      "|    total_timesteps      | 249600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026013087 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0527       |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | -0.0168      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00426      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 5014         |\n",
      "|    total_timesteps      | 252800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.770279e-05 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.887        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0855       |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.0163      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00425      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=256000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.643        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 5087         |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017504954 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.891        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0685       |\n",
      "|    n_updates            | 1580         |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00428      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 5141         |\n",
      "|    total_timesteps      | 259200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018072843 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0418       |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.0041       |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=262400, episode_reward=0.69 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=262400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.644        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 5215         |\n",
      "|    total_timesteps      | 262400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043759034 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0639       |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.0177      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00408      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 5268         |\n",
      "|    total_timesteps      | 265600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033568668 |\n",
      "|    clip_fraction        | 0.204        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0845       |\n",
      "|    n_updates            | 1640         |\n",
      "|    policy_gradient_loss | -0.0189      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00409      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=268800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=268800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5           |\n",
      "|    mean_reward          | 0.643       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 5339        |\n",
      "|    total_timesteps      | 268800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005056448 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0568      |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.00397     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 5388        |\n",
      "|    total_timesteps      | 272000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004210329 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 91.9        |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0884      |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    std                  | 0.055       |\n",
      "|    value_loss           | 0.004       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=275200, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=275200, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.643        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 5463         |\n",
      "|    total_timesteps      | 275200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014798951 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.101        |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.0177      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00401      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 87            |\n",
      "|    time_elapsed         | 5517          |\n",
      "|    total_timesteps      | 278400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074130297 |\n",
      "|    clip_fraction        | 0.216         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.9          |\n",
      "|    explained_variance   | 0.891         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0753        |\n",
      "|    n_updates            | 1720          |\n",
      "|    policy_gradient_loss | -0.0196       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00419       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=281600, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=281600, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.643        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 5590         |\n",
      "|    total_timesteps      | 281600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033871245 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0882       |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00415      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 5644         |\n",
      "|    total_timesteps      | 284800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042266105 |\n",
      "|    clip_fraction        | 0.187        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0673       |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.0174      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00393      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "Eval num_timesteps=288000, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.641        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 5718         |\n",
      "|    total_timesteps      | 288000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022346687 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0724       |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.0179      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00405      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 5782         |\n",
      "|    total_timesteps      | 291200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030605244 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0472       |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.0177      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00389      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=294400, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=294400, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5             |\n",
      "|    mean_reward          | 0.641         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 92            |\n",
      "|    time_elapsed         | 5855          |\n",
      "|    total_timesteps      | 294400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015796661 |\n",
      "|    clip_fraction        | 0.199         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 91.9          |\n",
      "|    explained_variance   | 0.895         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0744        |\n",
      "|    n_updates            | 1820          |\n",
      "|    policy_gradient_loss | -0.0178       |\n",
      "|    std                  | 0.055         |\n",
      "|    value_loss           | 0.00395       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 5907         |\n",
      "|    total_timesteps      | 297600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042018485 |\n",
      "|    clip_fraction        | 0.199        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0774       |\n",
      "|    n_updates            | 1840         |\n",
      "|    policy_gradient_loss | -0.0189      |\n",
      "|    std                  | 0.055        |\n",
      "|    value_loss           | 0.00404      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=300800, episode_reward=0.70 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=300800, episode_reward=0.64 +/- 0.00\n",
      "Episode length: 5.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5            |\n",
      "|    mean_reward          | 0.642        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 5979         |\n",
      "|    total_timesteps      | 300800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024415182 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 91.9         |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0411       |\n",
      "|    n_updates            | 1860         |\n",
      "|    policy_gradient_loss | -0.017       |\n",
      "|    std                  | 0.0549       |\n",
      "|    value_loss           | 0.00393      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox  6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seed in range(1,4):\n",
    "    if True:\n",
    "        print(f'seed {seed}')\n",
    "        log_dir = './data/'+case+'/seed_'+str(seed)\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        num_cpu = 64\n",
    "        env_train.seed(seed)\n",
    "        env_eval.seed(seed)\n",
    "        env_train_ = env_wrappers(env_train, x_coords, y_coords)\n",
    "        env_eval_ = env_wrappers(env_eval, x_coords, y_coords)\n",
    "        train_callback = CustomEvalCallback( env_train_, \n",
    "                                            best_model_save_path=None, \n",
    "                                            n_eval_episodes=1,\n",
    "                                            log_path=str(log_dir)+'/results_train', \n",
    "                                            eval_freq=100)\n",
    "        callback_list = [train_callback]\n",
    "        eval_callback = CustomEvalCallback( env_eval_, \n",
    "                                           best_model_save_path=str(log_dir)+'/best_model_eval', \n",
    "                                           n_eval_episodes=1,\n",
    "                                           log_path=str(log_dir)+'/results_eval', \n",
    "                                           eval_freq=100)\n",
    "        callback_list.append(eval_callback)\n",
    "        callback = CallbackList(callback_list)\n",
    "        env = SubprocVecEnv([make_env(env_train_, i, seed) for i in range(num_cpu)])\n",
    "        print(env.observation_space)\n",
    "#     env = VecMonitor(env, filename=log_dir)\n",
    "        print(f'seed {seed}: model definition ..')\n",
    "        model = PPO(policy=MlpPolicy,\n",
    "            env=env,\n",
    "            learning_rate = 1e-6,\n",
    "            n_steps = 50,\n",
    "            batch_size = 16,\n",
    "            n_epochs = 20,\n",
    "            gamma = 0.99,\n",
    "            gae_lambda = 0.95,\n",
    "            clip_range = 0.1,\n",
    "            clip_range_vf = None,\n",
    "            ent_coef = 0.001,\n",
    "            vf_coef = 0.5,\n",
    "            max_grad_norm = 0.5,\n",
    "            use_sde= False,\n",
    "            create_eval_env= False,\n",
    "            policy_kwargs = dict(net_arch=[150,100,80], log_std_init=-2.9),\n",
    "            verbose = 1,\n",
    "            target_kl = 0.05,\n",
    "            seed = seed,\n",
    "            device = \"auto\")\n",
    "        print(f'seed {seed}: learning ..')\n",
    "        model.learn(total_timesteps=300000, callback=callback)\n",
    "        model.save(log_dir+'/PPO')\n",
    "        del model\n",
    "        fig = plot_learning(log_dir, case='train')\n",
    "        fig.savefig(log_dir+'/learn_train.png')\n",
    "        fig = plot_learning(log_dir, case='eval')\n",
    "        fig.savefig(log_dir+'/learn_eval.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
