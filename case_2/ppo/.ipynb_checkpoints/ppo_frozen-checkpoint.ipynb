{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to access functions from other locations\n",
    "import sys\n",
    "sys.path.append('/data/ad181/RemoteDir/rl_robust_owc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ad181/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "from stable_baselines3.ppo import PPO, MlpPolicy\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "from utils.custom_eval_callback import CustomEvalCallback\n",
    "from typing import Callable\n",
    "\n",
    "from utils.plot_functions import plot_learning\n",
    "from utils.env_wrappers import StepReset, StateCoarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1\n",
    "case='case_2_ppo_frozen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./data', exist_ok=True)\n",
    "os.makedirs('./data/'+case, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../envs_params/env_data/env_train.pkl', 'rb') as input:\n",
    "    env_train = pickle.load(input)\n",
    "k_list_train = env_train.k_list[4]\n",
    "env_train.set_k(np.array([k_list_train]))\n",
    "\n",
    "with open('../envs_params/env_data/env_eval.pkl', 'rb') as input:\n",
    "    env_eval = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env wrapper to reduce state space\n",
    "x_coords, y_coords = env_train.p_x, env_train.p_y\n",
    "\n",
    "def env_wrappers(env, x_coords, y_coords):\n",
    "    env = StepReset(env)\n",
    "    env = StateCoarse(env, x_coords, y_coords, include_well_pr=True)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_train = env_wrappers(env_train, x_coords, y_coords)\n",
    "# print(env_train.observation_space)\n",
    "# base_action = np.ones(env_train.action_space.shape[0])\n",
    "\n",
    "# state, done = env_train.reset(), False\n",
    "# print(state)\n",
    "# while not done:\n",
    "#     state, reward, done, info = env_train.step(base_action)\n",
    "#     print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env, rank: int, seed: int) -> Callable:\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "    \n",
    "    :param env_id: (str) the environment ID\n",
    "    :param num_env: (int) the number of environment you wish to have in subprocesses\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    :return: (Callable)\n",
    "    \"\"\"\n",
    "    def _init() -> gym.Env:\n",
    "        env_ = env\n",
    "        env_.seed(seed + rank)\n",
    "        return env_\n",
    "    return _init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1\n",
      "Box(-100000.0, 100000.0, (9,), float64)\n",
      "seed 1: model definition ..\n",
      "Using cuda device\n",
      "seed 1: learning ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7fae0da5f1d0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fae0da5f160>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7fae0da5f1d0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fae0da5f198>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 242  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 13   |\n",
      "|    total_timesteps | 3200 |\n",
      "-----------------------------\n",
      "Eval num_timesteps=6400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6400, episode_reward=0.54 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4          |\n",
      "|    mean_reward          | 0.54       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 118        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 6400       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00267396 |\n",
      "|    clip_fraction        | 0.0988     |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 2.41       |\n",
      "|    explained_variance   | -0.0375    |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.023     |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00374   |\n",
      "|    std                  | 0.149      |\n",
      "|    value_loss           | 0.0481     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 9600         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037434641 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.42         |\n",
      "|    explained_variance   | 0.776        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0292      |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 0.149        |\n",
      "|    value_loss           | 0.00242      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12800, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=12800, episode_reward=0.56 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.562       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004844548 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.42        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -5.94e-05   |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.149       |\n",
      "|    value_loss           | 0.00173     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 98           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 16000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039849747 |\n",
      "|    clip_fraction        | 0.259        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.44         |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0186      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    std                  | 0.148        |\n",
      "|    value_loss           | 0.00141      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19200, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=19200, episode_reward=0.56 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.559       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 19200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004232569 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.46        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0331     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 0.148       |\n",
      "|    value_loss           | 0.00122     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 94           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 237          |\n",
      "|    total_timesteps      | 22400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042516645 |\n",
      "|    clip_fraction        | 0.223        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.49         |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0014      |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    std                  | 0.147        |\n",
      "|    value_loss           | 0.00109      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=25600, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=25600, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.571        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 284          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022721835 |\n",
      "|    clip_fraction        | 0.233        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.52         |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0115       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    std                  | 0.146        |\n",
      "|    value_loss           | 0.000969     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 319          |\n",
      "|    total_timesteps      | 28800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044320016 |\n",
      "|    clip_fraction        | 0.226        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.55         |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0495      |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0136      |\n",
      "|    std                  | 0.145        |\n",
      "|    value_loss           | 0.000902     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=32000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=32000, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.578       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 32000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004938473 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0079     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    std                  | 0.145       |\n",
      "|    value_loss           | 0.000869    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 406          |\n",
      "|    total_timesteps      | 35200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024109734 |\n",
      "|    clip_fraction        | 0.215        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.58         |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0244       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    std                  | 0.144        |\n",
      "|    value_loss           | 0.000808     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=38400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=38400, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.583       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 445         |\n",
      "|    total_timesteps      | 38400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004998315 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.61        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    std                  | 0.144       |\n",
      "|    value_loss           | 0.000832    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 479          |\n",
      "|    total_timesteps      | 41600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024985666 |\n",
      "|    clip_fraction        | 0.183        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.63         |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0148       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 0.000751     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=44800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=44800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.586       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 519         |\n",
      "|    total_timesteps      | 44800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002483385 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.67        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0424      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 0.000732    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 86            |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 552           |\n",
      "|    total_timesteps      | 48000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039683306 |\n",
      "|    clip_fraction        | 0.171         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 2.7           |\n",
      "|    explained_variance   | 0.977         |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.0239        |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.00893      |\n",
      "|    std                  | 0.141         |\n",
      "|    value_loss           | 0.000734      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=51200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=51200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.585        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 592          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038859362 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.72         |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.014       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    std                  | 0.14         |\n",
      "|    value_loss           | 0.000696     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 626         |\n",
      "|    total_timesteps      | 54400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004308698 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00486     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    std                  | 0.14        |\n",
      "|    value_loss           | 0.000727    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=57600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=57600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.586        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 665          |\n",
      "|    total_timesteps      | 57600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034443268 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.8          |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00998      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00825     |\n",
      "|    std                  | 0.138        |\n",
      "|    value_loss           | 0.000645     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 700          |\n",
      "|    total_timesteps      | 60800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029910982 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.83         |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0268      |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00893     |\n",
      "|    std                  | 0.137        |\n",
      "|    value_loss           | 0.000622     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=64000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=64000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.587        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 740          |\n",
      "|    total_timesteps      | 64000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028720677 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.87         |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0206      |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00918     |\n",
      "|    std                  | 0.136        |\n",
      "|    value_loss           | 0.000628     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 775         |\n",
      "|    total_timesteps      | 67200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003340736 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.91        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00024    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.000611    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=70400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.588        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 817          |\n",
      "|    total_timesteps      | 70400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038518417 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.94         |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0208      |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00701     |\n",
      "|    std                  | 0.134        |\n",
      "|    value_loss           | 0.000557     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 852          |\n",
      "|    total_timesteps      | 73600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035288883 |\n",
      "|    clip_fraction        | 0.181        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.99         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0118      |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00835     |\n",
      "|    std                  | 0.133        |\n",
      "|    value_loss           | 0.00058      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=76800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=76800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.587       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 894         |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005200817 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.03        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0335      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    std                  | 0.132       |\n",
      "|    value_loss           | 0.000553    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 929         |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003959552 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000811    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    std                  | 0.131       |\n",
      "|    value_loss           | 0.000542    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=83200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=83200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.589        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 971          |\n",
      "|    total_timesteps      | 83200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038987172 |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.11         |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.013        |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    std                  | 0.13         |\n",
      "|    value_loss           | 0.000547     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 1016         |\n",
      "|    total_timesteps      | 86400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050284434 |\n",
      "|    clip_fraction        | 0.186        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.14         |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0111       |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00867     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 0.000518     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=89600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=89600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.591       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1055        |\n",
      "|    total_timesteps      | 89600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003378274 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.19        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0152      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 0.000505    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 1091         |\n",
      "|    total_timesteps      | 92800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022173785 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.23         |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00957     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    std                  | 0.127        |\n",
      "|    value_loss           | 0.000473     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=96000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.59         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 1130         |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044492707 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.28         |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00295     |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00746     |\n",
      "|    std                  | 0.126        |\n",
      "|    value_loss           | 0.000473     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 1166         |\n",
      "|    total_timesteps      | 99200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033875487 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0313       |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00703     |\n",
      "|    std                  | 0.124        |\n",
      "|    value_loss           | 0.000437     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=102400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=102400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 4             |\n",
      "|    mean_reward          | 0.592         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 84            |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 1206          |\n",
      "|    total_timesteps      | 102400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016663477 |\n",
      "|    clip_fraction        | 0.157         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 3.39          |\n",
      "|    explained_variance   | 0.987         |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | -0.00736      |\n",
      "|    n_updates            | 620           |\n",
      "|    policy_gradient_loss | -0.00633      |\n",
      "|    std                  | 0.123         |\n",
      "|    value_loss           | 0.000455      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 1240         |\n",
      "|    total_timesteps      | 105600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036629809 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0226      |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.0079      |\n",
      "|    std                  | 0.121        |\n",
      "|    value_loss           | 0.000457     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=108800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=108800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4          |\n",
      "|    mean_reward          | 0.593      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 84         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 1280       |\n",
      "|    total_timesteps      | 108800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00159997 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 3.5        |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0187     |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.00656   |\n",
      "|    std                  | 0.12       |\n",
      "|    value_loss           | 0.000418   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1315        |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001721256 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.54        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00458     |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 0.000405    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=115200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=115200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.593        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 1357         |\n",
      "|    total_timesteps      | 115200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023243886 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.59         |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00547     |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    std                  | 0.118        |\n",
      "|    value_loss           | 0.000413     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 1392         |\n",
      "|    total_timesteps      | 118400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024022358 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.65         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00357      |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    std                  | 0.117        |\n",
      "|    value_loss           | 0.000383     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=121600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=121600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.594        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 1432         |\n",
      "|    total_timesteps      | 121600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009487516 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.7          |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00552      |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    std                  | 0.116        |\n",
      "|    value_loss           | 0.000363     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 1467         |\n",
      "|    total_timesteps      | 124800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023114278 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.73         |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0376      |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    std                  | 0.115        |\n",
      "|    value_loss           | 0.000351     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=128000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.595        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 1508         |\n",
      "|    total_timesteps      | 128000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024456063 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.78         |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00456     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    std                  | 0.114        |\n",
      "|    value_loss           | 0.000359     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 1545         |\n",
      "|    total_timesteps      | 131200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029679097 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.81         |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0132      |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    std                  | 0.114        |\n",
      "|    value_loss           | 0.000311     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=134400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=134400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1594        |\n",
      "|    total_timesteps      | 134400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004317246 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.86        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0104      |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    std                  | 0.112       |\n",
      "|    value_loss           | 0.000303    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 1627         |\n",
      "|    total_timesteps      | 137600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019056511 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.89         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00114     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    std                  | 0.112        |\n",
      "|    value_loss           | 0.000282     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=140800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=140800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1667        |\n",
      "|    total_timesteps      | 140800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006679311 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.92        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0101     |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    std                  | 0.111       |\n",
      "|    value_loss           | 0.000305    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 1701         |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020808592 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.97         |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0129      |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    std                  | 0.11         |\n",
      "|    value_loss           | 0.000292     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=147200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=147200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.593       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1741        |\n",
      "|    total_timesteps      | 147200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002111391 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.02        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00629    |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    std                  | 0.109       |\n",
      "|    value_loss           | 0.000275    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1780        |\n",
      "|    total_timesteps      | 150400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002466262 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.08        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0305      |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    std                  | 0.108       |\n",
      "|    value_loss           | 0.000275    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=153600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=153600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.594        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 1820         |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024351915 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.14         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0219      |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0066      |\n",
      "|    std                  | 0.106        |\n",
      "|    value_loss           | 0.000282     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 84        |\n",
      "|    iterations           | 49        |\n",
      "|    time_elapsed         | 1855      |\n",
      "|    total_timesteps      | 156800    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0022516 |\n",
      "|    clip_fraction        | 0.157     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | 4.19      |\n",
      "|    explained_variance   | 0.993     |\n",
      "|    learning_rate        | 5e-05     |\n",
      "|    loss                 | 0.0119    |\n",
      "|    n_updates            | 960       |\n",
      "|    policy_gradient_loss | -0.00465  |\n",
      "|    std                  | 0.106     |\n",
      "|    value_loss           | 0.000252  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=160000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.594        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 1896         |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063390685 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.24         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0128      |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    std                  | 0.105        |\n",
      "|    value_loss           | 0.000248     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 1930         |\n",
      "|    total_timesteps      | 163200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055977986 |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.27         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0182      |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    std                  | 0.104        |\n",
      "|    value_loss           | 0.000251     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=166400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=166400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.595        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 1970         |\n",
      "|    total_timesteps      | 166400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012643083 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.31         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0174       |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    std                  | 0.103        |\n",
      "|    value_loss           | 0.000233     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 2004        |\n",
      "|    total_timesteps      | 169600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002133987 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.34        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0184     |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    std                  | 0.103       |\n",
      "|    value_loss           | 0.000235    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=172800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=172800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.596        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 2044         |\n",
      "|    total_timesteps      | 172800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019568517 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.4          |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00751     |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    std                  | 0.101        |\n",
      "|    value_loss           | 0.000219     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 2079         |\n",
      "|    total_timesteps      | 176000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029004533 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.47         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0175      |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    std                  | 0.0999       |\n",
      "|    value_loss           | 0.000225     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=179200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=179200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 2119        |\n",
      "|    total_timesteps      | 179200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001720041 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.52        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0111      |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    std                  | 0.0992      |\n",
      "|    value_loss           | 0.000226    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 2153        |\n",
      "|    total_timesteps      | 182400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002795378 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.56        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00785     |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    std                  | 0.0984      |\n",
      "|    value_loss           | 0.000208    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=185600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=185600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 2193        |\n",
      "|    total_timesteps      | 185600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003771116 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.61        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0191     |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    std                  | 0.0976      |\n",
      "|    value_loss           | 0.000207    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 2228        |\n",
      "|    total_timesteps      | 188800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004517777 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.67        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00511     |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    std                  | 0.0963      |\n",
      "|    value_loss           | 0.000196    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=192000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.595        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 2269         |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020502233 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.72         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0114      |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    std                  | 0.0957       |\n",
      "|    value_loss           | 0.000169     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 2304        |\n",
      "|    total_timesteps      | 195200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003463716 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.77        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    std                  | 0.0947      |\n",
      "|    value_loss           | 0.000178    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=198400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=198400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.597        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 2343         |\n",
      "|    total_timesteps      | 198400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057343496 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.81         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00797     |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    std                  | 0.0942       |\n",
      "|    value_loss           | 0.000186     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 2379         |\n",
      "|    total_timesteps      | 201600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015886207 |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.85         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0253       |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    std                  | 0.0934       |\n",
      "|    value_loss           | 0.000172     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=204800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=204800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 2418        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004388738 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.89        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    std                  | 0.0928      |\n",
      "|    value_loss           | 0.000167    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 2463         |\n",
      "|    total_timesteps      | 208000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046326006 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.92         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00205     |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    std                  | 0.0924       |\n",
      "|    value_loss           | 0.000164     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=211200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=211200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.597        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 2502         |\n",
      "|    total_timesteps      | 211200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038481709 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.97         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.018        |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    std                  | 0.0913       |\n",
      "|    value_loss           | 0.000151     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 2536         |\n",
      "|    total_timesteps      | 214400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026914054 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.03         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0126       |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    std                  | 0.0904       |\n",
      "|    value_loss           | 0.000154     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=217600, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=217600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 4             |\n",
      "|    mean_reward          | 0.597         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 84            |\n",
      "|    iterations           | 68            |\n",
      "|    time_elapsed         | 2575          |\n",
      "|    total_timesteps      | 217600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027036955 |\n",
      "|    clip_fraction        | 0.146         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 5.07          |\n",
      "|    explained_variance   | 0.996         |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.0401        |\n",
      "|    n_updates            | 1340          |\n",
      "|    policy_gradient_loss | -0.00352      |\n",
      "|    std                  | 0.0899        |\n",
      "|    value_loss           | 0.000136      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 2609         |\n",
      "|    total_timesteps      | 220800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009544136 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.11         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0125       |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    std                  | 0.0893       |\n",
      "|    value_loss           | 0.000137     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=224000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.595        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 2649         |\n",
      "|    total_timesteps      | 224000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003437897 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.15         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0336       |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    std                  | 0.0884       |\n",
      "|    value_loss           | 0.000136     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 2682         |\n",
      "|    total_timesteps      | 227200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021478855 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.19         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0137      |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    std                  | 0.088        |\n",
      "|    value_loss           | 0.000127     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=230400, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=230400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.596        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 2722         |\n",
      "|    total_timesteps      | 230400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024309417 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.24         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000141     |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    std                  | 0.0869       |\n",
      "|    value_loss           | 0.000125     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 2755        |\n",
      "|    total_timesteps      | 233600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004334349 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.3         |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00901    |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    std                  | 0.086       |\n",
      "|    value_loss           | 0.000127    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=236800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=236800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.598        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 2796         |\n",
      "|    total_timesteps      | 236800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031757532 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.35         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0103      |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    std                  | 0.0856       |\n",
      "|    value_loss           | 0.000118     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 2829         |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024683934 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.39         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00149     |\n",
      "|    n_updates            | 1480         |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    std                  | 0.0848       |\n",
      "|    value_loss           | 0.000114     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=243200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=243200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.599        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 2869         |\n",
      "|    total_timesteps      | 243200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037415505 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.44         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0336      |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    std                  | 0.084        |\n",
      "|    value_loss           | 0.000105     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 2903         |\n",
      "|    total_timesteps      | 246400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032117588 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.49         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0026      |\n",
      "|    n_updates            | 1520         |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    std                  | 0.0834       |\n",
      "|    value_loss           | 0.000112     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=249600, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=249600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.597       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 2943        |\n",
      "|    total_timesteps      | 249600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004458777 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.55        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00436     |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    std                  | 0.0822      |\n",
      "|    value_loss           | 0.000105    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 2978         |\n",
      "|    total_timesteps      | 252800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029449158 |\n",
      "|    clip_fraction        | 0.163        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.61         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0576       |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    std                  | 0.0813       |\n",
      "|    value_loss           | 0.000103     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=256000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.598        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 3018         |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014949451 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.66         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0308      |\n",
      "|    n_updates            | 1580         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    std                  | 0.0806       |\n",
      "|    value_loss           | 9.31e-05     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 84            |\n",
      "|    iterations           | 81            |\n",
      "|    time_elapsed         | 3053          |\n",
      "|    total_timesteps      | 259200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057067664 |\n",
      "|    clip_fraction        | 0.155         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 5.71          |\n",
      "|    explained_variance   | 0.998         |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | -0.0407       |\n",
      "|    n_updates            | 1600          |\n",
      "|    policy_gradient_loss | -0.00308      |\n",
      "|    std                  | 0.0799        |\n",
      "|    value_loss           | 8.89e-05      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=262400, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=262400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 3103         |\n",
      "|    total_timesteps      | 262400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015871965 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.76         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00544     |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    std                  | 0.0792       |\n",
      "|    value_loss           | 9.05e-05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 3138         |\n",
      "|    total_timesteps      | 265600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025631308 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.81         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0134       |\n",
      "|    n_updates            | 1640         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    std                  | 0.0784       |\n",
      "|    value_loss           | 8.53e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=268800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=268800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.6         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 3178        |\n",
      "|    total_timesteps      | 268800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005004279 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.86        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00605    |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    std                  | 0.0779      |\n",
      "|    value_loss           | 7.98e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 3212         |\n",
      "|    total_timesteps      | 272000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050630365 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.9          |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00334     |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    std                  | 0.0775       |\n",
      "|    value_loss           | 8.49e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=275200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=275200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 3251         |\n",
      "|    total_timesteps      | 275200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051114904 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.93         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0237       |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    std                  | 0.077        |\n",
      "|    value_loss           | 8.37e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 3286        |\n",
      "|    total_timesteps      | 278400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003443205 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.99        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0139      |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    std                  | 0.0761      |\n",
      "|    value_loss           | 7.48e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=281600, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=281600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 4             |\n",
      "|    mean_reward          | 0.6           |\n",
      "| time/                   |               |\n",
      "|    fps                  | 84            |\n",
      "|    iterations           | 88            |\n",
      "|    time_elapsed         | 3325          |\n",
      "|    total_timesteps      | 281600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1861287e-05 |\n",
      "|    clip_fraction        | 0.145         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 6.04          |\n",
      "|    explained_variance   | 0.998         |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.00857       |\n",
      "|    n_updates            | 1740          |\n",
      "|    policy_gradient_loss | -0.0019       |\n",
      "|    std                  | 0.0756        |\n",
      "|    value_loss           | 6.62e-05      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 3358         |\n",
      "|    total_timesteps      | 284800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020473646 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 6.09         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0188       |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    std                  | 0.0748       |\n",
      "|    value_loss           | 6.5e-05      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=288000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 3399         |\n",
      "|    total_timesteps      | 288000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032951194 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 6.13         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0176      |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    std                  | 0.0745       |\n",
      "|    value_loss           | 6.32e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 3432        |\n",
      "|    total_timesteps      | 291200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004426299 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 6.16        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0337     |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    std                  | 0.0742      |\n",
      "|    value_loss           | 6.52e-05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=294400, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=294400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 3473         |\n",
      "|    total_timesteps      | 294400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044774963 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 6.19         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00104      |\n",
      "|    n_updates            | 1820         |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    std                  | 0.0737       |\n",
      "|    value_loss           | 6.47e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 3507        |\n",
      "|    total_timesteps      | 297600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003084598 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 6.23        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0222      |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    std                  | 0.0734      |\n",
      "|    value_loss           | 6.55e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=300800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 3547         |\n",
      "|    total_timesteps      | 300800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016734138 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 6.26         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00986     |\n",
      "|    n_updates            | 1860         |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    std                  | 0.0731       |\n",
      "|    value_loss           | 6.39e-05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 2\n",
      "Box(-100000.0, 100000.0, (9,), float64)\n",
      "seed 2: model definition ..\n",
      "Using cuda device\n",
      "seed 2: learning ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7fae00658a58> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fae08040940>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7fae00658a58> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fae006800b8>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 239        |\n",
      "|    iterations           | 1          |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 3200       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00389408 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 6.29       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0234     |\n",
      "|    n_updates            | 1880       |\n",
      "|    policy_gradient_loss | -0.00271   |\n",
      "|    std                  | 0.0726     |\n",
      "|    value_loss           | 5.85e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=6400, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6400, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4          |\n",
      "|    mean_reward          | 0.567      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 119        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 6400       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00358303 |\n",
      "|    clip_fraction        | 0.099      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 2.39       |\n",
      "|    explained_variance   | -1.44      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | -0.00809   |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00252   |\n",
      "|    std                  | 0.15       |\n",
      "|    value_loss           | 0.0224     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 9600         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059109926 |\n",
      "|    clip_fraction        | 0.247        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.4          |\n",
      "|    explained_variance   | 0.92         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00401      |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    std                  | 0.15         |\n",
      "|    value_loss           | 0.00209      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=12800, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.567        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 12800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059481654 |\n",
      "|    clip_fraction        | 0.254        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.41         |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0202      |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0159      |\n",
      "|    std                  | 0.149        |\n",
      "|    value_loss           | 0.00157      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 16000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005347508 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.42        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0279     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 0.149       |\n",
      "|    value_loss           | 0.0013      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=19200, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=19200, episode_reward=0.56 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.561        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 96           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 19200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038831988 |\n",
      "|    clip_fraction        | 0.241        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.45         |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0123      |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0157      |\n",
      "|    std                  | 0.148        |\n",
      "|    value_loss           | 0.0012       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 95           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 234          |\n",
      "|    total_timesteps      | 22400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025232404 |\n",
      "|    clip_fraction        | 0.216        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.47         |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000992     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0131      |\n",
      "|    std                  | 0.147        |\n",
      "|    value_loss           | 0.000999     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=25600, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=25600, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.572        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 273          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028192836 |\n",
      "|    clip_fraction        | 0.223        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.5          |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.027       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.0137      |\n",
      "|    std                  | 0.147        |\n",
      "|    value_loss           | 0.00103      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 28800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004547424 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.53        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0394     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.146       |\n",
      "|    value_loss           | 0.000953    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=32000, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=32000, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.57         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 92           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 346          |\n",
      "|    total_timesteps      | 32000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053031673 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.56         |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0261      |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    std                  | 0.145        |\n",
      "|    value_loss           | 0.000867     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 35200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004320319 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.58        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0279     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.144       |\n",
      "|    value_loss           | 0.000788    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=38400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=38400, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.573       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 420         |\n",
      "|    total_timesteps      | 38400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002097628 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.61        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.018      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 0.000789    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 456         |\n",
      "|    total_timesteps      | 41600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001974467 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.64        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 0.000809    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=44800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=44800, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.573        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 495          |\n",
      "|    total_timesteps      | 44800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027720197 |\n",
      "|    clip_fraction        | 0.188        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.67         |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00581     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00962     |\n",
      "|    std                  | 0.142        |\n",
      "|    value_loss           | 0.00074      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 530          |\n",
      "|    total_timesteps      | 48000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028380794 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.7          |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0321       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0088      |\n",
      "|    std                  | 0.141        |\n",
      "|    value_loss           | 0.000691     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=51200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=51200, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.577       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008052828 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00674    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.139       |\n",
      "|    value_loss           | 0.000711    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 607         |\n",
      "|    total_timesteps      | 54400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005367471 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0123     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    std                  | 0.138       |\n",
      "|    value_loss           | 0.000676    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=57600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=57600, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.573        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 647          |\n",
      "|    total_timesteps      | 57600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048077283 |\n",
      "|    clip_fraction        | 0.171        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.81         |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0282      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00791     |\n",
      "|    std                  | 0.138        |\n",
      "|    value_loss           | 0.000632     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 681          |\n",
      "|    total_timesteps      | 60800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021323424 |\n",
      "|    clip_fraction        | 0.182        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.85         |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0173       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00923     |\n",
      "|    std                  | 0.136        |\n",
      "|    value_loss           | 0.000633     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=64000, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.577        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 722          |\n",
      "|    total_timesteps      | 64000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028999215 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.91         |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00256     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00912     |\n",
      "|    std                  | 0.135        |\n",
      "|    value_loss           | 0.000656     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 758         |\n",
      "|    total_timesteps      | 67200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005328822 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.97        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00926    |\n",
      "|    std                  | 0.133       |\n",
      "|    value_loss           | 0.00057     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=70400, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.58         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 798          |\n",
      "|    total_timesteps      | 70400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012542541 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3            |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00879      |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00818     |\n",
      "|    std                  | 0.133        |\n",
      "|    value_loss           | 0.000552     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 834          |\n",
      "|    total_timesteps      | 73600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036108983 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.03         |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0293      |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    std                  | 0.132        |\n",
      "|    value_loss           | 0.000542     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=76800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=76800, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.579        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 875          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032072302 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.07         |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0301      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00866     |\n",
      "|    std                  | 0.131        |\n",
      "|    value_loss           | 0.000481     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 910          |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026173869 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.12         |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0331      |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00805     |\n",
      "|    std                  | 0.13         |\n",
      "|    value_loss           | 0.000501     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=83200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=83200, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.581        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 950          |\n",
      "|    total_timesteps      | 83200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029953283 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.15         |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0142      |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00782     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 0.000502     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 987          |\n",
      "|    total_timesteps      | 86400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026397705 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.19         |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0136       |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    std                  | 0.128        |\n",
      "|    value_loss           | 0.000475     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=89600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=89600, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.584       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1027        |\n",
      "|    total_timesteps      | 89600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003966106 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0304     |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 0.000492    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 1060         |\n",
      "|    total_timesteps      | 92800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050342786 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.27         |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0345       |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    std                  | 0.126        |\n",
      "|    value_loss           | 0.000454     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=96000, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.584        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 1100         |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030646264 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.32         |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0127      |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00838     |\n",
      "|    std                  | 0.125        |\n",
      "|    value_loss           | 0.000442     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 1134         |\n",
      "|    total_timesteps      | 99200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015996498 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.37         |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0193      |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    std                  | 0.123        |\n",
      "|    value_loss           | 0.000413     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=102400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=102400, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.584        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 1174         |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029249904 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.41         |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00418      |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.00728     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 0.000419     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 1207         |\n",
      "|    total_timesteps      | 105600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011941117 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.44         |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0158      |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 0.00042      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=108800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=108800, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4          |\n",
      "|    mean_reward          | 0.583      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 87         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 1246       |\n",
      "|    total_timesteps      | 108800     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00449377 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 3.48       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.000939   |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.00603   |\n",
      "|    std                  | 0.121      |\n",
      "|    value_loss           | 0.000382   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 1280        |\n",
      "|    total_timesteps      | 112000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003508326 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.52        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0105      |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    std                  | 0.12        |\n",
      "|    value_loss           | 0.000413    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=115200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=115200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.585       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1329        |\n",
      "|    total_timesteps      | 115200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003180716 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.55        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00747    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 0.000354    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1363        |\n",
      "|    total_timesteps      | 118400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004622726 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.58        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 0.00036     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=121600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=121600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.587        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 1404         |\n",
      "|    total_timesteps      | 121600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017574877 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.63         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0268       |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    std                  | 0.117        |\n",
      "|    value_loss           | 0.000368     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 1439         |\n",
      "|    total_timesteps      | 124800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029578386 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.67         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0265      |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    std                  | 0.117        |\n",
      "|    value_loss           | 0.00037      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=128000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.589        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 1481         |\n",
      "|    total_timesteps      | 128000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055190427 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.71         |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000152     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    std                  | 0.116        |\n",
      "|    value_loss           | 0.000351     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1517        |\n",
      "|    total_timesteps      | 131200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003204835 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.75        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0191     |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    std                  | 0.115       |\n",
      "|    value_loss           | 0.000359    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=134400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=134400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 4             |\n",
      "|    mean_reward          | 0.587         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 86            |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 1557          |\n",
      "|    total_timesteps      | 134400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086041226 |\n",
      "|    clip_fraction        | 0.152         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 3.79          |\n",
      "|    explained_variance   | 0.99          |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.00374       |\n",
      "|    n_updates            | 820           |\n",
      "|    policy_gradient_loss | -0.00598      |\n",
      "|    std                  | 0.114         |\n",
      "|    value_loss           | 0.000348      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1593        |\n",
      "|    total_timesteps      | 137600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006158275 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.83        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00626    |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    std                  | 0.113       |\n",
      "|    value_loss           | 0.000329    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=140800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=140800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.588       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1632        |\n",
      "|    total_timesteps      | 140800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003954281 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.86        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00206    |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    std                  | 0.112       |\n",
      "|    value_loss           | 0.000309    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 1667         |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026068992 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.89         |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0296      |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    std                  | 0.112        |\n",
      "|    value_loss           | 0.000315     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=147200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=147200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.59         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 1706         |\n",
      "|    total_timesteps      | 147200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048064333 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.93         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0158      |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    std                  | 0.111        |\n",
      "|    value_loss           | 0.000297     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 1741         |\n",
      "|    total_timesteps      | 150400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054469835 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.96         |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.006        |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    std                  | 0.111        |\n",
      "|    value_loss           | 0.000304     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=153600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=153600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.59         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 1781         |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032094133 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.01         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0166      |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    std                  | 0.109        |\n",
      "|    value_loss           | 0.000286     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 1814         |\n",
      "|    total_timesteps      | 156800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026436734 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.03         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0295       |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    std                  | 0.109        |\n",
      "|    value_loss           | 0.000267     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=160000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.591        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 1854         |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041512772 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.06         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0227      |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    std                  | 0.109        |\n",
      "|    value_loss           | 0.000272     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 1889        |\n",
      "|    total_timesteps      | 163200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003435753 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.11        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    std                  | 0.107       |\n",
      "|    value_loss           | 0.000278    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=166400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=166400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.592        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 1928         |\n",
      "|    total_timesteps      | 166400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038576117 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.16         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00437     |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    std                  | 0.107        |\n",
      "|    value_loss           | 0.000266     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 1962         |\n",
      "|    total_timesteps      | 169600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035156237 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.2          |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0151      |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    std                  | 0.106        |\n",
      "|    value_loss           | 0.000241     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=172800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=172800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.593        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 2002         |\n",
      "|    total_timesteps      | 172800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029204644 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.24         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0222       |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    std                  | 0.105        |\n",
      "|    value_loss           | 0.000226     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 2036        |\n",
      "|    total_timesteps      | 176000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004174467 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.27        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0237     |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    std                  | 0.104       |\n",
      "|    value_loss           | 0.000231    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=179200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=179200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.593       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 2075        |\n",
      "|    total_timesteps      | 179200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003476511 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.32        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0264     |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    std                  | 0.104       |\n",
      "|    value_loss           | 0.000232    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 2109         |\n",
      "|    total_timesteps      | 182400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025028018 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.36         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00663     |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    std                  | 0.103        |\n",
      "|    value_loss           | 0.000247     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=185600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=185600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.593        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 2149         |\n",
      "|    total_timesteps      | 185600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016330581 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.4          |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0074       |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    std                  | 0.102        |\n",
      "|    value_loss           | 0.000243     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 2183        |\n",
      "|    total_timesteps      | 188800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002544485 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.46        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0239      |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    std                  | 0.101       |\n",
      "|    value_loss           | 0.000227    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=192000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.592        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 2221         |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031130903 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.5          |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00957     |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    std                  | 0.1          |\n",
      "|    value_loss           | 0.000229     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 2255         |\n",
      "|    total_timesteps      | 195200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021189163 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.54         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0127       |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    std                  | 0.0994       |\n",
      "|    value_loss           | 0.000222     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=198400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=198400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.592        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 2294         |\n",
      "|    total_timesteps      | 198400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028713471 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.57         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0237      |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    std                  | 0.099        |\n",
      "|    value_loss           | 0.000205     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 86            |\n",
      "|    iterations           | 63            |\n",
      "|    time_elapsed         | 2329          |\n",
      "|    total_timesteps      | 201600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039554105 |\n",
      "|    clip_fraction        | 0.138         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 4.6           |\n",
      "|    explained_variance   | 0.994         |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.00311       |\n",
      "|    n_updates            | 1240          |\n",
      "|    policy_gradient_loss | -0.0034       |\n",
      "|    std                  | 0.0983        |\n",
      "|    value_loss           | 0.00021       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=204800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=204800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 4             |\n",
      "|    mean_reward          | 0.591         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 86            |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 2368          |\n",
      "|    total_timesteps      | 204800        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022542584 |\n",
      "|    clip_fraction        | 0.156         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 4.64          |\n",
      "|    explained_variance   | 0.995         |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.0245        |\n",
      "|    n_updates            | 1260          |\n",
      "|    policy_gradient_loss | -0.00481      |\n",
      "|    std                  | 0.0976        |\n",
      "|    value_loss           | 0.000187      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 2400        |\n",
      "|    total_timesteps      | 208000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002535864 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.68        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00334     |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    std                  | 0.0968      |\n",
      "|    value_loss           | 0.00019     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=211200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=211200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.592        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 2440         |\n",
      "|    total_timesteps      | 211200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038403978 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.72         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.02        |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    std                  | 0.0962       |\n",
      "|    value_loss           | 0.000194     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 2474         |\n",
      "|    total_timesteps      | 214400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016040173 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.75         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00477      |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    std                  | 0.0958       |\n",
      "|    value_loss           | 0.000198     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=217600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=217600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.592        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 2513         |\n",
      "|    total_timesteps      | 217600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035761294 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.79         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0231       |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    std                  | 0.0949       |\n",
      "|    value_loss           | 0.000186     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 2549         |\n",
      "|    total_timesteps      | 220800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025130766 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.83         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000684     |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    std                  | 0.0941       |\n",
      "|    value_loss           | 0.000175     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.593        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 2588         |\n",
      "|    total_timesteps      | 224000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020251614 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.86         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00537     |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    std                  | 0.0936       |\n",
      "|    value_loss           | 0.000165     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 2620        |\n",
      "|    total_timesteps      | 227200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005223345 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.9         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0131     |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    std                  | 0.093       |\n",
      "|    value_loss           | 0.000167    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=230400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=230400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.593        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 2661         |\n",
      "|    total_timesteps      | 230400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029892046 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.93         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00339     |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    std                  | 0.0925       |\n",
      "|    value_loss           | 0.000163     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 86            |\n",
      "|    iterations           | 73            |\n",
      "|    time_elapsed         | 2697          |\n",
      "|    total_timesteps      | 233600        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071435736 |\n",
      "|    clip_fraction        | 0.151         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 4.96          |\n",
      "|    explained_variance   | 0.996         |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | -0.00984      |\n",
      "|    n_updates            | 1440          |\n",
      "|    policy_gradient_loss | -0.00493      |\n",
      "|    std                  | 0.0923        |\n",
      "|    value_loss           | 0.000155      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=236800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=236800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.594        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 2737         |\n",
      "|    total_timesteps      | 236800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053106397 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5            |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0197       |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    std                  | 0.0913       |\n",
      "|    value_loss           | 0.000157     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 2771         |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027896047 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.05         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00613      |\n",
      "|    n_updates            | 1480         |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    std                  | 0.0906       |\n",
      "|    value_loss           | 0.000157     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=243200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=243200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.595        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 2812         |\n",
      "|    total_timesteps      | 243200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022804255 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.09         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00149     |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    std                  | 0.0898       |\n",
      "|    value_loss           | 0.000134     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 2858         |\n",
      "|    total_timesteps      | 246400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027939542 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.14         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0299       |\n",
      "|    n_updates            | 1520         |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    std                  | 0.089        |\n",
      "|    value_loss           | 0.000135     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=249600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=249600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.595       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 2902        |\n",
      "|    total_timesteps      | 249600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005365659 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.19        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00274     |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    std                  | 0.0882      |\n",
      "|    value_loss           | 0.000128    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 2936         |\n",
      "|    total_timesteps      | 252800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021122105 |\n",
      "|    clip_fraction        | 0.181        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.22         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00484      |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    std                  | 0.0879       |\n",
      "|    value_loss           | 0.000118     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=256000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.596       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 2975        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001349745 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.24        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00446     |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    std                  | 0.0876      |\n",
      "|    value_loss           | 0.000113    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 3011         |\n",
      "|    total_timesteps      | 259200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022412317 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.29         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00623     |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    std                  | 0.0866       |\n",
      "|    value_loss           | 0.000117     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=262400, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=262400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.596        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 3051         |\n",
      "|    total_timesteps      | 262400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019100079 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.35         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0244      |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    std                  | 0.0858       |\n",
      "|    value_loss           | 0.000108     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 3087         |\n",
      "|    total_timesteps      | 265600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014343199 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.4          |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00969     |\n",
      "|    n_updates            | 1640         |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    std                  | 0.0851       |\n",
      "|    value_loss           | 0.000119     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=268800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=268800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.596        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 3127         |\n",
      "|    total_timesteps      | 268800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034964008 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.44         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0142       |\n",
      "|    n_updates            | 1660         |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.0844       |\n",
      "|    value_loss           | 0.000111     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 85            |\n",
      "|    iterations           | 85            |\n",
      "|    time_elapsed         | 3167          |\n",
      "|    total_timesteps      | 272000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038938454 |\n",
      "|    clip_fraction        | 0.151         |\n",
      "|    clip_range           | 0.1           |\n",
      "|    entropy_loss         | 5.48          |\n",
      "|    explained_variance   | 0.997         |\n",
      "|    learning_rate        | 5e-05         |\n",
      "|    loss                 | 0.0172        |\n",
      "|    n_updates            | 1680          |\n",
      "|    policy_gradient_loss | -0.00371      |\n",
      "|    std                  | 0.0837        |\n",
      "|    value_loss           | 0.000103      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=275200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=275200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.596       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 3208        |\n",
      "|    total_timesteps      | 275200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004325971 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.53        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0327      |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    std                  | 0.0832      |\n",
      "|    value_loss           | 9.26e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 3248         |\n",
      "|    total_timesteps      | 278400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031402903 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.56         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0167      |\n",
      "|    n_updates            | 1720         |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    std                  | 0.0826       |\n",
      "|    value_loss           | 9.75e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=281600, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=281600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.597        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 3287         |\n",
      "|    total_timesteps      | 281600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043472154 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.6          |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00564      |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    std                  | 0.0819       |\n",
      "|    value_loss           | 9.12e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 3321         |\n",
      "|    total_timesteps      | 284800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011997166 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.63         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0068       |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    std                  | 0.0816       |\n",
      "|    value_loss           | 9.53e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=288000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.596       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 3360        |\n",
      "|    total_timesteps      | 288000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003223469 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.67        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00799    |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    std                  | 0.0811      |\n",
      "|    value_loss           | 8.87e-05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 3394         |\n",
      "|    total_timesteps      | 291200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012543341 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.71         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0127       |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    std                  | 0.0803       |\n",
      "|    value_loss           | 8.49e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=294400, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=294400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.597        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 3433         |\n",
      "|    total_timesteps      | 294400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041710446 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.75         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.012        |\n",
      "|    n_updates            | 1820         |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    std                  | 0.0798       |\n",
      "|    value_loss           | 8.16e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 3466        |\n",
      "|    total_timesteps      | 297600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004852186 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.78        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0149     |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    std                  | 0.0797      |\n",
      "|    value_loss           | 8.29e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=300800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.597       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 3505        |\n",
      "|    total_timesteps      | 300800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004179498 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.81        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00448    |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    std                  | 0.0791      |\n",
      "|    value_loss           | 7.91e-05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 3\n",
      "Box(-100000.0, 100000.0, (9,), float64)\n",
      "seed 3: model definition ..\n",
      "Using cuda device\n",
      "seed 3: learning ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7fae004c2550> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fae004cf0f0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
      "/data/ad181/RemoteDir/Paper_1_codes_revised/utils/custom_eval_callback.py:97: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7fae004c2550> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fae004cfe10>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 3200        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004291204 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.85        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00305    |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    std                  | 0.0784      |\n",
      "|    value_loss           | 8.14e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6400, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 4              |\n",
      "|    mean_reward          | 0.591          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 118            |\n",
      "|    iterations           | 2              |\n",
      "|    time_elapsed         | 54             |\n",
      "|    total_timesteps      | 6400           |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00017012455 |\n",
      "|    clip_fraction        | 0.0928         |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | 2.4            |\n",
      "|    explained_variance   | 0.169          |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | -0.00913       |\n",
      "|    n_updates            | 20             |\n",
      "|    policy_gradient_loss | -0.00379       |\n",
      "|    std                  | 0.15           |\n",
      "|    value_loss           | 0.0818         |\n",
      "--------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 9600        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003824615 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.39        |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00743     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    std                  | 0.15        |\n",
      "|    value_loss           | 0.00396     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=12800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=12800, episode_reward=0.56 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.556       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006061492 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.39        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0182     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    std                  | 0.15        |\n",
      "|    value_loss           | 0.00174     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 16000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005731897 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.4         |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    std                  | 0.15        |\n",
      "|    value_loss           | 0.0016      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=19200, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=19200, episode_reward=0.55 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.555        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 94           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 19200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050302423 |\n",
      "|    clip_fraction        | 0.225        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.43         |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0236      |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    std                  | 0.148        |\n",
      "|    value_loss           | 0.00142      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 238          |\n",
      "|    total_timesteps      | 22400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035988465 |\n",
      "|    clip_fraction        | 0.181        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.47         |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0336      |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    std                  | 0.148        |\n",
      "|    value_loss           | 0.00116      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=25600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=25600, episode_reward=0.56 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.559       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 25600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007973262 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0364     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 0.147       |\n",
      "|    value_loss           | 0.00113     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 92           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 311          |\n",
      "|    total_timesteps      | 28800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036688177 |\n",
      "|    clip_fraction        | 0.223        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.5          |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00745     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.013       |\n",
      "|    std                  | 0.147        |\n",
      "|    value_loss           | 0.00101      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=32000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=32000, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.568        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 349          |\n",
      "|    total_timesteps      | 32000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031387603 |\n",
      "|    clip_fraction        | 0.21         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.51         |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000857     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0125      |\n",
      "|    std                  | 0.147        |\n",
      "|    value_loss           | 0.000993     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 382          |\n",
      "|    total_timesteps      | 35200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014057312 |\n",
      "|    clip_fraction        | 0.186        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.53         |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0106      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    std                  | 0.146        |\n",
      "|    value_loss           | 0.000922     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=38400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=38400, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.571        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 422          |\n",
      "|    total_timesteps      | 38400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013958317 |\n",
      "|    clip_fraction        | 0.215        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.56         |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0138       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    std                  | 0.145        |\n",
      "|    value_loss           | 0.000865     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 455          |\n",
      "|    total_timesteps      | 41600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022740073 |\n",
      "|    clip_fraction        | 0.178        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.6          |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00887     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    std                  | 0.144        |\n",
      "|    value_loss           | 0.000804     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=44800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=44800, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.571        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 494          |\n",
      "|    total_timesteps      | 44800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023756435 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.64         |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0194       |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    std                  | 0.142        |\n",
      "|    value_loss           | 0.000818     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 527          |\n",
      "|    total_timesteps      | 48000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054892018 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.68         |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0294      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00937     |\n",
      "|    std                  | 0.142        |\n",
      "|    value_loss           | 0.000735     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=51200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=51200, episode_reward=0.57 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.573       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002633107 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.73        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00664     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    std                  | 0.14        |\n",
      "|    value_loss           | 0.00072     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 54400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004239736 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00275     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    std                  | 0.139       |\n",
      "|    value_loss           | 0.000698    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=57600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=57600, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.577       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 642         |\n",
      "|    total_timesteps      | 57600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005649162 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.81        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0352     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    std                  | 0.138       |\n",
      "|    value_loss           | 0.000675    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 675          |\n",
      "|    total_timesteps      | 60800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022666105 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.84         |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0273       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    std                  | 0.137        |\n",
      "|    value_loss           | 0.000673     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=64000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=64000, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.583        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 714          |\n",
      "|    total_timesteps      | 64000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030722928 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.87         |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0308      |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00893     |\n",
      "|    std                  | 0.136        |\n",
      "|    value_loss           | 0.000662     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 747         |\n",
      "|    total_timesteps      | 67200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006498475 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 2.91        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0159     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 0.0006      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=70400, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.583        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 785          |\n",
      "|    total_timesteps      | 70400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028400738 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.94         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0158       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00737     |\n",
      "|    std                  | 0.134        |\n",
      "|    value_loss           | 0.000615     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 819          |\n",
      "|    total_timesteps      | 73600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049777175 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 2.97         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0155      |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    std                  | 0.134        |\n",
      "|    value_loss           | 0.000578     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=76800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=76800, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.584        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 863          |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031651831 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.02         |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0131      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00752     |\n",
      "|    std                  | 0.132        |\n",
      "|    value_loss           | 0.000594     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 897          |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025768557 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.07         |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000658     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    std                  | 0.131        |\n",
      "|    value_loss           | 0.000516     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=83200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=83200, episode_reward=0.58 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.585        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 947          |\n",
      "|    total_timesteps      | 83200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030208135 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.13         |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00639     |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00705     |\n",
      "|    std                  | 0.13         |\n",
      "|    value_loss           | 0.000537     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 982         |\n",
      "|    total_timesteps      | 86400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001969745 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.18        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00529     |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 0.000493    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=89600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=89600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.586        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 1022         |\n",
      "|    total_timesteps      | 89600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048539056 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.23         |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0052       |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    std                  | 0.127        |\n",
      "|    value_loss           | 0.000495     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1058        |\n",
      "|    total_timesteps      | 92800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004727872 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0121      |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 0.000458    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=96000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=96000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.587        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 1097         |\n",
      "|    total_timesteps      | 96000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033827361 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.3          |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00867      |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    std                  | 0.125        |\n",
      "|    value_loss           | 0.000442     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 1132         |\n",
      "|    total_timesteps      | 99200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018106421 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0122       |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    std                  | 0.124        |\n",
      "|    value_loss           | 0.000422     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=102400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=102400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.589        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 1171         |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034951633 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.38         |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00808     |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    std                  | 0.123        |\n",
      "|    value_loss           | 0.000422     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 1206         |\n",
      "|    total_timesteps      | 105600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021087956 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.42         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00547     |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 0.000384     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=108800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=108800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.592        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 1245         |\n",
      "|    total_timesteps      | 108800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036615515 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.46         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0195      |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00758     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 0.000386     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 1280         |\n",
      "|    total_timesteps      | 112000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022191205 |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.51         |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00634     |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    std                  | 0.12         |\n",
      "|    value_loss           | 0.000356     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=115200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=115200, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.592        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 1319         |\n",
      "|    total_timesteps      | 115200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032319704 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.57         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.000992    |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    std                  | 0.119        |\n",
      "|    value_loss           | 0.000374     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 1352         |\n",
      "|    total_timesteps      | 118400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023789767 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.62         |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0182       |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00659     |\n",
      "|    std                  | 0.118        |\n",
      "|    value_loss           | 0.000335     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=121600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=121600, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4          |\n",
      "|    mean_reward          | 0.593      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 87         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 1391       |\n",
      "|    total_timesteps      | 121600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00441681 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 3.68       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.011      |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.0066    |\n",
      "|    std                  | 0.116      |\n",
      "|    value_loss           | 0.000335   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1425        |\n",
      "|    total_timesteps      | 124800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002661756 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.72        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000911    |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    std                  | 0.115       |\n",
      "|    value_loss           | 0.000318    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=128000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=128000, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.594        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 1472         |\n",
      "|    total_timesteps      | 128000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039168773 |\n",
      "|    clip_fraction        | 0.169        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.78         |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0114      |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    std                  | 0.114        |\n",
      "|    value_loss           | 0.000307     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1505        |\n",
      "|    total_timesteps      | 131200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001812811 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 3.84        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00941    |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    std                  | 0.113       |\n",
      "|    value_loss           | 0.000289    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=134400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=134400, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4          |\n",
      "|    mean_reward          | 0.595      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 86         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 1545       |\n",
      "|    total_timesteps      | 134400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00440704 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | 3.9        |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 5e-05      |\n",
      "|    loss                 | 0.0248     |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.00613   |\n",
      "|    std                  | 0.111      |\n",
      "|    value_loss           | 0.000296   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 1580         |\n",
      "|    total_timesteps      | 137600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040655555 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 3.96         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.027       |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    std                  | 0.11         |\n",
      "|    value_loss           | 0.00029      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=140800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=140800, episode_reward=0.59 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.595        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 1619         |\n",
      "|    total_timesteps      | 140800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029252106 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.02         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00135     |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    std                  | 0.109        |\n",
      "|    value_loss           | 0.00027      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 1652         |\n",
      "|    total_timesteps      | 144000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033525056 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.07         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00337     |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    std                  | 0.108        |\n",
      "|    value_loss           | 0.000255     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=147200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=147200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.597       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1693        |\n",
      "|    total_timesteps      | 147200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002795093 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00488    |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    std                  | 0.107       |\n",
      "|    value_loss           | 0.000263    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1727        |\n",
      "|    total_timesteps      | 150400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003522432 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.17        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0271     |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    std                  | 0.106       |\n",
      "|    value_loss           | 0.000243    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=153600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=153600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.598        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 1768         |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030869497 |\n",
      "|    clip_fraction        | 0.182        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.22         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00196     |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    std                  | 0.105        |\n",
      "|    value_loss           | 0.000222     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 1802         |\n",
      "|    total_timesteps      | 156800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029151272 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.26         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0012       |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    std                  | 0.104        |\n",
      "|    value_loss           | 0.000224     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=160000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.599        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 1841         |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045127897 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.31         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00854     |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.00513     |\n",
      "|    std                  | 0.103        |\n",
      "|    value_loss           | 0.000209     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 1875         |\n",
      "|    total_timesteps      | 163200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031788975 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.38         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0288      |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    std                  | 0.102        |\n",
      "|    value_loss           | 0.000194     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=166400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=166400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.599        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 1914         |\n",
      "|    total_timesteps      | 166400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032836648 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.44         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00705     |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    std                  | 0.101        |\n",
      "|    value_loss           | 0.000189     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 1949         |\n",
      "|    total_timesteps      | 169600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022116709 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.48         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0129       |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    std                  | 0.1          |\n",
      "|    value_loss           | 0.000178     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=172800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=172800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.599        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 1988         |\n",
      "|    total_timesteps      | 172800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035940034 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.55         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0204      |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    std                  | 0.099        |\n",
      "|    value_loss           | 0.000162     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 2023         |\n",
      "|    total_timesteps      | 176000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030967211 |\n",
      "|    clip_fraction        | 0.135        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.6          |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00847     |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    std                  | 0.0983       |\n",
      "|    value_loss           | 0.000156     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=179200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=179200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 2064         |\n",
      "|    total_timesteps      | 179200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036433053 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.63         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00279      |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    std                  | 0.098        |\n",
      "|    value_loss           | 0.000151     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 2099         |\n",
      "|    total_timesteps      | 182400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032807868 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.67         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0165       |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    std                  | 0.097        |\n",
      "|    value_loss           | 0.000148     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=185600, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=185600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 2149         |\n",
      "|    total_timesteps      | 185600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063633765 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.72         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0212      |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    std                  | 0.0963       |\n",
      "|    value_loss           | 0.000154     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 2182         |\n",
      "|    total_timesteps      | 188800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007636124 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.77         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00257      |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    std                  | 0.0955       |\n",
      "|    value_loss           | 0.000136     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=192000, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=192000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.6          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 2220         |\n",
      "|    total_timesteps      | 192000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030043132 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.82         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000559     |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    std                  | 0.0946       |\n",
      "|    value_loss           | 0.000138     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 2252         |\n",
      "|    total_timesteps      | 195200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016841415 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.86         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0141       |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    std                  | 0.0938       |\n",
      "|    value_loss           | 0.000117     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=198400, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=198400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.602       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 2291        |\n",
      "|    total_timesteps      | 198400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005541605 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 4.91        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00358     |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    std                  | 0.0931      |\n",
      "|    value_loss           | 0.000125    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 2325         |\n",
      "|    total_timesteps      | 201600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030988946 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 4.96         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0136       |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    std                  | 0.0923       |\n",
      "|    value_loss           | 0.000114     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=204800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=204800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.601       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 2365        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005479992 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.01        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0192      |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    std                  | 0.0915      |\n",
      "|    value_loss           | 0.00011     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 2398         |\n",
      "|    total_timesteps      | 208000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045160763 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.07         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0065       |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    std                  | 0.0904       |\n",
      "|    value_loss           | 0.000109     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=211200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=211200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.601        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 2437         |\n",
      "|    total_timesteps      | 211200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036229908 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.12         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00516     |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    std                  | 0.0898       |\n",
      "|    value_loss           | 0.000102     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 2470         |\n",
      "|    total_timesteps      | 214400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013864259 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.17         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.000474    |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    std                  | 0.0889       |\n",
      "|    value_loss           | 9.46e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=217600, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=217600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.601       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 2510        |\n",
      "|    total_timesteps      | 217600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005023727 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.23        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0103     |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    std                  | 0.088       |\n",
      "|    value_loss           | 9.88e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 2544        |\n",
      "|    total_timesteps      | 220800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005515593 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.29        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    std                  | 0.0871      |\n",
      "|    value_loss           | 9.18e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=224000, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=224000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.602       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 2582        |\n",
      "|    total_timesteps      | 224000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003612974 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.33        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.0489      |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    std                  | 0.0867      |\n",
      "|    value_loss           | 8.93e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 2616         |\n",
      "|    total_timesteps      | 227200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036941504 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.37         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.000481    |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    std                  | 0.086        |\n",
      "|    value_loss           | 8.83e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=230400, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=230400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.603        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 2655         |\n",
      "|    total_timesteps      | 230400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042411163 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.41         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00819      |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    std                  | 0.0855       |\n",
      "|    value_loss           | 7.87e-05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 2689         |\n",
      "|    total_timesteps      | 233600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047815978 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.45         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00485     |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    std                  | 0.0847       |\n",
      "|    value_loss           | 8.05e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=236800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=236800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.602        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 2728         |\n",
      "|    total_timesteps      | 236800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019634592 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.5          |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.000266     |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    std                  | 0.0842       |\n",
      "|    value_loss           | 7.53e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 2761         |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032193041 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.54         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00473     |\n",
      "|    n_updates            | 1480         |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    std                  | 0.0837       |\n",
      "|    value_loss           | 7.41e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=243200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=243200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.602        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 2801         |\n",
      "|    total_timesteps      | 243200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031083857 |\n",
      "|    clip_fraction        | 0.169        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.58         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0152       |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    std                  | 0.0831       |\n",
      "|    value_loss           | 7.19e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 2834         |\n",
      "|    total_timesteps      | 246400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026664124 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.62         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00404     |\n",
      "|    n_updates            | 1520         |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    std                  | 0.0825       |\n",
      "|    value_loss           | 6.78e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=249600, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=249600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 2873        |\n",
      "|    total_timesteps      | 249600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004784276 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.66        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00182     |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    std                  | 0.082       |\n",
      "|    value_loss           | 6.85e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 2907         |\n",
      "|    total_timesteps      | 252800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038087063 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.69         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00594     |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    std                  | 0.0816       |\n",
      "|    value_loss           | 6.53e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=256000, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=256000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 2946        |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004498877 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.72        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.00761    |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    std                  | 0.0813      |\n",
      "|    value_loss           | 5.79e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 2980         |\n",
      "|    total_timesteps      | 259200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041053123 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.76         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00927     |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    std                  | 0.0807       |\n",
      "|    value_loss           | 6.26e-05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=262400, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=262400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.603        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 3019         |\n",
      "|    total_timesteps      | 262400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019182428 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.82         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -2.47e-05    |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    std                  | 0.0798       |\n",
      "|    value_loss           | 5.53e-05     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 86             |\n",
      "|    iterations           | 83             |\n",
      "|    time_elapsed         | 3052           |\n",
      "|    total_timesteps      | 265600         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | -0.00048447252 |\n",
      "|    clip_fraction        | 0.16           |\n",
      "|    clip_range           | 0.1            |\n",
      "|    entropy_loss         | 5.86           |\n",
      "|    explained_variance   | 0.998          |\n",
      "|    learning_rate        | 5e-05          |\n",
      "|    loss                 | 0.00613        |\n",
      "|    n_updates            | 1640           |\n",
      "|    policy_gradient_loss | -0.00442       |\n",
      "|    std                  | 0.0793         |\n",
      "|    value_loss           | 5.57e-05       |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=268800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=268800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 3091        |\n",
      "|    total_timesteps      | 268800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003643403 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 5.89        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | -0.0162     |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    std                  | 0.0791      |\n",
      "|    value_loss           | 5.53e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 3125         |\n",
      "|    total_timesteps      | 272000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023902953 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.93         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0468       |\n",
      "|    n_updates            | 1680         |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    std                  | 0.0784       |\n",
      "|    value_loss           | 6.08e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=275200, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=275200, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.603        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 3164         |\n",
      "|    total_timesteps      | 275200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039279563 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 5.97         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00228      |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    std                  | 0.0778       |\n",
      "|    value_loss           | 5.74e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 3199         |\n",
      "|    total_timesteps      | 278400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030402606 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 6.01         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.00694      |\n",
      "|    n_updates            | 1720         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    std                  | 0.0774       |\n",
      "|    value_loss           | 5.62e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=281600, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=281600, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.603        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 3238         |\n",
      "|    total_timesteps      | 281600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028342423 |\n",
      "|    clip_fraction        | 0.144        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 6.05         |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0108      |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    std                  | 0.0771       |\n",
      "|    value_loss           | 5.4e-05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 3271         |\n",
      "|    total_timesteps      | 284800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022894356 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 6.09         |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0124       |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    std                  | 0.0763       |\n",
      "|    value_loss           | 4.81e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=288000, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=288000, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 3310        |\n",
      "|    total_timesteps      | 288000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004822937 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 6.14        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.00478     |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    std                  | 0.0756      |\n",
      "|    value_loss           | 4.25e-05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 87           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 3346         |\n",
      "|    total_timesteps      | 291200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025778061 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 6.19         |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.00511     |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    std                  | 0.0752       |\n",
      "|    value_loss           | 4.52e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=294400, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=294400, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4           |\n",
      "|    mean_reward          | 0.603       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 3389        |\n",
      "|    total_timesteps      | 294400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002330494 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | 6.24        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 5e-05       |\n",
      "|    loss                 | 0.000533    |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    std                  | 0.0743      |\n",
      "|    value_loss           | 4.29e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 3421         |\n",
      "|    total_timesteps      | 297600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040947935 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 6.29         |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | 0.0251       |\n",
      "|    n_updates            | 1840         |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    std                  | 0.0737       |\n",
      "|    value_loss           | 4.04e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=300800, episode_reward=0.61 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "Eval num_timesteps=300800, episode_reward=0.60 +/- 0.00\n",
      "Episode length: 4.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4            |\n",
      "|    mean_reward          | 0.602        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 3468         |\n",
      "|    total_timesteps      | 300800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031992265 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | 6.33         |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 5e-05        |\n",
      "|    loss                 | -0.0049      |\n",
      "|    n_updates            | 1860         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    std                  | 0.0734       |\n",
      "|    value_loss           | 3.93e-05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"599.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seed in range(1,4):\n",
    "    if True:\n",
    "        print(f'seed {seed}')\n",
    "        log_dir = './data/'+case+'/seed_'+str(seed)\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        num_cpu = 64\n",
    "        env_train.seed(seed)\n",
    "        env_eval.seed(seed)\n",
    "        env_train_ = env_wrappers(env_train, x_coords, y_coords)\n",
    "        env_eval_ = env_wrappers(env_eval, x_coords, y_coords)\n",
    "        train_callback = CustomEvalCallback(env_train_, \n",
    "                                            best_model_save_path=None, \n",
    "                                            n_eval_episodes=1,\n",
    "                                            log_path=str(log_dir)+'/results_train', \n",
    "                                            eval_freq=100)\n",
    "        callback_list = [train_callback]\n",
    "        eval_callback = CustomEvalCallback(env_eval_, \n",
    "                                           best_model_save_path=str(log_dir)+'/best_model_eval', \n",
    "                                           n_eval_episodes=1,\n",
    "                                           log_path=str(log_dir)+'/results_eval', \n",
    "                                           eval_freq=100)\n",
    "        callback_list.append(eval_callback)\n",
    "        callback = CallbackList(callback_list)\n",
    "        env = SubprocVecEnv([make_env(env_train_, i, seed) for i in range(num_cpu)])\n",
    "        print(env.observation_space)\n",
    "        print(f'seed {seed}: model definition ..')\n",
    "        model = PPO(policy=MlpPolicy,\n",
    "                env=env,\n",
    "                learning_rate = 5e-5,\n",
    "                n_steps = 50,\n",
    "                batch_size = 16,\n",
    "                n_epochs = 20,\n",
    "                gamma = 0.99,\n",
    "                gae_lambda = 0.95,\n",
    "                clip_range = 0.1,\n",
    "                clip_range_vf = None,\n",
    "                ent_coef = 0.001,\n",
    "                vf_coef = 0.5,\n",
    "                max_grad_norm = 0.5,\n",
    "                use_sde= False,\n",
    "                create_eval_env= False,\n",
    "                policy_kwargs = dict(net_arch=[20,20], log_std_init=-1.9),\n",
    "                verbose = 1,\n",
    "                target_kl =0.05,\n",
    "                seed = seed,\n",
    "                device = \"auto\")\n",
    "        print(f'seed {seed}: learning ..')\n",
    "        model.learn(total_timesteps=300000, callback=callback)\n",
    "        model.save(log_dir+'/PPO')\n",
    "        fig = plot_learning(log_dir, case='train')\n",
    "        fig.savefig(log_dir+'/learn_train.png')\n",
    "        fig = plot_learning(log_dir, case='eval')\n",
    "        fig.savefig(log_dir+'/learn_eval.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
